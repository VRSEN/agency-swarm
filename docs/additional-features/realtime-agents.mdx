---
title: "Realtime Agents"
description: "Build low-latency realtime voice agents with Agency Swarm."
icon: "microphone"
---

Agency Swarm layers its realtime experience on top of the OpenAI Agents SDK so that you can reuse your existing Agency Swarm Agent parameters (instructions, tools, handoffs) unchanged in voice sessions.

The `run_realtime` helper converts your `Agent` parameters into realtime counterparts, launches the Agents SDK session, and hosts a FastAPI/WebSocket bridge (with an optional Twilio transport) so you can ship low-latency voice flows without wiring the protocol yourself.

## What you can build

- **Voice-first assistants** for web, mobile, or phone.
- **Interruptible** dialogs: users talk over the model; it stops and pivots.
- **Realtime clients** that stream audio while sharing additional Realtime events (text, tool payloads) through one connection.

## How it works (at a glance)

Client (mic/WebRTC or Twilio) ↔ **FastAPI WebSocket** ↔ **OpenAI Realtime** ↔ **Agency Swarm Agent + Tools**.

The session uses **one model (e.g. `gpt-realtime`)** and a **session-level voice** (e.g., `alloy`, `verse`). Voice is picked at session start.

![Hosted Agency Swarm realtime demo UI showing active voice session](/images/agencii-hosted.png)

## Requirements

- OpenAI access to the **Realtime API** and the `gpt-realtime` model.
- Python 3.12+.
- `agency-swarm` v1.3+ with FastAPI extras.

```bash
pip install "agency-swarm[fastapi]"
```

<Tip>
  Load your credentials before running the examples (for example, `source .env` so `OPENAI_API_KEY` is in the environment).
</Tip>

## Quickstart (FastAPI, WebSocket)

Define your agent like usual:

```python
# voice_agent.py
from agency_swarm import Agent, function_tool

@function_tool
def lookup_order(order_id: str) -> str:
    """Return a short order status by ID."""
    return f"Order {order_id} is on its way."

voice_agent = Agent(
    name="Voice Concierge",
    instructions="Speak briefly. Ask one question at a time. Use tools only when needed.",
    tools=[lookup_order],
)
```

Start the server with the new helper:

```python
# server.py
from agency_swarm import Agency
from agency_swarm.integrations import run_realtime
from voice_agent import voice_agent

if __name__ == "__main__":
    agency = Agency(voice_agent)
    run_realtime(
        agency=agency.to_realtime(),
        model="gpt-realtime",
        voice="alloy",
        turn_detection={"type": "server_vad"},
        host="0.0.0.0",
        port=8000,
    )
```

`run_realtime` starts the FastAPI app, opens the Realtime connection, and hosts a `/realtime` WebSocket endpoint for you. There is no additional routing code to write. Run `python -m examples.interactive.realtime.demo` for the bundled browser UI and edit that script to customize the agent behavior.

<Note>
- **Single-model rule:** realtime uses one model per session; per-agent `model` is ignored during voice sessions.   
- **Voice:** choose at session start. You can’t switch voices after audio has begun.
</Note>

## Add a simple web client (browser)

Use the official OpenAI Realtime example client (WebRTC or WebSocket). Point it to `ws://localhost:8000/realtime` (or your deployed address), and you’ll get mic capture, response audio, and a minimal UI.
- Example: FastAPI app + client (OpenAI “realtime/app” sample).
- Event flow: send conversation.item.create (user input), then response.create to get the model to answer.
- When using the packaged browser demo, audio runs at 24 kHz, matching the default realtime voice output.

See OpenAI’s example for a copy-paste front end and event payloads.

## Twilio (phone calls) — optional

Pass a Twilio number to the helper and it will respond with the TwiML + media-stream bridge automatically:

```python
run_realtime(
    agency=Agency(voice_agent).to_realtime(),
    model="gpt-realtime",
    voice="alloy",
    twilio_number="+15551234567",
    twilio_audio_format="g711_ulaw",
    turn_detection={"type": "server_vad"},
)
```

### Notes

- Use HTTPS (valid certs) so Twilio can open the WebSocket.
- Keep the media stream async — never block the loop with slow I/O.
- For local dev, tunnel with ngrok http 8000 and set your number’s webhook to /incoming-call.

## Using multiple agents (handoffs)

Realtime handoffs reuse the wiring you already defined in your `Agency`. Register your delegation routes with `SendMessageHandoff`, then call `run_realtime` with `agency.to_realtime()`—its designated entry point becomes the realtime starter automatically.

```python
from agency_swarm import Agency, Agent
from agency_swarm.tools import SendMessageHandoff

billing = Agent(name="Billing", instructions="Answer billing questions briefly.")
faq = Agent(name="FAQ", instructions="Answer FAQs briefly.")

concierge = Agent(
    name="Concierge",
    instructions="Triage the request, then delegate if needed.",
)

agency = Agency(
    concierge,
    communication_flows=[
        (concierge > billing, SendMessageHandoff),
        (concierge > faq, SendMessageHandoff),
    ],
)

run_realtime(agency=agency.to_realtime(), model="gpt-realtime", voice="alloy")
```

<Note>
  Handoffs are provided by the underlying RealtimeAgent type and must come from your `Agency` configuration—do not populate `agent.handoffs` manually. In telephony transports, test thoroughly—interrupts and audio buffer management can affect stability during/after a handoff. Keep sub-agents concise.
</Note>

## Operational tips

- Interrupts: With server VAD, the API emits interruption events; keep your UI/telephony bridge ready to truncate playback and resume.
- Latency budgets: Run the realtime server in its own process; avoid heavy CPU in the event loop.
- Observability: Log tool invocations and measure barge-in to stop and first-token to user latencies.
- Fallbacks: Reuse the same agents for text streaming endpoints if voice is unavailable.

## Troubleshooting

- No audio or clipped speech: Check input_audio_format/output_audio_format (Twilio uses μ-law 8k).
- Voice stuck on default: Voice must be set before the model emits audio.
- Per-agent models ignored: By design in realtime — choose the model at session start.
- Handoff loops: Keep handoff graphs shallow; return to the primary agent explicitly when finished.

## See also

- FastAPI Integration (HTTP/REST patterns you can run alongside realtime): /additional-features/fastapi-integration
- OpenAI Realtime guides, models, and event references (if you need protocol details).
