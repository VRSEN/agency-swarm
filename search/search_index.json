{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>An open source agent orchestration framework built on top of the latest OpenAI Assistants API.</p> <p> </p>"},{"location":"#what-is-agency-swarm","title":"What is Agency Swarm?","text":"<p>Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the agent creation process and enable anyone to create collaborative swarm of agents (Agencies), each with distinct roles and capabilities. By thinking about automation in terms of real world entities, such as agencies and specialized agent roles, we make it a lot more intuitive for both the agents and the users.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Customizable Agent Roles: Define roles like CEO, virtual assistant, developer, etc., and customize their functionalities with Assistants API.</li> <li>Full Control Over Prompts: Avoid conflicts and restrictions of pre-defined prompts, allowing full customization.</li> <li>Tool Creation: Tools within Agency Swarm are created using Instructor, which provides a convenient interface and automatic type validation.</li> <li>Efficient Communication: Agents communicate through a specially designed \"send message\" tool based on their own descriptions.</li> <li>State Management: Agency Swarm efficiently manages the state of your assistants on OpenAI, maintaining it in a special <code>settings.json</code> file.</li> <li>Deployable in Production: Agency Swarm is designed to be reliable and easily deployable in production environments.</li> </ul>"},{"location":"#agency-swarm-vs-other-frameworks","title":"Agency Swarm vs Other Frameworks","text":"<p>Unlike other frameworks, Agency Swarm:</p> <ol> <li>Does not write prompts for you.</li> <li>Prevents hallucinations with automatic type checking and error correction with instructor</li> <li>Allows you to easily define communication flows.</li> </ol>"},{"location":"#autogen-vs-agency-swarm","title":"AutoGen vs Agency Swarm","text":"<p>In AutoGen, by default, the next speaker is determined with an extra call to the model that emulates \"role play\" between the agents. [1] Not only this is very inefficient, but it also makes the system less controllable and less customizable, because you cannot control which agent can communicate with which other agent.</p> <p>Recently, autogen has added support for determining the next speaker based on certain hardcoded conditions. While this does make your system more customizable, it completely undermines the main benefit of agentic systems - adaptability. In my opinion, you should only determine the boundaries for your agents, not the conditions themselves, as you are unlikely to account for every single condition in the real world. (#113)</p> <p>In Agency Swarm, on the other hand, the communication is handled through the special <code>SendMessage</code> tool. [2] Your agents will determine who to communicate with by themselves based on their own descriptions. All you have to do is set the boundaries for their communication inside the agency chart.</p>"},{"location":"#crewai-vs-agency-swarm","title":"CrewAI vs Agency Swarm","text":"<p>CrewAI introduces a concept of \"process\" [3] into agent communication, which provides some control over the communication flow. However, the biggest problem with CrewAI is that it is built on top of Langchain, which was created long before any function-calling models were released. This means that there is no type checking or error correction, so any action that your agent takes (which is the most important part of the system) could cause the whole system to go down if the model hallucinates. The sole advantage of CrewAI is its compatibility with open-source models.</p>"},{"location":"#need-help","title":"Need help?","text":"<p>If you need quick help with Agency Swarm, feel free to ask in the Discord server.</p> <p>If you need help creating custom agent swarms for your business, check out our Agents-as-a-Service subscription, or schedule a consultation with me at https://calendly.com/vrsen/ai-project-consultation</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT license.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#agency_swarm.agents.agent.Agent","title":"<code>Agent</code>","text":"Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>class Agent:\n    _shared_state: SharedState = None\n\n    @property\n    def assistant(self):\n        if not hasattr(self, \"_assistant\") or self._assistant is None:\n            raise Exception(\n                \"Assistant is not initialized. Please run init_oai() first.\"\n            )\n        return self._assistant\n\n    @assistant.setter\n    def assistant(self, value):\n        self._assistant = value\n\n    @property\n    def functions(self):\n        return [tool for tool in self.tools if issubclass(tool, BaseTool)]\n\n    @property\n    def shared_state(self):\n        return self._shared_state\n\n    @shared_state.setter\n    def shared_state(self, value):\n        self._shared_state = value\n        for tool in self.tools:\n            if issubclass(tool, BaseTool):\n                tool._shared_state = value\n\n    def response_validator(self, message: str | list) -&gt; str:\n        \"\"\"\n        Validates the response from the agent. If the response is invalid, it must raise an exception with instructions\n        for the caller agent on how to proceed.\n\n        Parameters:\n            message (str): The response from the agent.\n\n        Returns:\n            str: The validated response.\n        \"\"\"\n        return message\n\n    def __init__(\n        self,\n        id: str = None,\n        name: str = None,\n        description: str = None,\n        instructions: str = \"\",\n        tools: List[\n            Union[\n                Type[BaseTool], Type[FileSearch], Type[CodeInterpreter], type[Retrieval]\n            ]\n        ] = None,\n        tool_resources: ToolResources = None,\n        temperature: float = None,\n        top_p: float = None,\n        response_format: Union[str, dict, type] = \"auto\",\n        tools_folder: str = None,\n        files_folder: Union[List[str], str] = None,\n        schemas_folder: Union[List[str], str] = None,\n        api_headers: Dict[str, Dict[str, str]] = None,\n        api_params: Dict[str, Dict[str, str]] = None,\n        file_ids: List[str] = None,\n        metadata: Dict[str, str] = None,\n        model: str = \"gpt-4o-2024-08-06\",\n        reasoning_effort: Literal[\"low\", \"medium\", \"high\"] = \"medium\",\n        validation_attempts: int = 1,\n        max_prompt_tokens: int = None,\n        max_completion_tokens: int = None,\n        truncation_strategy: dict = None,\n        examples: List[ExampleMessage] = None,\n        file_search: FileSearchConfig = None,\n        parallel_tool_calls: bool = True,\n        refresh_from_id: bool = True,\n    ):\n        \"\"\"\n        Initializes an Agent with specified attributes, tools, and OpenAI client.\n\n        Parameters:\n            id (str, optional): Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.\n            name (str, optional): Name of the agent. Defaults to the class name if not provided.\n            description (str, optional): A brief description of the agent's purpose. Defaults to None.\n            instructions (str, optional): Path to a file containing specific instructions for the agent. Defaults to an empty string.\n            tools (List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]], optional): A list of tools (as classes) that the agent can use. Defaults to an empty list.\n            tool_resources (ToolResources, optional): A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.\n            temperature (float, optional): The temperature parameter for the OpenAI API. Defaults to None.\n            top_p (float, optional): The top_p parameter for the OpenAI API. Defaults to None.\n            response_format (Union[str, Dict, type], optional): The response format for the OpenAI API. If BaseModel is provided, it will be converted to a response format. Defaults to None.\n            tools_folder (str, optional): Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.\n            files_folder (Union[List[str], str], optional): Path or list of paths to directories containing files associated with the agent. Defaults to None.\n            schemas_folder (Union[List[str], str], optional): Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.\n            api_headers (Dict[str,Dict[str, str]], optional): Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n            api_params (Dict[str, Dict[str, str]], optional): Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n            metadata (Dict[str, str], optional): Metadata associated with the agent. Defaults to an empty dictionary.\n            model (str, optional): The model identifier for the OpenAI API. Defaults to \"gpt-4o\".\n            reasoning_effort (Literal[\"low\", \"medium\", \"high\"], optional): The reasoning effort for the model. Only for o-series models. Defaults to \"medium\".\n            validation_attempts (int, optional): Number of attempts to validate the response with response_validator function. Defaults to 1.\n            max_prompt_tokens (int, optional): Maximum number of tokens allowed in the prompt. Defaults to None.\n            max_completion_tokens (int, optional): Maximum number of tokens allowed in the completion. Defaults to None.\n            truncation_strategy (TruncationStrategy, optional): Truncation strategy for the OpenAI API. Defaults to None.\n            examples (List[Dict], optional): A list of example messages for the agent. Defaults to None.\n            file_search (FileSearchConfig, optional): A dictionary containing the file search tool configuration. Defaults to None.\n            parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n            refresh_from_id (bool, optional): Whether to load and update the agent from the OpenAI assistant ID when provided. Defaults to True.\n\n        This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.\n        \"\"\"\n        # public attributes\n        self.id = id\n        self.name = name if name else self.__class__.__name__\n        self.description = description\n        self.instructions = instructions\n        self.tools = tools[:] if tools is not None else []\n        self.tools = [tool for tool in self.tools if tool.__name__ != \"ExampleTool\"]\n        self.tool_resources = tool_resources\n        self.temperature = temperature\n        self.top_p = top_p\n        self.response_format = response_format\n        # use structured outputs if response_format is a BaseModel\n        if isinstance(self.response_format, type):\n            self.response_format = type_to_response_format_param(self.response_format)\n        self.tools_folder = tools_folder\n        self.files_folder = files_folder if files_folder else []\n        self.schemas_folder = schemas_folder if schemas_folder else []\n        self.api_headers = api_headers if api_headers else {}\n        self.api_params = api_params if api_params else {}\n        self.metadata = metadata if metadata else {}\n        self.model = model\n        self.reasoning_effort = reasoning_effort\n        self.validation_attempts = validation_attempts\n        self.max_prompt_tokens = max_prompt_tokens\n        self.max_completion_tokens = max_completion_tokens\n        self.truncation_strategy = truncation_strategy\n        self.examples = examples\n        self.file_search = file_search\n        self.parallel_tool_calls = parallel_tool_calls\n        self.refresh_from_id = refresh_from_id\n\n        self.settings_path = \"./settings.json\"\n\n        # private attributes\n        self._assistant: Any = None\n        self._shared_instructions = None\n\n        # init methods\n        self.client = get_openai_client()\n        self._read_instructions()\n\n        # upload files\n        self._upload_files()\n        if file_ids:\n            print(\n                \"Warning: 'file_ids' parameter is deprecated. Please use 'tool_resources' parameter instead.\"\n            )\n            self.add_file_ids(file_ids, \"file_search\")\n\n        self._parse_schemas()\n        self._parse_tools_folder()\n\n    # --- OpenAI Assistant Methods ---\n\n    def init_oai(self):\n        \"\"\"\n        Initializes the OpenAI assistant for the agent.\n\n        This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.\n\n        Output:\n            self: Returns the agent instance for chaining methods or further processing.\n        \"\"\"\n\n        # check if settings.json exists\n        path = self.get_settings_path()\n\n        # load assistant from id\n        if self.id:\n            if not self.refresh_from_id:\n                return self\n\n            self.assistant = self.client.beta.assistants.retrieve(self.id)\n            # Assign attributes to self if they are None\n            self.instructions = self.instructions or self.assistant.instructions\n            self.name = (\n                self.name\n                if self.name != self.__class__.__name__\n                else self.assistant.name\n            )\n            self.description = self.description or self.assistant.description\n            self.temperature = (\n                self.assistant.temperature\n                if self.temperature is None\n                else self.temperature\n            )\n            self.top_p = self.top_p or self.assistant.top_p\n            self.response_format = (\n                self.response_format or self.assistant.response_format\n            )\n            if not isinstance(self.response_format, str):\n                self.response_format = (\n                    self.response_format or self.response_format.model_dump()\n                )\n            else:\n                self.response_format = (\n                    self.response_format or self.assistant.response_format\n                )\n            self.tool_resources = (\n                self.tool_resources or self.assistant.tool_resources.model_dump()\n            )\n            self.metadata = self.metadata or self.assistant.metadata\n            self.model = self.model or self.assistant.model\n            self.tool_resources = (\n                self.tool_resources or self.assistant.tool_resources.model_dump()\n            )\n\n            for tool in self.assistant.tools:\n                # update assistants created with v1\n                if tool.type == \"retrieval\":\n                    self.client.beta.assistants.update(\n                        self.id, tools=self.get_oai_tools()\n                    )\n\n            # update assistant if parameters are different\n            if not self._check_parameters(self.assistant.model_dump()):\n                self._update_assistant()\n\n            return self\n\n        # load assistant from settings\n        if os.path.exists(path):\n            with open(path, \"r\") as f:\n                settings = json.load(f)\n                # iterate settings and find the assistant with the same name\n                for assistant_settings in settings:\n                    if assistant_settings[\"name\"] == self.name:\n                        try:\n                            self.assistant = self.client.beta.assistants.retrieve(\n                                assistant_settings[\"id\"]\n                            )\n                            self.id = assistant_settings[\"id\"]\n\n                            # update assistant if parameters are different\n                            if not self._check_parameters(self.assistant.model_dump()):\n                                print(\"Updating agent... \" + self.name)\n                                self._update_assistant()\n\n                            if self.assistant.tool_resources:\n                                self.tool_resources = (\n                                    self.assistant.tool_resources.model_dump()\n                                )\n\n                            self._update_settings()\n                            return self\n                        except NotFoundError:\n                            continue\n\n        # create assistant if settings.json does not exist or assistant with the same name does not exist\n        self.assistant = self._create_assistant()\n\n        if self.assistant.tool_resources:\n            self.tool_resources = self.assistant.tool_resources.model_dump()\n\n        self.id = self.assistant.id\n\n        self._save_settings()\n\n        return self\n\n    def _create_assistant(self):\n        \"\"\"Creates a new OpenAI assistant with the agent's current configuration.\"\"\"\n        params = {\n            \"model\": self.model,\n            \"name\": self.name,\n            \"description\": self.description,\n            \"instructions\": self.instructions,\n            \"tools\": self.get_oai_tools(),\n            \"tool_resources\": self.tool_resources,\n            \"metadata\": self.metadata,\n            \"temperature\": self.temperature,\n            \"top_p\": self.top_p,\n            \"response_format\": self.response_format,\n        }\n\n        extra_body = {}\n\n        # o-series models\n        if params['model'].startswith('o'):\n            params['temperature'] = None\n            params['top_p'] = None\n            extra_body['reasoning_effort'] = self.reasoning_effort\n\n        return self.client.beta.assistants.create(\n            **params,\n            extra_body=extra_body\n        )\n\n        if self.assistant.tool_resources:\n            self.tool_resources = self.assistant.tool_resources.model_dump()\n\n        self.id = self.assistant.id\n\n        self._save_settings()\n\n        return self\n\n    def _update_assistant(self):\n        \"\"\"\n        Updates the existing assistant's parameters on the OpenAI server.\n\n        This method updates the assistant's details such as name, description, instructions, tools, file IDs, metadata, and the model. It only updates parameters that have non-empty values. After updating the assistant, it also updates the local settings file to reflect these changes.\n\n        No input parameters are directly passed to this method as it uses the agent's instance attributes.\n\n        No output parameters are returned, but the method updates the assistant's details on the OpenAI server and locally updates the settings file.\n        \"\"\"\n        tool_resources = copy.deepcopy(self.tool_resources)\n        if tool_resources and tool_resources.get(\"file_search\"):\n            tool_resources[\"file_search\"].pop(\"vector_stores\", None)\n\n        params = {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"instructions\": self.instructions,\n            \"tools\": self.get_oai_tools(),\n            \"tool_resources\": tool_resources,\n            \"temperature\": self.temperature,\n            \"top_p\": self.top_p,\n            \"response_format\": self.response_format,\n            \"metadata\": self.metadata,\n            \"model\": self.model,\n        }\n\n        extra_body = {}\n\n        # o-series models\n        if params['model'].startswith('o'):\n            params['temperature'] = None \n            params['top_p'] = None \n            extra_body['reasoning_effort'] = self.reasoning_effort\n\n        self.assistant = self.client.beta.assistants.update(\n            self.id,\n            **params,\n            extra_body=extra_body\n        )\n\n        self._update_settings()\n\n    def _upload_files(self):\n        def add_id_to_file(f_path, id):\n            \"\"\"Add file id to file name\"\"\"\n            if os.path.isfile(f_path):\n                file_name, file_ext = os.path.splitext(f_path)\n                f_path_new = file_name + \"_\" + id + file_ext\n                os.rename(f_path, f_path_new)\n                return f_path_new\n\n        def get_id_from_file(f_path):\n            \"\"\"Get file id from file name\"\"\"\n            if os.path.isfile(f_path):\n                file_name, file_ext = os.path.splitext(f_path)\n                file_name = os.path.basename(file_name)\n                file_name = file_name.split(\"_\")\n                if len(file_name) &gt; 1:\n                    return file_name[-1] if \"file-\" in file_name[-1] else None\n                else:\n                    return None\n\n        files_folders = (\n            self.files_folder\n            if isinstance(self.files_folder, list)\n            else [self.files_folder]\n        )\n\n        file_search_ids = []\n        code_interpreter_ids = []\n\n        for files_folder in files_folders:\n            if isinstance(files_folder, str):\n                f_path = files_folder\n\n                if not os.path.isdir(f_path):\n                    f_path = os.path.join(self.get_class_folder_path(), files_folder)\n                    f_path = os.path.normpath(f_path)\n\n                if os.path.isdir(f_path):\n                    f_paths = os.listdir(f_path)\n\n                    f_paths = [f for f in f_paths if not f.startswith(\".\")]\n\n                    f_paths = [os.path.join(f_path, f) for f in f_paths]\n\n                    code_interpreter_file_extensions = [\n                        \".json\",  # JSON\n                        \".csv\",  # CSV\n                        \".xml\",  # XML\n                        \".jpeg\",  # JPEG\n                        \".jpg\",  # JPEG\n                        \".gif\",  # GIF\n                        \".png\",  # PNG\n                        \".zip\",  # ZIP\n                    ]\n\n                    for f_path in f_paths:\n                        file_ext = os.path.splitext(f_path)[1]\n\n                        f_path = f_path.strip()\n                        file_id = get_id_from_file(f_path)\n                        if file_id:\n                            print(\n                                \"File already uploaded. Skipping... \"\n                                + os.path.basename(f_path)\n                            )\n                        else:\n                            print(\"Uploading new file... \" + os.path.basename(f_path))\n                            with open(f_path, \"rb\") as f:\n                                file_id = (\n                                    self.client.with_options(\n                                        timeout=80 * 1000,\n                                    )\n                                    .files.create(file=f, purpose=\"assistants\")\n                                    .id\n                                )\n                                f.close()  # fix permission error on windows\n                            add_id_to_file(f_path, file_id)\n\n                        if file_ext in code_interpreter_file_extensions:\n                            code_interpreter_ids.append(file_id)\n                        else:\n                            file_search_ids.append(file_id)\n                else:\n                    print(\n                        f\"Files folder '{f_path}' is not a directory. Skipping...\",\n                    )\n            else:\n                print(\n                    \"Files folder path must be a string or list of strings. Skipping... \",\n                    files_folder,\n                )\n\n        if FileSearch not in self.tools and file_search_ids:\n            print(\"Detected files without FileSearch. Adding FileSearch tool...\")\n            self.add_tool(FileSearch)\n        if CodeInterpreter not in self.tools and code_interpreter_ids:\n            print(\n                \"Detected files without CodeInterpreter. Adding CodeInterpreter tool...\"\n            )\n            self.add_tool(CodeInterpreter)\n\n        self.add_file_ids(file_search_ids, \"file_search\")\n        self.add_file_ids(code_interpreter_ids, \"code_interpreter\")\n\n    # --- Tool Methods ---\n\n    # TODO: fix 2 methods below\n    def add_tool(self, tool):\n        if not isinstance(tool, type):\n            raise Exception(\"Tool must not be initialized.\")\n\n        subclasses = [FileSearch, CodeInterpreter, Retrieval]\n        for subclass in subclasses:\n            if issubclass(tool, subclass):\n                if not any(issubclass(t, subclass) for t in self.tools):\n                    self.tools.append(tool)\n                return\n\n        if issubclass(tool, BaseTool):\n            if tool.__name__ == \"ExampleTool\":\n                print(\"Skipping importing ExampleTool...\")\n                return\n            self.tools = [t for t in self.tools if t.__name__ != tool.__name__]\n            self.tools.append(tool)\n        else:\n            raise Exception(\"Invalid tool type.\")\n\n    def get_oai_tools(self):\n        tools = []\n        for tool in self.tools:\n            if not isinstance(tool, type):\n                print(tool)\n                raise Exception(\"Tool must not be initialized.\")\n\n            if issubclass(tool, FileSearch):\n                tools.append(\n                    tool(file_search=self.file_search).model_dump(exclude_none=True)\n                )\n            elif issubclass(tool, CodeInterpreter):\n                tools.append(tool().model_dump())\n            elif issubclass(tool, Retrieval):\n                tools.append(tool().model_dump())\n            elif issubclass(tool, BaseTool):\n                tools.append({\"type\": \"function\", \"function\": tool.openai_schema})\n            else:\n                raise Exception(\"Invalid tool type.\")\n        return tools\n\n    def _parse_schemas(self):\n        schemas_folders = (\n            self.schemas_folder\n            if isinstance(self.schemas_folder, list)\n            else [self.schemas_folder]\n        )\n\n        for schemas_folder in schemas_folders:\n            if isinstance(schemas_folder, str):\n                f_path = schemas_folder\n\n                if not os.path.isdir(f_path):\n                    f_path = os.path.join(self.get_class_folder_path(), schemas_folder)\n                    f_path = os.path.normpath(f_path)\n\n                if os.path.isdir(f_path):\n                    f_paths = os.listdir(f_path)\n\n                    f_paths = [f for f in f_paths if not f.startswith(\".\")]\n\n                    f_paths = [os.path.join(f_path, f) for f in f_paths]\n\n                    for f_path in f_paths:\n                        with open(f_path, \"r\") as f:\n                            openapi_spec = f.read()\n                            f.close()  # fix permission error on windows\n                        try:\n                            validate_openapi_spec(openapi_spec)\n                        except Exception as e:\n                            print(\"Invalid OpenAPI schema: \" + os.path.basename(f_path))\n                            raise e\n                        try:\n                            headers = None\n                            params = None\n                            if os.path.basename(f_path) in self.api_headers:\n                                headers = self.api_headers[os.path.basename(f_path)]\n                            if os.path.basename(f_path) in self.api_params:\n                                params = self.api_params[os.path.basename(f_path)]\n                            tools = ToolFactory.from_openapi_schema(\n                                openapi_spec, headers=headers, params=params\n                            )\n                        except Exception as e:\n                            print(\n                                \"Error parsing OpenAPI schema: \"\n                                + os.path.basename(f_path)\n                            )\n                            raise e\n                        for tool in tools:\n                            self.add_tool(tool)\n                else:\n                    print(\n                        \"Schemas folder path is not a directory. Skipping... \", f_path\n                    )\n            else:\n                print(\n                    \"Schemas folder path must be a string or list of strings. Skipping... \",\n                    schemas_folder,\n                )\n\n    def _parse_tools_folder(self):\n        if not self.tools_folder:\n            return\n\n        if not os.path.isdir(self.tools_folder):\n            self.tools_folder = os.path.join(\n                self.get_class_folder_path(), self.tools_folder\n            )\n            self.tools_folder = os.path.normpath(self.tools_folder)\n\n        if os.path.isdir(self.tools_folder):\n            f_paths = os.listdir(self.tools_folder)\n            f_paths = [\n                f for f in f_paths if not f.startswith(\".\") and not f.startswith(\"__\")\n            ]\n            f_paths = [os.path.join(self.tools_folder, f) for f in f_paths]\n            for f_path in f_paths:\n                if not f_path.endswith(\".py\"):\n                    continue\n                if os.path.isfile(f_path):\n                    try:\n                        tool = ToolFactory.from_file(f_path)\n                        self.add_tool(tool)\n                    except Exception as e:\n                        print(\n                            f\"Error parsing tool file {os.path.basename(f_path)}: {e}. Skipping...\"\n                        )\n                else:\n                    print(\"Items in tools folder must be files. Skipping... \", f_path)\n        else:\n            print(\n                \"Tools folder path is not a directory. Skipping... \", self.tools_folder\n            )\n\n    def get_openapi_schema(self, url):\n        \"\"\"Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized.\"\"\"\n        if self.assistant is None:\n            raise Exception(\n                \"Assistant is not initialized. Please initialize the agency first, before using this method\"\n            )\n\n        return ToolFactory.get_openapi_schema(self.tools, url)\n\n    # --- Settings Methods ---\n\n    def _check_parameters(self, assistant_settings, debug=False):\n        \"\"\"\n        Checks if the agent's parameters match with the given assistant settings.\n\n        Parameters:\n            assistant_settings (dict): A dictionary containing the settings of an assistant.\n            debug (bool): If True, prints debug statements. Default is False.\n\n        Returns:\n            bool: True if all the agent's parameters match the assistant settings, False otherwise.\n\n        This method compares the current agent's parameters such as name, description, instructions, tools, file IDs, metadata, and model with the given assistant settings. It uses DeepDiff to compare complex structures like tools and metadata. If any parameter does not match, it returns False; otherwise, it returns True.\n        \"\"\"\n        if self.name != assistant_settings[\"name\"]:\n            if debug:\n                print(f\"Name mismatch: {self.name} != {assistant_settings['name']}\")\n            return False\n\n        if self.description != assistant_settings[\"description\"]:\n            if debug:\n                print(\n                    f\"Description mismatch: {self.description} != {assistant_settings['description']}\"\n                )\n            return False\n\n        if self.instructions != assistant_settings[\"instructions\"]:\n            if debug:\n                print(\n                    f\"Instructions mismatch: {self.instructions} != {assistant_settings['instructions']}\"\n                )\n            return False\n\n        def clean_tool(tool):\n            if isinstance(tool, dict):\n                if (\n                    \"function\" in tool\n                    and \"strict\" in tool[\"function\"]\n                    and not tool[\"function\"][\"strict\"]\n                ):\n                    tool[\"function\"].pop(\"strict\", None)\n            return tool\n\n        local_tools = [clean_tool(tool) for tool in self.get_oai_tools()]\n        assistant_tools = [clean_tool(tool) for tool in assistant_settings[\"tools\"]]\n\n        # find file_search and code_interpreter tools in local_tools and assistant_tools\n        # Find file_search tools in local and assistant tools\n        local_file_search = next(\n            (tool for tool in local_tools if tool[\"type\"] == \"file_search\"), None\n        )\n        assistant_file_search = next(\n            (tool for tool in assistant_tools if tool[\"type\"] == \"file_search\"), None\n        )\n\n        if local_file_search:\n            # If local file_search doesn't have a 'file_search' key, use assistant's if available\n            if (\n                \"file_search\" not in local_file_search\n                and assistant_file_search\n                and \"file_search\" in assistant_file_search\n            ):\n                local_file_search[\"file_search\"] = assistant_file_search[\"file_search\"]\n            elif \"file_search\" in local_file_search:\n                # Update max_num_results if not set locally but available in assistant\n                if (\n                    \"max_num_results\" not in local_file_search[\"file_search\"]\n                    and assistant_file_search\n                    and assistant_file_search[\"file_search\"].get(\"max_num_results\")\n                    is not None\n                ):\n                    local_file_search[\"file_search\"][\"max_num_results\"] = (\n                        assistant_file_search[\"file_search\"][\"max_num_results\"]\n                    )\n\n                # Update ranking_options if not set locally but available in assistant\n                if (\n                    \"ranking_options\" not in local_file_search[\"file_search\"]\n                    and assistant_file_search\n                    and assistant_file_search[\"file_search\"].get(\"ranking_options\")\n                    is not None\n                ):\n                    local_file_search[\"file_search\"][\"ranking_options\"] = (\n                        assistant_file_search[\"file_search\"][\"ranking_options\"]\n                    )\n\n        local_tools.sort(key=lambda x: json.dumps(x, sort_keys=True))\n        assistant_tools.sort(key=lambda x: json.dumps(x, sort_keys=True))\n\n        tools_diff = DeepDiff(local_tools, assistant_tools, ignore_order=True)\n        if tools_diff:\n            if debug:\n                print(f\"Tools mismatch: {tools_diff}\")\n                print(\"Local tools:\", local_tools)\n                print(\"Assistant tools:\", assistant_tools)\n            return False\n\n        if self.temperature != assistant_settings[\"temperature\"]:\n            if debug:\n                print(\n                    f\"Temperature mismatch: {self.temperature} != {assistant_settings['temperature']}\"\n                )\n            return False\n\n        if self.top_p != assistant_settings[\"top_p\"]:\n            if debug:\n                print(f\"Top_p mismatch: {self.top_p} != {assistant_settings['top_p']}\")\n            return False\n\n        # adjust differences between local and assistant tool resources\n        tool_resources_settings = copy.deepcopy(self.tool_resources)\n        if tool_resources_settings is None:\n            tool_resources_settings = {}\n        if tool_resources_settings.get(\"file_search\"):\n            tool_resources_settings[\"file_search\"].pop(\"vector_stores\", None)\n        if tool_resources_settings.get(\"file_search\") is None:\n            tool_resources_settings[\"file_search\"] = {\"vector_store_ids\": []}\n        if tool_resources_settings.get(\"code_interpreter\") is None:\n            tool_resources_settings[\"code_interpreter\"] = {\"file_ids\": []}\n\n        assistant_tool_resources = assistant_settings[\"tool_resources\"]\n        if assistant_tool_resources is None:\n            assistant_tool_resources = {}\n        if assistant_tool_resources.get(\"code_interpreter\") is None:\n            assistant_tool_resources[\"code_interpreter\"] = {\"file_ids\": []}\n        if assistant_tool_resources.get(\"file_search\") is None:\n            assistant_tool_resources[\"file_search\"] = {\"vector_store_ids\": []}\n\n        tool_resources_diff = DeepDiff(\n            tool_resources_settings, assistant_tool_resources, ignore_order=True\n        )\n        if tool_resources_diff != {}:\n            if debug:\n                print(f\"Tool resources mismatch: {tool_resources_diff}\")\n                print(\"Local tool resources:\", tool_resources_settings)\n                print(\"Assistant tool resources:\", assistant_settings[\"tool_resources\"])\n            return False\n\n        metadata_diff = DeepDiff(\n            self.metadata, assistant_settings[\"metadata\"], ignore_order=True\n        )\n        if metadata_diff != {}:\n            if debug:\n                print(f\"Metadata mismatch: {metadata_diff}\")\n            return False\n\n        if self.model != assistant_settings[\"model\"]:\n            if debug:\n                print(f\"Model mismatch: {self.model} != {assistant_settings['model']}\")\n            return False\n\n        response_format_diff = DeepDiff(\n            self.response_format,\n            assistant_settings[\"response_format\"],\n            ignore_order=True,\n        )\n        if response_format_diff != {}:\n            if debug:\n                print(f\"Response format mismatch: {response_format_diff}\")\n            return False\n\n        return True\n\n    def _save_settings(self):\n        path = self.get_settings_path()\n        # check if settings.json exists\n        if not os.path.isfile(path):\n            with open(path, \"w\") as f:\n                json.dump([self.assistant.model_dump()], f, indent=4)\n        else:\n            settings = []\n            with open(path, \"r\") as f:\n                settings = json.load(f)\n                settings.append(self.assistant.model_dump())\n            with open(path, \"w\") as f:\n                json.dump(settings, f, indent=4)\n\n    def _update_settings(self):\n        path = self.get_settings_path()\n        # check if settings.json exists\n        if os.path.isfile(path):\n            settings = []\n            with open(path, \"r\") as f:\n                settings = json.load(f)\n                for i, assistant_settings in enumerate(settings):\n                    if assistant_settings[\"id\"] == self.id:\n                        settings[i] = self.assistant.model_dump()\n                        break\n            with open(path, \"w\") as f:\n                json.dump(settings, f, indent=4)\n\n    # --- Helper Methods ---\n\n    def add_file_ids(\n        self,\n        file_ids: List[str],\n        tool_resource: Literal[\"code_interpreter\", \"file_search\"],\n    ):\n        if not file_ids:\n            return\n\n        if self.tool_resources is None:\n            self.tool_resources = {}\n\n        if tool_resource == \"code_interpreter\":\n            if CodeInterpreter not in self.tools:\n                raise Exception(\"CodeInterpreter tool not found in tools.\")\n\n            if (\n                tool_resource not in self.tool_resources\n                or self.tool_resources[tool_resource] is None\n            ):\n                self.tool_resources[tool_resource] = {\"file_ids\": file_ids}\n\n            self.tool_resources[tool_resource][\"file_ids\"] = file_ids\n        elif tool_resource == \"file_search\":\n            if FileSearch not in self.tools:\n                raise Exception(\"FileSearch tool not found in tools.\")\n\n            if (\n                tool_resource not in self.tool_resources\n                or self.tool_resources[tool_resource] is None\n            ):\n                self.tool_resources[tool_resource] = {\n                    \"vector_stores\": [{\"file_ids\": file_ids}]\n                }\n            elif not self.tool_resources[tool_resource].get(\"vector_store_ids\"):\n                self.tool_resources[tool_resource][\"vector_stores\"] = [\n                    {\"file_ids\": file_ids}\n                ]\n            else:\n                vector_store_id = self.tool_resources[tool_resource][\n                    \"vector_store_ids\"\n                ][0]\n                self.client.beta.vector_stores.file_batches.create(\n                    vector_store_id=vector_store_id, file_ids=file_ids\n                )\n        else:\n            raise Exception(\"Invalid tool resource.\")\n\n    def get_settings_path(self):\n        return self.settings_path\n\n    def _read_instructions(self):\n        class_instructions_path = os.path.normpath(\n            os.path.join(self.get_class_folder_path(), self.instructions)\n        )\n        if os.path.isfile(class_instructions_path):\n            with open(class_instructions_path, \"r\") as f:\n                self.instructions = f.read()\n        elif os.path.isfile(self.instructions):\n            with open(self.instructions, \"r\") as f:\n                self.instructions = f.read()\n        elif (\n            \"./instructions.md\" in self.instructions\n            or \"./instructions.txt\" in self.instructions\n        ):\n            raise Exception(\"Instructions file not found.\")\n\n    def get_class_folder_path(self):\n        try:\n            # First, try to use the __file__ attribute of the module\n            return os.path.abspath(os.path.dirname(self.__module__.__file__))\n        except (TypeError, OSError, AttributeError) as e:\n            # If that fails, fall back to inspect\n            try:\n                class_file = inspect.getfile(self.__class__)\n            except (TypeError, OSError, AttributeError) as e:\n                return \"./\"\n            return os.path.abspath(os.path.realpath(os.path.dirname(class_file)))\n\n    def add_shared_instructions(self, instructions: str):\n        if not instructions:\n            return\n\n        if self._shared_instructions is None:\n            self._shared_instructions = instructions\n        else:\n            self.instructions = self.instructions.replace(self._shared_instructions, \"\")\n            self.instructions = self.instructions.strip().strip(\"\\n\")\n            self._shared_instructions = instructions\n\n        self.instructions = self._shared_instructions + \"\\n\\n\" + self.instructions\n\n    # --- Cleanup Methods ---\n    def delete(self):\n        \"\"\"Deletes assistant, all vector stores, and all files associated with the agent.\"\"\"\n        self._delete_assistant()\n        self._delete_files()\n        self._delete_settings()\n\n    def _delete_files(self):\n        if not self.tool_resources:\n            return\n\n        file_ids = []\n        if self.tool_resources.get(\"code_interpreter\"):\n            file_ids = self.tool_resources[\"code_interpreter\"].get(\"file_ids\", [])\n\n        if self.tool_resources.get(\"file_search\"):\n            file_search_vector_store_ids = self.tool_resources[\"file_search\"].get(\n                \"vector_store_ids\", []\n            )\n            for vector_store_id in file_search_vector_store_ids:\n                files = self.client.beta.vector_stores.files.list(\n                    vector_store_id=vector_store_id, limit=100\n                )\n                for file in files:\n                    file_ids.append(file.id)\n\n                self.client.beta.vector_stores.delete(vector_store_id)\n\n        for file_id in file_ids:\n            self.client.files.delete(file_id)\n\n    def _delete_assistant(self):\n        self.client.beta.assistants.delete(self.id)\n        self._delete_settings()\n\n    def _delete_settings(self):\n        path = self.get_settings_path()\n        # check if settings.json exists\n        if os.path.isfile(path):\n            settings = []\n            with open(path, \"r\") as f:\n                settings = json.load(f)\n                for i, assistant_settings in enumerate(settings):\n                    if assistant_settings[\"id\"] == self.id:\n                        settings.pop(i)\n                        break\n            with open(path, \"w\") as f:\n                json.dump(settings, f, indent=4)\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.__init__","title":"<code>__init__(id=None, name=None, description=None, instructions='', tools=None, tool_resources=None, temperature=None, top_p=None, response_format='auto', tools_folder=None, files_folder=None, schemas_folder=None, api_headers=None, api_params=None, file_ids=None, metadata=None, model='gpt-4o-2024-08-06', reasoning_effort='medium', validation_attempts=1, max_prompt_tokens=None, max_completion_tokens=None, truncation_strategy=None, examples=None, file_search=None, parallel_tool_calls=True, refresh_from_id=True)</code>","text":"<p>Initializes an Agent with specified attributes, tools, and OpenAI client.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.</p> <code>None</code> <code>name</code> <code>str</code> <p>Name of the agent. Defaults to the class name if not provided.</p> <code>None</code> <code>description</code> <code>str</code> <p>A brief description of the agent's purpose. Defaults to None.</p> <code>None</code> <code>instructions</code> <code>str</code> <p>Path to a file containing specific instructions for the agent. Defaults to an empty string.</p> <code>''</code> <code>tools</code> <code>List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]]</code> <p>A list of tools (as classes) that the agent can use. Defaults to an empty list.</p> <code>None</code> <code>tool_resources</code> <code>ToolResources</code> <p>A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.</p> <code>None</code> <code>temperature</code> <code>float</code> <p>The temperature parameter for the OpenAI API. Defaults to None.</p> <code>None</code> <code>top_p</code> <code>float</code> <p>The top_p parameter for the OpenAI API. Defaults to None.</p> <code>None</code> <code>response_format</code> <code>Union[str, Dict, type]</code> <p>The response format for the OpenAI API. If BaseModel is provided, it will be converted to a response format. Defaults to None.</p> <code>'auto'</code> <code>tools_folder</code> <code>str</code> <p>Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.</p> <code>None</code> <code>files_folder</code> <code>Union[List[str], str]</code> <p>Path or list of paths to directories containing files associated with the agent. Defaults to None.</p> <code>None</code> <code>schemas_folder</code> <code>Union[List[str], str]</code> <p>Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.</p> <code>None</code> <code>api_headers</code> <code>Dict[str, Dict[str, str]]</code> <p>Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.</p> <code>None</code> <code>api_params</code> <code>Dict[str, Dict[str, str]]</code> <p>Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.</p> <code>None</code> <code>metadata</code> <code>Dict[str, str]</code> <p>Metadata associated with the agent. Defaults to an empty dictionary.</p> <code>None</code> <code>model</code> <code>str</code> <p>The model identifier for the OpenAI API. Defaults to \"gpt-4o\".</p> <code>'gpt-4o-2024-08-06'</code> <code>reasoning_effort</code> <code>Literal['low', 'medium', 'high']</code> <p>The reasoning effort for the model. Only for o-series models. Defaults to \"medium\".</p> <code>'medium'</code> <code>validation_attempts</code> <code>int</code> <p>Number of attempts to validate the response with response_validator function. Defaults to 1.</p> <code>1</code> <code>max_prompt_tokens</code> <code>int</code> <p>Maximum number of tokens allowed in the prompt. Defaults to None.</p> <code>None</code> <code>max_completion_tokens</code> <code>int</code> <p>Maximum number of tokens allowed in the completion. Defaults to None.</p> <code>None</code> <code>truncation_strategy</code> <code>TruncationStrategy</code> <p>Truncation strategy for the OpenAI API. Defaults to None.</p> <code>None</code> <code>examples</code> <code>List[Dict]</code> <p>A list of example messages for the agent. Defaults to None.</p> <code>None</code> <code>file_search</code> <code>FileSearchConfig</code> <p>A dictionary containing the file search tool configuration. Defaults to None.</p> <code>None</code> <code>parallel_tool_calls</code> <code>bool</code> <p>Whether to enable parallel function calling during tool use. Defaults to True.</p> <code>True</code> <code>refresh_from_id</code> <code>bool</code> <p>Whether to load and update the agent from the OpenAI assistant ID when provided. Defaults to True.</p> <code>True</code> <p>This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def __init__(\n    self,\n    id: str = None,\n    name: str = None,\n    description: str = None,\n    instructions: str = \"\",\n    tools: List[\n        Union[\n            Type[BaseTool], Type[FileSearch], Type[CodeInterpreter], type[Retrieval]\n        ]\n    ] = None,\n    tool_resources: ToolResources = None,\n    temperature: float = None,\n    top_p: float = None,\n    response_format: Union[str, dict, type] = \"auto\",\n    tools_folder: str = None,\n    files_folder: Union[List[str], str] = None,\n    schemas_folder: Union[List[str], str] = None,\n    api_headers: Dict[str, Dict[str, str]] = None,\n    api_params: Dict[str, Dict[str, str]] = None,\n    file_ids: List[str] = None,\n    metadata: Dict[str, str] = None,\n    model: str = \"gpt-4o-2024-08-06\",\n    reasoning_effort: Literal[\"low\", \"medium\", \"high\"] = \"medium\",\n    validation_attempts: int = 1,\n    max_prompt_tokens: int = None,\n    max_completion_tokens: int = None,\n    truncation_strategy: dict = None,\n    examples: List[ExampleMessage] = None,\n    file_search: FileSearchConfig = None,\n    parallel_tool_calls: bool = True,\n    refresh_from_id: bool = True,\n):\n    \"\"\"\n    Initializes an Agent with specified attributes, tools, and OpenAI client.\n\n    Parameters:\n        id (str, optional): Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.\n        name (str, optional): Name of the agent. Defaults to the class name if not provided.\n        description (str, optional): A brief description of the agent's purpose. Defaults to None.\n        instructions (str, optional): Path to a file containing specific instructions for the agent. Defaults to an empty string.\n        tools (List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]], optional): A list of tools (as classes) that the agent can use. Defaults to an empty list.\n        tool_resources (ToolResources, optional): A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.\n        temperature (float, optional): The temperature parameter for the OpenAI API. Defaults to None.\n        top_p (float, optional): The top_p parameter for the OpenAI API. Defaults to None.\n        response_format (Union[str, Dict, type], optional): The response format for the OpenAI API. If BaseModel is provided, it will be converted to a response format. Defaults to None.\n        tools_folder (str, optional): Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.\n        files_folder (Union[List[str], str], optional): Path or list of paths to directories containing files associated with the agent. Defaults to None.\n        schemas_folder (Union[List[str], str], optional): Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.\n        api_headers (Dict[str,Dict[str, str]], optional): Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n        api_params (Dict[str, Dict[str, str]], optional): Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.\n        metadata (Dict[str, str], optional): Metadata associated with the agent. Defaults to an empty dictionary.\n        model (str, optional): The model identifier for the OpenAI API. Defaults to \"gpt-4o\".\n        reasoning_effort (Literal[\"low\", \"medium\", \"high\"], optional): The reasoning effort for the model. Only for o-series models. Defaults to \"medium\".\n        validation_attempts (int, optional): Number of attempts to validate the response with response_validator function. Defaults to 1.\n        max_prompt_tokens (int, optional): Maximum number of tokens allowed in the prompt. Defaults to None.\n        max_completion_tokens (int, optional): Maximum number of tokens allowed in the completion. Defaults to None.\n        truncation_strategy (TruncationStrategy, optional): Truncation strategy for the OpenAI API. Defaults to None.\n        examples (List[Dict], optional): A list of example messages for the agent. Defaults to None.\n        file_search (FileSearchConfig, optional): A dictionary containing the file search tool configuration. Defaults to None.\n        parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n        refresh_from_id (bool, optional): Whether to load and update the agent from the OpenAI assistant ID when provided. Defaults to True.\n\n    This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.\n    \"\"\"\n    # public attributes\n    self.id = id\n    self.name = name if name else self.__class__.__name__\n    self.description = description\n    self.instructions = instructions\n    self.tools = tools[:] if tools is not None else []\n    self.tools = [tool for tool in self.tools if tool.__name__ != \"ExampleTool\"]\n    self.tool_resources = tool_resources\n    self.temperature = temperature\n    self.top_p = top_p\n    self.response_format = response_format\n    # use structured outputs if response_format is a BaseModel\n    if isinstance(self.response_format, type):\n        self.response_format = type_to_response_format_param(self.response_format)\n    self.tools_folder = tools_folder\n    self.files_folder = files_folder if files_folder else []\n    self.schemas_folder = schemas_folder if schemas_folder else []\n    self.api_headers = api_headers if api_headers else {}\n    self.api_params = api_params if api_params else {}\n    self.metadata = metadata if metadata else {}\n    self.model = model\n    self.reasoning_effort = reasoning_effort\n    self.validation_attempts = validation_attempts\n    self.max_prompt_tokens = max_prompt_tokens\n    self.max_completion_tokens = max_completion_tokens\n    self.truncation_strategy = truncation_strategy\n    self.examples = examples\n    self.file_search = file_search\n    self.parallel_tool_calls = parallel_tool_calls\n    self.refresh_from_id = refresh_from_id\n\n    self.settings_path = \"./settings.json\"\n\n    # private attributes\n    self._assistant: Any = None\n    self._shared_instructions = None\n\n    # init methods\n    self.client = get_openai_client()\n    self._read_instructions()\n\n    # upload files\n    self._upload_files()\n    if file_ids:\n        print(\n            \"Warning: 'file_ids' parameter is deprecated. Please use 'tool_resources' parameter instead.\"\n        )\n        self.add_file_ids(file_ids, \"file_search\")\n\n    self._parse_schemas()\n    self._parse_tools_folder()\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent._check_parameters","title":"<code>_check_parameters(assistant_settings, debug=False)</code>","text":"<p>Checks if the agent's parameters match with the given assistant settings.</p> <p>Parameters:</p> Name Type Description Default <code>assistant_settings</code> <code>dict</code> <p>A dictionary containing the settings of an assistant.</p> required <code>debug</code> <code>bool</code> <p>If True, prints debug statements. Default is False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all the agent's parameters match the assistant settings, False otherwise.</p> <p>This method compares the current agent's parameters such as name, description, instructions, tools, file IDs, metadata, and model with the given assistant settings. It uses DeepDiff to compare complex structures like tools and metadata. If any parameter does not match, it returns False; otherwise, it returns True.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def _check_parameters(self, assistant_settings, debug=False):\n    \"\"\"\n    Checks if the agent's parameters match with the given assistant settings.\n\n    Parameters:\n        assistant_settings (dict): A dictionary containing the settings of an assistant.\n        debug (bool): If True, prints debug statements. Default is False.\n\n    Returns:\n        bool: True if all the agent's parameters match the assistant settings, False otherwise.\n\n    This method compares the current agent's parameters such as name, description, instructions, tools, file IDs, metadata, and model with the given assistant settings. It uses DeepDiff to compare complex structures like tools and metadata. If any parameter does not match, it returns False; otherwise, it returns True.\n    \"\"\"\n    if self.name != assistant_settings[\"name\"]:\n        if debug:\n            print(f\"Name mismatch: {self.name} != {assistant_settings['name']}\")\n        return False\n\n    if self.description != assistant_settings[\"description\"]:\n        if debug:\n            print(\n                f\"Description mismatch: {self.description} != {assistant_settings['description']}\"\n            )\n        return False\n\n    if self.instructions != assistant_settings[\"instructions\"]:\n        if debug:\n            print(\n                f\"Instructions mismatch: {self.instructions} != {assistant_settings['instructions']}\"\n            )\n        return False\n\n    def clean_tool(tool):\n        if isinstance(tool, dict):\n            if (\n                \"function\" in tool\n                and \"strict\" in tool[\"function\"]\n                and not tool[\"function\"][\"strict\"]\n            ):\n                tool[\"function\"].pop(\"strict\", None)\n        return tool\n\n    local_tools = [clean_tool(tool) for tool in self.get_oai_tools()]\n    assistant_tools = [clean_tool(tool) for tool in assistant_settings[\"tools\"]]\n\n    # find file_search and code_interpreter tools in local_tools and assistant_tools\n    # Find file_search tools in local and assistant tools\n    local_file_search = next(\n        (tool for tool in local_tools if tool[\"type\"] == \"file_search\"), None\n    )\n    assistant_file_search = next(\n        (tool for tool in assistant_tools if tool[\"type\"] == \"file_search\"), None\n    )\n\n    if local_file_search:\n        # If local file_search doesn't have a 'file_search' key, use assistant's if available\n        if (\n            \"file_search\" not in local_file_search\n            and assistant_file_search\n            and \"file_search\" in assistant_file_search\n        ):\n            local_file_search[\"file_search\"] = assistant_file_search[\"file_search\"]\n        elif \"file_search\" in local_file_search:\n            # Update max_num_results if not set locally but available in assistant\n            if (\n                \"max_num_results\" not in local_file_search[\"file_search\"]\n                and assistant_file_search\n                and assistant_file_search[\"file_search\"].get(\"max_num_results\")\n                is not None\n            ):\n                local_file_search[\"file_search\"][\"max_num_results\"] = (\n                    assistant_file_search[\"file_search\"][\"max_num_results\"]\n                )\n\n            # Update ranking_options if not set locally but available in assistant\n            if (\n                \"ranking_options\" not in local_file_search[\"file_search\"]\n                and assistant_file_search\n                and assistant_file_search[\"file_search\"].get(\"ranking_options\")\n                is not None\n            ):\n                local_file_search[\"file_search\"][\"ranking_options\"] = (\n                    assistant_file_search[\"file_search\"][\"ranking_options\"]\n                )\n\n    local_tools.sort(key=lambda x: json.dumps(x, sort_keys=True))\n    assistant_tools.sort(key=lambda x: json.dumps(x, sort_keys=True))\n\n    tools_diff = DeepDiff(local_tools, assistant_tools, ignore_order=True)\n    if tools_diff:\n        if debug:\n            print(f\"Tools mismatch: {tools_diff}\")\n            print(\"Local tools:\", local_tools)\n            print(\"Assistant tools:\", assistant_tools)\n        return False\n\n    if self.temperature != assistant_settings[\"temperature\"]:\n        if debug:\n            print(\n                f\"Temperature mismatch: {self.temperature} != {assistant_settings['temperature']}\"\n            )\n        return False\n\n    if self.top_p != assistant_settings[\"top_p\"]:\n        if debug:\n            print(f\"Top_p mismatch: {self.top_p} != {assistant_settings['top_p']}\")\n        return False\n\n    # adjust differences between local and assistant tool resources\n    tool_resources_settings = copy.deepcopy(self.tool_resources)\n    if tool_resources_settings is None:\n        tool_resources_settings = {}\n    if tool_resources_settings.get(\"file_search\"):\n        tool_resources_settings[\"file_search\"].pop(\"vector_stores\", None)\n    if tool_resources_settings.get(\"file_search\") is None:\n        tool_resources_settings[\"file_search\"] = {\"vector_store_ids\": []}\n    if tool_resources_settings.get(\"code_interpreter\") is None:\n        tool_resources_settings[\"code_interpreter\"] = {\"file_ids\": []}\n\n    assistant_tool_resources = assistant_settings[\"tool_resources\"]\n    if assistant_tool_resources is None:\n        assistant_tool_resources = {}\n    if assistant_tool_resources.get(\"code_interpreter\") is None:\n        assistant_tool_resources[\"code_interpreter\"] = {\"file_ids\": []}\n    if assistant_tool_resources.get(\"file_search\") is None:\n        assistant_tool_resources[\"file_search\"] = {\"vector_store_ids\": []}\n\n    tool_resources_diff = DeepDiff(\n        tool_resources_settings, assistant_tool_resources, ignore_order=True\n    )\n    if tool_resources_diff != {}:\n        if debug:\n            print(f\"Tool resources mismatch: {tool_resources_diff}\")\n            print(\"Local tool resources:\", tool_resources_settings)\n            print(\"Assistant tool resources:\", assistant_settings[\"tool_resources\"])\n        return False\n\n    metadata_diff = DeepDiff(\n        self.metadata, assistant_settings[\"metadata\"], ignore_order=True\n    )\n    if metadata_diff != {}:\n        if debug:\n            print(f\"Metadata mismatch: {metadata_diff}\")\n        return False\n\n    if self.model != assistant_settings[\"model\"]:\n        if debug:\n            print(f\"Model mismatch: {self.model} != {assistant_settings['model']}\")\n        return False\n\n    response_format_diff = DeepDiff(\n        self.response_format,\n        assistant_settings[\"response_format\"],\n        ignore_order=True,\n    )\n    if response_format_diff != {}:\n        if debug:\n            print(f\"Response format mismatch: {response_format_diff}\")\n        return False\n\n    return True\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent._create_assistant","title":"<code>_create_assistant()</code>","text":"<p>Creates a new OpenAI assistant with the agent's current configuration.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def _create_assistant(self):\n    \"\"\"Creates a new OpenAI assistant with the agent's current configuration.\"\"\"\n    params = {\n        \"model\": self.model,\n        \"name\": self.name,\n        \"description\": self.description,\n        \"instructions\": self.instructions,\n        \"tools\": self.get_oai_tools(),\n        \"tool_resources\": self.tool_resources,\n        \"metadata\": self.metadata,\n        \"temperature\": self.temperature,\n        \"top_p\": self.top_p,\n        \"response_format\": self.response_format,\n    }\n\n    extra_body = {}\n\n    # o-series models\n    if params['model'].startswith('o'):\n        params['temperature'] = None\n        params['top_p'] = None\n        extra_body['reasoning_effort'] = self.reasoning_effort\n\n    return self.client.beta.assistants.create(\n        **params,\n        extra_body=extra_body\n    )\n\n    if self.assistant.tool_resources:\n        self.tool_resources = self.assistant.tool_resources.model_dump()\n\n    self.id = self.assistant.id\n\n    self._save_settings()\n\n    return self\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent._update_assistant","title":"<code>_update_assistant()</code>","text":"<p>Updates the existing assistant's parameters on the OpenAI server.</p> <p>This method updates the assistant's details such as name, description, instructions, tools, file IDs, metadata, and the model. It only updates parameters that have non-empty values. After updating the assistant, it also updates the local settings file to reflect these changes.</p> <p>No input parameters are directly passed to this method as it uses the agent's instance attributes.</p> <p>No output parameters are returned, but the method updates the assistant's details on the OpenAI server and locally updates the settings file.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def _update_assistant(self):\n    \"\"\"\n    Updates the existing assistant's parameters on the OpenAI server.\n\n    This method updates the assistant's details such as name, description, instructions, tools, file IDs, metadata, and the model. It only updates parameters that have non-empty values. After updating the assistant, it also updates the local settings file to reflect these changes.\n\n    No input parameters are directly passed to this method as it uses the agent's instance attributes.\n\n    No output parameters are returned, but the method updates the assistant's details on the OpenAI server and locally updates the settings file.\n    \"\"\"\n    tool_resources = copy.deepcopy(self.tool_resources)\n    if tool_resources and tool_resources.get(\"file_search\"):\n        tool_resources[\"file_search\"].pop(\"vector_stores\", None)\n\n    params = {\n        \"name\": self.name,\n        \"description\": self.description,\n        \"instructions\": self.instructions,\n        \"tools\": self.get_oai_tools(),\n        \"tool_resources\": tool_resources,\n        \"temperature\": self.temperature,\n        \"top_p\": self.top_p,\n        \"response_format\": self.response_format,\n        \"metadata\": self.metadata,\n        \"model\": self.model,\n    }\n\n    extra_body = {}\n\n    # o-series models\n    if params['model'].startswith('o'):\n        params['temperature'] = None \n        params['top_p'] = None \n        extra_body['reasoning_effort'] = self.reasoning_effort\n\n    self.assistant = self.client.beta.assistants.update(\n        self.id,\n        **params,\n        extra_body=extra_body\n    )\n\n    self._update_settings()\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.delete","title":"<code>delete()</code>","text":"<p>Deletes assistant, all vector stores, and all files associated with the agent.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def delete(self):\n    \"\"\"Deletes assistant, all vector stores, and all files associated with the agent.\"\"\"\n    self._delete_assistant()\n    self._delete_files()\n    self._delete_settings()\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.get_openapi_schema","title":"<code>get_openapi_schema(url)</code>","text":"<p>Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def get_openapi_schema(self, url):\n    \"\"\"Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized.\"\"\"\n    if self.assistant is None:\n        raise Exception(\n            \"Assistant is not initialized. Please initialize the agency first, before using this method\"\n        )\n\n    return ToolFactory.get_openapi_schema(self.tools, url)\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.init_oai","title":"<code>init_oai()</code>","text":"<p>Initializes the OpenAI assistant for the agent.</p> <p>This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.</p> Output <p>self: Returns the agent instance for chaining methods or further processing.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def init_oai(self):\n    \"\"\"\n    Initializes the OpenAI assistant for the agent.\n\n    This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.\n\n    Output:\n        self: Returns the agent instance for chaining methods or further processing.\n    \"\"\"\n\n    # check if settings.json exists\n    path = self.get_settings_path()\n\n    # load assistant from id\n    if self.id:\n        if not self.refresh_from_id:\n            return self\n\n        self.assistant = self.client.beta.assistants.retrieve(self.id)\n        # Assign attributes to self if they are None\n        self.instructions = self.instructions or self.assistant.instructions\n        self.name = (\n            self.name\n            if self.name != self.__class__.__name__\n            else self.assistant.name\n        )\n        self.description = self.description or self.assistant.description\n        self.temperature = (\n            self.assistant.temperature\n            if self.temperature is None\n            else self.temperature\n        )\n        self.top_p = self.top_p or self.assistant.top_p\n        self.response_format = (\n            self.response_format or self.assistant.response_format\n        )\n        if not isinstance(self.response_format, str):\n            self.response_format = (\n                self.response_format or self.response_format.model_dump()\n            )\n        else:\n            self.response_format = (\n                self.response_format or self.assistant.response_format\n            )\n        self.tool_resources = (\n            self.tool_resources or self.assistant.tool_resources.model_dump()\n        )\n        self.metadata = self.metadata or self.assistant.metadata\n        self.model = self.model or self.assistant.model\n        self.tool_resources = (\n            self.tool_resources or self.assistant.tool_resources.model_dump()\n        )\n\n        for tool in self.assistant.tools:\n            # update assistants created with v1\n            if tool.type == \"retrieval\":\n                self.client.beta.assistants.update(\n                    self.id, tools=self.get_oai_tools()\n                )\n\n        # update assistant if parameters are different\n        if not self._check_parameters(self.assistant.model_dump()):\n            self._update_assistant()\n\n        return self\n\n    # load assistant from settings\n    if os.path.exists(path):\n        with open(path, \"r\") as f:\n            settings = json.load(f)\n            # iterate settings and find the assistant with the same name\n            for assistant_settings in settings:\n                if assistant_settings[\"name\"] == self.name:\n                    try:\n                        self.assistant = self.client.beta.assistants.retrieve(\n                            assistant_settings[\"id\"]\n                        )\n                        self.id = assistant_settings[\"id\"]\n\n                        # update assistant if parameters are different\n                        if not self._check_parameters(self.assistant.model_dump()):\n                            print(\"Updating agent... \" + self.name)\n                            self._update_assistant()\n\n                        if self.assistant.tool_resources:\n                            self.tool_resources = (\n                                self.assistant.tool_resources.model_dump()\n                            )\n\n                        self._update_settings()\n                        return self\n                    except NotFoundError:\n                        continue\n\n    # create assistant if settings.json does not exist or assistant with the same name does not exist\n    self.assistant = self._create_assistant()\n\n    if self.assistant.tool_resources:\n        self.tool_resources = self.assistant.tool_resources.model_dump()\n\n    self.id = self.assistant.id\n\n    self._save_settings()\n\n    return self\n</code></pre>"},{"location":"api/#agency_swarm.agents.agent.Agent.response_validator","title":"<code>response_validator(message)</code>","text":"<p>Validates the response from the agent. If the response is invalid, it must raise an exception with instructions for the caller agent on how to proceed.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The response from the agent.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The validated response.</p> Source code in <code>agency_swarm/agents/agent.py</code> <pre><code>def response_validator(self, message: str | list) -&gt; str:\n    \"\"\"\n    Validates the response from the agent. If the response is invalid, it must raise an exception with instructions\n    for the caller agent on how to proceed.\n\n    Parameters:\n        message (str): The response from the agent.\n\n    Returns:\n        str: The validated response.\n    \"\"\"\n    return message\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency","title":"<code>Agency</code>","text":"Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>class Agency:\n    def __init__(\n        self,\n        agency_chart: List,\n        shared_instructions: str = \"\",\n        shared_files: Union[str, List[str]] = None,\n        async_mode: Literal[\"threading\", \"tools_threading\"] = None,\n        send_message_tool_class: Type[SendMessageBase] = SendMessage,\n        settings_path: str = \"./settings.json\",\n        settings_callbacks: SettingsCallbacks = None,\n        threads_callbacks: ThreadsCallbacks = None,\n        temperature: float = 0.3,\n        top_p: float = None,\n        max_prompt_tokens: int = None,\n        max_completion_tokens: int = None,\n        truncation_strategy: dict = None,\n    ):\n        \"\"\"\n        Initializes the Agency object, setting up agents, threads, and core functionalities.\n\n        Parameters:\n            agency_chart: The structure defining the hierarchy and interaction of agents within the agency.\n            shared_instructions (str, optional): A path to a file containing shared instructions for all agents. Defaults to an empty string.\n            shared_files (Union[str, List[str]], optional): A path to a folder or a list of folders containing shared files for all agents. Defaults to None.\n            async_mode (str, optional): Specifies the mode for asynchronous processing. In \"threading\" mode, all sub-agents run in separate threads. In \"tools_threading\" mode, all tools run in separate threads, but agents do not. Defaults to None.\n            send_message_tool_class (Type[SendMessageBase], optional): The class to use for the send_message tool. For async communication, use `SendMessageAsyncThreading`. Defaults to SendMessage.\n            settings_path (str, optional): The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.\n            settings_callbacks (SettingsCallbacks, optional): A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n            threads_callbacks (ThreadsCallbacks, optional): A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n            temperature (float, optional): The temperature value to use for the agents. Agent-specific values will override this. Defaults to 0.3.\n            top_p (float, optional): The top_p value to use for the agents. Agent-specific values will override this. Defaults to None.\n            max_prompt_tokens (int, optional): The maximum number of tokens allowed in the prompt for each agent. Agent-specific values will override this. Defaults to None.\n            max_completion_tokens (int, optional): The maximum number of tokens allowed in the completion for each agent. Agent-specific values will override this. Defaults to None.\n            truncation_strategy (dict, optional): The truncation strategy to use for the completion for each agent. Agent-specific values will override this. Defaults to None.\n\n        This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.\n        \"\"\"\n        self.ceo = None\n        self.user = User()\n        self.agents = []\n        self.agents_and_threads = {}\n        self.main_recipients = []\n        self.main_thread = None\n        self.recipient_agents = None  # for autocomplete\n        self.shared_files = shared_files if shared_files else []\n        self.async_mode = async_mode\n        self.send_message_tool_class = send_message_tool_class\n        self.settings_path = settings_path\n        self.settings_callbacks = settings_callbacks\n        self.threads_callbacks = threads_callbacks\n        self.temperature = temperature\n        self.top_p = top_p\n        self.max_prompt_tokens = max_prompt_tokens\n        self.max_completion_tokens = max_completion_tokens\n        self.truncation_strategy = truncation_strategy\n\n        # set thread type based send_message_tool_class async mode\n        if (\n            hasattr(send_message_tool_class.ToolConfig, \"async_mode\")\n            and send_message_tool_class.ToolConfig.async_mode\n        ):\n            self._thread_type = ThreadAsync\n        else:\n            self._thread_type = Thread\n\n        if self.async_mode == \"threading\":\n            from agency_swarm.tools.send_message import SendMessageAsyncThreading\n\n            print(\n                \"Warning: 'threading' mode is deprecated. Please use send_message_tool_class = SendMessageAsyncThreading to use async communication.\"\n            )\n            self.send_message_tool_class = SendMessageAsyncThreading\n        elif self.async_mode == \"tools_threading\":\n            Thread.async_mode = \"tools_threading\"\n            print(\n                \"Warning: 'tools_threading' mode is deprecated. Use tool.ToolConfig.async_mode = 'threading' instead.\"\n            )\n        elif self.async_mode is None:\n            pass\n        else:\n            raise Exception(\n                \"Please select async_mode = 'threading' or 'tools_threading'.\"\n            )\n\n        if os.path.isfile(\n            os.path.join(self._get_class_folder_path(), shared_instructions)\n        ):\n            self._read_instructions(\n                os.path.join(self._get_class_folder_path(), shared_instructions)\n            )\n        elif os.path.isfile(shared_instructions):\n            self._read_instructions(shared_instructions)\n        else:\n            self.shared_instructions = shared_instructions\n\n        self.shared_state = SharedState()\n\n        self._parse_agency_chart(agency_chart)\n        self._init_threads()\n        self._create_special_tools()\n        self._init_agents()\n\n    def get_completion(\n        self,\n        message: str,\n        message_files: List[str] = None,\n        yield_messages: bool = False,\n        recipient_agent: Agent = None,\n        additional_instructions: str = None,\n        attachments: List[dict] = None,\n        tool_choice: dict = None,\n        verbose: bool = False,\n        response_format: dict = None,\n    ):\n        \"\"\"\n        Retrieves the completion for a given message from the main thread.\n\n        Parameters:\n            message (str): The message for which completion is to be retrieved.\n            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n            yield_messages (bool, optional): Flag to determine if intermediate messages should be yielded. Defaults to True.\n            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n            parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n            verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.\n            response_format (dict, optional): The response format to use for the completion.\n\n        Returns:\n            Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.\n        \"\"\"\n        if verbose and yield_messages:\n            raise Exception(\"Verbose mode is not compatible with yield_messages=True\")\n\n        res = self.main_thread.get_completion(\n            message=message,\n            message_files=message_files,\n            attachments=attachments,\n            recipient_agent=recipient_agent,\n            additional_instructions=additional_instructions,\n            tool_choice=tool_choice,\n            yield_messages=yield_messages or verbose,\n            response_format=response_format,\n        )\n\n        if not yield_messages or verbose:\n            while True:\n                try:\n                    message = next(res)\n                    if verbose:\n                        message.cprint()\n                except StopIteration as e:\n                    return e.value\n\n        return res\n\n    def get_completion_stream(\n        self,\n        message: str,\n        event_handler: type(AgencyEventHandler),\n        message_files: List[str] = None,\n        recipient_agent: Agent = None,\n        additional_instructions: str = None,\n        attachments: List[dict] = None,\n        tool_choice: dict = None,\n        response_format: dict = None,\n    ):\n        \"\"\"\n        Generates a stream of completions for a given message from the main thread.\n\n        Parameters:\n            message (str): The message for which completion is to be retrieved.\n            event_handler (type(AgencyEventHandler)): The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md\n            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n            parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n\n        Returns:\n            Final response: Final response from the main thread.\n        \"\"\"\n        if not inspect.isclass(event_handler):\n            raise Exception(\"Event handler must not be an instance.\")\n\n        res = self.main_thread.get_completion_stream(\n            message=message,\n            message_files=message_files,\n            event_handler=event_handler,\n            attachments=attachments,\n            recipient_agent=recipient_agent,\n            additional_instructions=additional_instructions,\n            tool_choice=tool_choice,\n            response_format=response_format,\n        )\n\n        while True:\n            try:\n                next(res)\n            except StopIteration as e:\n                event_handler.on_all_streams_end()\n\n                return e.value\n\n    def get_completion_parse(\n        self,\n        message: str,\n        response_format: Type[T],\n        message_files: List[str] = None,\n        recipient_agent: Agent = None,\n        additional_instructions: str = None,\n        attachments: List[dict] = None,\n        tool_choice: dict = None,\n        verbose: bool = False,\n    ) -&gt; T:\n        \"\"\"\n        Retrieves the completion for a given message from the main thread and parses the response using the provided pydantic model.\n\n        Parameters:\n            message (str): The message for which completion is to be retrieved.\n            response_format (type(BaseModel)): The response format to use for the completion.\n            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n            verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.\n\n        Returns:\n            Final response: The final response from the main thread, parsed using the provided pydantic model.\n        \"\"\"\n        response_model = None\n        if isinstance(response_format, type):\n            response_model = response_format\n            response_format = type_to_response_format_param(response_format)\n\n        res = self.get_completion(\n            message=message,\n            message_files=message_files,\n            recipient_agent=recipient_agent,\n            additional_instructions=additional_instructions,\n            attachments=attachments,\n            tool_choice=tool_choice,\n            response_format=response_format,\n            verbose=verbose,\n        )\n\n        try:\n            return response_model.model_validate_json(res)\n        except:\n            parsed_res = json.loads(res)\n            if \"refusal\" in parsed_res:\n                raise RefusalError(parsed_res[\"refusal\"])\n            else:\n                raise Exception(\"Failed to parse response: \" + res)\n\n    def demo_gradio(self, height=450, dark_mode=True, **kwargs):\n        \"\"\"\n        Launches a Gradio-based demo interface for the agency chatbot.\n\n        Parameters:\n            height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 600.\n            dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.\n            **kwargs: Additional keyword arguments to be passed to the Gradio interface.\n        This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.\n        \"\"\"\n\n        try:\n            import gradio as gr\n        except ImportError:\n            raise Exception(\"Please install gradio: pip install gradio\")\n\n        js = \"\"\"function () {\n          gradioURL = window.location.href\n          if (!gradioURL.endsWith('?__theme={theme}')) {\n            window.location.replace(gradioURL + '?__theme={theme}');\n          }\n        }\"\"\"\n\n        if dark_mode:\n            js = js.replace(\"{theme}\", \"dark\")\n        else:\n            js = js.replace(\"{theme}\", \"light\")\n\n        attachments = []\n        images = []\n        message_file_names = None\n        uploading_files = False\n        recipient_agent_names = [agent.name for agent in self.main_recipients]\n        recipient_agent = self.main_recipients[0]\n\n        with gr.Blocks(js=js) as demo:\n            chatbot_queue = queue.Queue()\n            chatbot = gr.Chatbot(height=height)\n            with gr.Row():\n                with gr.Column(scale=9):\n                    dropdown = gr.Dropdown(\n                        label=\"Recipient Agent\",\n                        choices=recipient_agent_names,\n                        value=recipient_agent.name,\n                    )\n                    msg = gr.Textbox(label=\"Your Message\", lines=4)\n                with gr.Column(scale=1):\n                    file_upload = gr.Files(label=\"OpenAI Files\", type=\"filepath\")\n            button = gr.Button(value=\"Send\", variant=\"primary\")\n\n            def handle_dropdown_change(selected_option):\n                nonlocal recipient_agent\n                recipient_agent = self._get_agent_by_name(selected_option)\n\n            def handle_file_upload(file_list):\n                nonlocal attachments\n                nonlocal message_file_names\n                nonlocal uploading_files\n                nonlocal images\n                uploading_files = True\n                attachments = []\n                message_file_names = []\n                if file_list:\n                    try:\n                        for file_obj in file_list:\n                            purpose = get_file_purpose(file_obj.name)\n\n                            with open(file_obj.name, \"rb\") as f:\n                                # Upload the file to OpenAI\n                                file = self.main_thread.client.files.create(\n                                    file=f, purpose=purpose\n                                )\n\n                            if purpose == \"vision\":\n                                images.append(\n                                    {\n                                        \"type\": \"image_file\",\n                                        \"image_file\": {\"file_id\": file.id},\n                                    }\n                                )\n                            else:\n                                attachments.append(\n                                    {\n                                        \"file_id\": file.id,\n                                        \"tools\": get_tools(file.filename),\n                                    }\n                                )\n\n                            message_file_names.append(file.filename)\n                            print(f\"Uploaded file ID: {file.id}\")\n                        return attachments\n                    except Exception as e:\n                        print(f\"Error: {e}\")\n                        return str(e)\n                    finally:\n                        uploading_files = False\n\n                uploading_files = False\n                return \"No files uploaded\"\n\n            def user(user_message, history):\n                if not user_message.strip():\n                    return user_message, history\n\n                nonlocal message_file_names\n                nonlocal uploading_files\n                nonlocal images\n                nonlocal attachments\n                nonlocal recipient_agent\n\n                # Check if attachments contain file search or code interpreter types\n                def check_and_add_tools_in_attachments(attachments, recipient_agent):\n                    for attachment in attachments:\n                        for tool in attachment.get(\"tools\", []):\n                            if tool[\"type\"] == \"file_search\":\n                                if not any(\n                                    isinstance(t, FileSearch)\n                                    for t in recipient_agent.tools\n                                ):\n                                    # Add FileSearch tool if it does not exist\n                                    recipient_agent.tools.append(FileSearch)\n                                    recipient_agent.client.beta.assistants.update(\n                                        recipient_agent.id,\n                                        tools=recipient_agent.get_oai_tools(),\n                                    )\n                                    print(\n                                        \"Added FileSearch tool to recipient agent to analyze the file.\"\n                                    )\n                            elif tool[\"type\"] == \"code_interpreter\":\n                                if not any(\n                                    isinstance(t, CodeInterpreter)\n                                    for t in recipient_agent.tools\n                                ):\n                                    # Add CodeInterpreter tool if it does not exist\n                                    recipient_agent.tools.append(CodeInterpreter)\n                                    recipient_agent.client.beta.assistants.update(\n                                        recipient_agent.id,\n                                        tools=recipient_agent.get_oai_tools(),\n                                    )\n                                    print(\n                                        \"Added CodeInterpreter tool to recipient agent to analyze the file.\"\n                                    )\n                    return None\n\n                check_and_add_tools_in_attachments(attachments, recipient_agent)\n\n                if history is None:\n                    history = []\n\n                original_user_message = user_message\n\n                # Append the user message with a placeholder for bot response\n                if recipient_agent:\n                    user_message = (\n                        f\"\ud83d\udc64 User \ud83d\udde3\ufe0f @{recipient_agent.name}:\\n\" + user_message.strip()\n                    )\n                else:\n                    user_message = f\"\ud83d\udc64 User:\" + user_message.strip()\n\n                nonlocal message_file_names\n                if message_file_names:\n                    user_message += \"\\n\\n\ud83d\udcce Files:\\n\" + \"\\n\".join(message_file_names)\n\n                return original_user_message, history + [[user_message, None]]\n\n            class GradioEventHandler(AgencyEventHandler):\n                message_output = None\n\n                @classmethod\n                def change_recipient_agent(cls, recipient_agent_name):\n                    nonlocal chatbot_queue\n                    chatbot_queue.put(\"[change_recipient_agent]\")\n                    chatbot_queue.put(recipient_agent_name)\n\n                @override\n                def on_message_created(self, message: Message) -&gt; None:\n                    if message.role == \"user\":\n                        full_content = \"\"\n                        for content in message.content:\n                            if content.type == \"image_file\":\n                                full_content += (\n                                    f\"\ud83d\uddbc\ufe0f Image File: {content.image_file.file_id}\\n\"\n                                )\n                                continue\n\n                            if content.type == \"image_url\":\n                                full_content += f\"\\n{content.image_url.url}\\n\"\n                                continue\n\n                            if content.type == \"text\":\n                                full_content += content.text.value + \"\\n\"\n\n                        self.message_output = MessageOutput(\n                            \"text\",\n                            self.agent_name,\n                            self.recipient_agent_name,\n                            full_content,\n                        )\n\n                    else:\n                        self.message_output = MessageOutput(\n                            \"text\", self.recipient_agent_name, self.agent_name, \"\"\n                        )\n\n                    chatbot_queue.put(\"[new_message]\")\n                    chatbot_queue.put(self.message_output.get_formatted_content())\n\n                @override\n                def on_text_delta(self, delta, snapshot):\n                    chatbot_queue.put(delta.value)\n\n                @override\n                def on_tool_call_created(self, tool_call: ToolCall):\n                    if isinstance(tool_call, dict):\n                        if \"type\" not in tool_call:\n                            tool_call[\"type\"] = \"function\"\n\n                        if tool_call[\"type\"] == \"function\":\n                            tool_call = FunctionToolCall(**tool_call)\n                        elif tool_call[\"type\"] == \"code_interpreter\":\n                            tool_call = CodeInterpreterToolCall(**tool_call)\n                        elif (\n                            tool_call[\"type\"] == \"file_search\"\n                            or tool_call[\"type\"] == \"retrieval\"\n                        ):\n                            tool_call = FileSearchToolCall(**tool_call)\n                        else:\n                            raise ValueError(\n                                \"Invalid tool call type: \" + tool_call[\"type\"]\n                            )\n\n                    # TODO: add support for code interpreter and retrieval tools\n                    if tool_call.type == \"function\":\n                        chatbot_queue.put(\"[new_message]\")\n                        self.message_output = MessageOutput(\n                            \"function\",\n                            self.recipient_agent_name,\n                            self.agent_name,\n                            str(tool_call.function),\n                        )\n                        chatbot_queue.put(\n                            self.message_output.get_formatted_header() + \"\\n\"\n                        )\n\n                @override\n                def on_tool_call_done(self, snapshot: ToolCall):\n                    if isinstance(snapshot, dict):\n                        if \"type\" not in snapshot:\n                            snapshot[\"type\"] = \"function\"\n\n                        if snapshot[\"type\"] == \"function\":\n                            snapshot = FunctionToolCall(**snapshot)\n                        elif snapshot[\"type\"] == \"code_interpreter\":\n                            snapshot = CodeInterpreterToolCall(**snapshot)\n                        elif snapshot[\"type\"] == \"file_search\":\n                            snapshot = FileSearchToolCall(**snapshot)\n                        else:\n                            raise ValueError(\n                                \"Invalid tool call type: \" + snapshot[\"type\"]\n                            )\n\n                    self.message_output = None\n\n                    # TODO: add support for code interpreter and retrieval tools\n                    if snapshot.type != \"function\":\n                        return\n\n                    chatbot_queue.put(str(snapshot.function))\n\n                    if snapshot.function.name == \"SendMessage\":\n                        try:\n                            args = eval(snapshot.function.arguments)\n                            recipient = args[\"recipient\"]\n                            self.message_output = MessageOutput(\n                                \"text\",\n                                self.recipient_agent_name,\n                                recipient,\n                                args[\"message\"],\n                            )\n\n                            chatbot_queue.put(\"[new_message]\")\n                            chatbot_queue.put(\n                                self.message_output.get_formatted_content()\n                            )\n                        except Exception as e:\n                            pass\n\n                    self.message_output = None\n\n                @override\n                def on_run_step_done(self, run_step: RunStep) -&gt; None:\n                    if run_step.type == \"tool_calls\":\n                        for tool_call in run_step.step_details.tool_calls:\n                            if tool_call.type != \"function\":\n                                continue\n\n                            if tool_call.function.name == \"SendMessage\":\n                                continue\n\n                            self.message_output = None\n                            chatbot_queue.put(\"[new_message]\")\n\n                            self.message_output = MessageOutput(\n                                \"function_output\",\n                                tool_call.function.name,\n                                self.recipient_agent_name,\n                                tool_call.function.output,\n                            )\n\n                            chatbot_queue.put(\n                                self.message_output.get_formatted_header() + \"\\n\"\n                            )\n                            chatbot_queue.put(tool_call.function.output)\n\n                @override\n                @classmethod\n                def on_all_streams_end(cls):\n                    cls.message_output = None\n                    chatbot_queue.put(\"[end]\")\n\n            def bot(original_message, history, dropdown):\n                nonlocal attachments\n                nonlocal message_file_names\n                nonlocal recipient_agent\n                nonlocal recipient_agent_names\n                nonlocal images\n                nonlocal uploading_files\n\n                if not original_message:\n                    return (\n                        \"\",\n                        history,\n                        gr.update(\n                            value=recipient_agent.name,\n                            choices=set([*recipient_agent_names, recipient_agent.name]),\n                        ),\n                    )\n\n                if uploading_files:\n                    history.append([None, \"Uploading files... Please wait.\"])\n                    yield (\n                        \"\",\n                        history,\n                        gr.update(\n                            value=recipient_agent.name,\n                            choices=set([*recipient_agent_names, recipient_agent.name]),\n                        ),\n                    )\n                    return (\n                        \"\",\n                        history,\n                        gr.update(\n                            value=recipient_agent.name,\n                            choices=set([*recipient_agent_names, recipient_agent.name]),\n                        ),\n                    )\n\n                print(\"Message files: \", attachments)\n                print(\"Images: \", images)\n\n                if images and len(images) &gt; 0:\n                    original_message = [\n                        {\n                            \"type\": \"text\",\n                            \"text\": original_message,\n                        },\n                        *images,\n                    ]\n\n                completion_thread = threading.Thread(\n                    target=self.get_completion_stream,\n                    args=(\n                        original_message,\n                        GradioEventHandler,\n                        [],\n                        recipient_agent,\n                        \"\",\n                        attachments,\n                        None,\n                    ),\n                )\n                completion_thread.start()\n\n                attachments = []\n                message_file_names = []\n                images = []\n                uploading_files = False\n\n                new_message = True\n                while True:\n                    try:\n                        bot_message = chatbot_queue.get(block=True)\n\n                        if bot_message == \"[end]\":\n                            completion_thread.join()\n                            break\n\n                        if bot_message == \"[new_message]\":\n                            new_message = True\n                            continue\n\n                        if bot_message == \"[change_recipient_agent]\":\n                            new_agent_name = chatbot_queue.get(block=True)\n                            recipient_agent = self._get_agent_by_name(new_agent_name)\n                            yield (\n                                \"\",\n                                history,\n                                gr.update(\n                                    value=new_agent_name,\n                                    choices=set(\n                                        [*recipient_agent_names, recipient_agent.name]\n                                    ),\n                                ),\n                            )\n                            continue\n\n                        if new_message:\n                            history.append([None, bot_message])\n                            new_message = False\n                        else:\n                            history[-1][1] += bot_message\n\n                        yield (\n                            \"\",\n                            history,\n                            gr.update(\n                                value=recipient_agent.name,\n                                choices=set(\n                                    [*recipient_agent_names, recipient_agent.name]\n                                ),\n                            ),\n                        )\n                    except queue.Empty:\n                        break\n\n            button.click(user, inputs=[msg, chatbot], outputs=[msg, chatbot]).then(\n                bot, [msg, chatbot, dropdown], [msg, chatbot, dropdown]\n            )\n            dropdown.change(handle_dropdown_change, dropdown)\n            file_upload.change(handle_file_upload, file_upload)\n            msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n                bot, [msg, chatbot, dropdown], [msg, chatbot, dropdown]\n            )\n\n            # Enable queuing for streaming intermediate outputs\n            demo.queue(default_concurrency_limit=10)\n\n        # Launch the demo\n        demo.launch(**kwargs)\n        return demo\n\n    def _recipient_agent_completer(self, text, state):\n        \"\"\"\n        Autocomplete completer for recipient agent names.\n        \"\"\"\n        options = [\n            agent\n            for agent in self.recipient_agents\n            if agent.lower().startswith(text.lower())\n        ]\n        if state &lt; len(options):\n            return options[state]\n        else:\n            return None\n\n    def _setup_autocomplete(self):\n        \"\"\"\n        Sets up readline with the completer function.\n        \"\"\"\n        try:\n            import readline\n        except ImportError:\n            # Attempt to import pyreadline for Windows compatibility\n            try:\n                import pyreadline as readline\n            except ImportError:\n                print(\n                    \"Module 'readline' not found. Autocomplete will not work. If you are using Windows, try installing 'pyreadline3'.\"\n                )\n                return\n\n        if not readline:\n            return\n\n        try:\n            readline.set_completer(self._recipient_agent_completer)\n            readline.parse_and_bind(\"tab: complete\")\n        except Exception as e:\n            print(\n                f\"Error setting up autocomplete for agents in terminal: {e}. Autocomplete will not work.\"\n            )\n\n    def run_demo(self):\n        \"\"\"\n        Executes agency in the terminal with autocomplete for recipient agent names.\n        \"\"\"\n        outer_self = self\n        from agency_swarm import AgencyEventHandler\n\n        class TermEventHandler(AgencyEventHandler):\n            message_output = None\n\n            @override\n            def on_message_created(self, message: Message) -&gt; None:\n                if message.role == \"user\":\n                    self.message_output = MessageOutputLive(\n                        \"text\", self.agent_name, self.recipient_agent_name, \"\"\n                    )\n                    self.message_output.cprint_update(message.content[0].text.value)\n                else:\n                    self.message_output = MessageOutputLive(\n                        \"text\", self.recipient_agent_name, self.agent_name, \"\"\n                    )\n\n            @override\n            def on_message_done(self, message: Message) -&gt; None:\n                self.message_output = None\n\n            @override\n            def on_text_delta(self, delta, snapshot):\n                self.message_output.cprint_update(snapshot.value)\n\n            @override\n            def on_tool_call_created(self, tool_call):\n                if isinstance(tool_call, dict):\n                    if \"type\" not in tool_call:\n                        tool_call[\"type\"] = \"function\"\n\n                    if tool_call[\"type\"] == \"function\":\n                        tool_call = FunctionToolCall(**tool_call)\n                    elif tool_call[\"type\"] == \"code_interpreter\":\n                        tool_call = CodeInterpreterToolCall(**tool_call)\n                    elif (\n                        tool_call[\"type\"] == \"file_search\"\n                        or tool_call[\"type\"] == \"retrieval\"\n                    ):\n                        tool_call = FileSearchToolCall(**tool_call)\n                    else:\n                        raise ValueError(\"Invalid tool call type: \" + tool_call[\"type\"])\n\n                # TODO: add support for code interpreter and retirieval tools\n\n                if tool_call.type == \"function\":\n                    self.message_output = MessageOutputLive(\n                        \"function\",\n                        self.recipient_agent_name,\n                        self.agent_name,\n                        str(tool_call.function),\n                    )\n\n            @override\n            def on_tool_call_delta(self, delta, snapshot):\n                if isinstance(snapshot, dict):\n                    if \"type\" not in snapshot:\n                        snapshot[\"type\"] = \"function\"\n\n                    if snapshot[\"type\"] == \"function\":\n                        snapshot = FunctionToolCall(**snapshot)\n                    elif snapshot[\"type\"] == \"code_interpreter\":\n                        snapshot = CodeInterpreterToolCall(**snapshot)\n                    elif snapshot[\"type\"] == \"file_search\":\n                        snapshot = FileSearchToolCall(**snapshot)\n                    else:\n                        raise ValueError(\"Invalid tool call type: \" + snapshot[\"type\"])\n\n                self.message_output.cprint_update(str(snapshot.function))\n\n            @override\n            def on_tool_call_done(self, snapshot):\n                self.message_output = None\n\n                # TODO: add support for code interpreter and retrieval tools\n                if snapshot.type != \"function\":\n                    return\n\n                if snapshot.function.name == \"SendMessage\" and not (\n                    hasattr(\n                        outer_self.send_message_tool_class.ToolConfig,\n                        \"output_as_result\",\n                    )\n                    and outer_self.send_message_tool_class.ToolConfig.output_as_result\n                ):\n                    try:\n                        args = eval(snapshot.function.arguments)\n                        recipient = args[\"recipient\"]\n                        self.message_output = MessageOutputLive(\n                            \"text\", self.recipient_agent_name, recipient, \"\"\n                        )\n\n                        self.message_output.cprint_update(args[\"message\"])\n                    except Exception as e:\n                        pass\n\n                self.message_output = None\n\n            @override\n            def on_run_step_done(self, run_step: RunStep) -&gt; None:\n                if run_step.type == \"tool_calls\":\n                    for tool_call in run_step.step_details.tool_calls:\n                        if tool_call.type != \"function\":\n                            continue\n\n                        if tool_call.function.name == \"SendMessage\":\n                            continue\n\n                        self.message_output = None\n                        self.message_output = MessageOutputLive(\n                            \"function_output\",\n                            tool_call.function.name,\n                            self.recipient_agent_name,\n                            tool_call.function.output,\n                        )\n                        self.message_output.cprint_update(tool_call.function.output)\n\n                    self.message_output = None\n\n            @override\n            def on_end(self):\n                self.message_output = None\n\n        self.recipient_agents = [str(agent.name) for agent in self.main_recipients]\n\n        self._setup_autocomplete()  # Prepare readline for autocomplete\n\n        while True:\n            console.rule()\n            text = input(\"\ud83d\udc64 USER: \")\n\n            if not text:\n                continue\n\n            if text.lower() == \"exit\":\n                break\n\n            recipient_agent = None\n            if \"@\" in text:\n                recipient_agent = text.split(\"@\")[1].split(\" \")[0]\n                text = text.replace(f\"@{recipient_agent}\", \"\").strip()\n                try:\n                    recipient_agent = [\n                        agent\n                        for agent in self.recipient_agents\n                        if agent.lower() == recipient_agent.lower()\n                    ][0]\n                    recipient_agent = self._get_agent_by_name(recipient_agent)\n                except Exception as e:\n                    print(f\"Recipient agent {recipient_agent} not found.\")\n                    continue\n\n            self.get_completion_stream(\n                message=text,\n                event_handler=TermEventHandler,\n                recipient_agent=recipient_agent,\n            )\n\n    def get_customgpt_schema(self, url: str):\n        \"\"\"Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.\n\n        Parameters:\n            url (str): Your server url where the api will be hosted.\n        \"\"\"\n\n        return self.ceo.get_openapi_schema(url)\n\n    def plot_agency_chart(self):\n        pass\n\n    def _init_agents(self):\n        \"\"\"\n        Initializes all agents in the agency with unique IDs, shared instructions, and OpenAI models.\n\n        This method iterates through each agent in the agency, assigns a unique ID, adds shared instructions, and initializes the OpenAI models for each agent.\n\n        There are no input parameters.\n\n        There are no output parameters as this method is used for internal initialization purposes within the Agency class.\n        \"\"\"\n        if self.settings_callbacks:\n            loaded_settings = self.settings_callbacks[\"load\"]()\n            with open(self.settings_path, \"w\") as f:\n                json.dump(loaded_settings, f, indent=4)\n\n        for agent in self.agents:\n            if \"temp_id\" in agent.id:\n                agent.id = None\n\n            agent.add_shared_instructions(self.shared_instructions)\n            agent.settings_path = self.settings_path\n\n            if self.shared_files:\n                if isinstance(self.shared_files, str):\n                    self.shared_files = [self.shared_files]\n\n                if isinstance(agent.files_folder, str):\n                    agent.files_folder = [agent.files_folder]\n                    agent.files_folder += self.shared_files\n                elif isinstance(agent.files_folder, list):\n                    agent.files_folder += self.shared_files\n\n            if self.temperature is not None and agent.temperature is None:\n                agent.temperature = self.temperature\n            if self.top_p and agent.top_p is None:\n                agent.top_p = self.top_p\n            if self.max_prompt_tokens is not None and agent.max_prompt_tokens is None:\n                agent.max_prompt_tokens = self.max_prompt_tokens\n            if (\n                self.max_completion_tokens is not None\n                and agent.max_completion_tokens is None\n            ):\n                agent.max_completion_tokens = self.max_completion_tokens\n            if (\n                self.truncation_strategy is not None\n                and agent.truncation_strategy is None\n            ):\n                agent.truncation_strategy = self.truncation_strategy\n\n            if not agent.shared_state:\n                agent.shared_state = self.shared_state\n\n            agent.init_oai()\n\n        if self.settings_callbacks:\n            with open(self.agents[0].get_settings_path(), \"r\") as f:\n                settings = f.read()\n            settings = json.loads(settings)\n            self.settings_callbacks[\"save\"](settings)\n\n    def _init_threads(self):\n        \"\"\"\n        Initializes threads for communication between agents within the agency.\n\n        This method creates Thread objects for each pair of interacting agents as defined in the agents_and_threads attribute of the Agency. Each thread facilitates communication and task execution between an agent and its designated recipient agent.\n\n        No input parameters.\n\n        Output Parameters:\n            This method does not return any value but updates the agents_and_threads attribute with initialized Thread objects.\n        \"\"\"\n        self.main_thread = Thread(self.user, self.ceo)\n\n        # load thread ids\n        loaded_thread_ids = {}\n        if self.threads_callbacks:\n            loaded_thread_ids = self.threads_callbacks[\"load\"]()\n            if \"main_thread\" in loaded_thread_ids and loaded_thread_ids[\"main_thread\"]:\n                self.main_thread.id = loaded_thread_ids[\"main_thread\"]\n            else:\n                self.main_thread.init_thread()\n\n        # Save main_thread into agents_and_threads\n        self.agents_and_threads[\"main_thread\"] = self.main_thread\n\n        # initialize threads\n        for agent_name, threads in self.agents_and_threads.items():\n            if agent_name == \"main_thread\":\n                continue\n            for other_agent, items in threads.items():\n                # create thread class\n                self.agents_and_threads[agent_name][other_agent] = self._thread_type(\n                    self._get_agent_by_name(items[\"agent\"]),\n                    self._get_agent_by_name(items[\"recipient_agent\"]),\n                )\n\n                # load thread id if available\n                if (\n                    agent_name in loaded_thread_ids\n                    and other_agent in loaded_thread_ids[agent_name]\n                ):\n                    self.agents_and_threads[agent_name][\n                        other_agent\n                    ].id = loaded_thread_ids[agent_name][other_agent]\n                # init threads if threre are threads callbacks so the ids are saved for later use\n                elif self.threads_callbacks:\n                    self.agents_and_threads[agent_name][other_agent].init_thread()\n\n        # save thread ids\n        if self.threads_callbacks:\n            loaded_thread_ids = {}\n            for agent_name, threads in self.agents_and_threads.items():\n                if agent_name == \"main_thread\":\n                    continue\n                loaded_thread_ids[agent_name] = {}\n                for other_agent, thread in threads.items():\n                    loaded_thread_ids[agent_name][other_agent] = thread.id\n\n            loaded_thread_ids[\"main_thread\"] = self.main_thread.id\n\n            self.threads_callbacks[\"save\"](loaded_thread_ids)\n\n    def _parse_agency_chart(self, agency_chart):\n        \"\"\"\n        Parses the provided agency chart to initialize and organize agents within the agency.\n\n        Parameters:\n            agency_chart: A structure representing the hierarchical organization of agents within the agency.\n                    It can contain Agent objects and lists of Agent objects.\n\n        This method iterates through each node in the agency chart. If a node is an Agent, it is set as the CEO if not already assigned.\n        If a node is a list, it iterates through the agents in the list, adding them to the agency and establishing communication\n        threads between them. It raises an exception if the agency chart is invalid or if multiple CEOs are defined.\n        \"\"\"\n        if not isinstance(agency_chart, list):\n            raise Exception(\"Invalid agency chart.\")\n\n        if len(agency_chart) == 0:\n            raise Exception(\"Agency chart cannot be empty.\")\n\n        for node in agency_chart:\n            if isinstance(node, Agent):\n                if not self.ceo:\n                    self.ceo = node\n                    self._add_agent(self.ceo)\n                else:\n                    self._add_agent(node)\n                self._add_main_recipient(node)\n\n            elif isinstance(node, list):\n                for i, agent in enumerate(node):\n                    if not isinstance(agent, Agent):\n                        raise Exception(\"Invalid agency chart.\")\n\n                    index = self._add_agent(agent)\n\n                    if i == len(node) - 1:\n                        continue\n\n                    if agent.name not in self.agents_and_threads.keys():\n                        self.agents_and_threads[agent.name] = {}\n\n                    if i &lt; len(node) - 1:\n                        other_agent = node[i + 1]\n                        if other_agent.name == agent.name:\n                            continue\n                        if (\n                            other_agent.name\n                            not in self.agents_and_threads[agent.name].keys()\n                        ):\n                            self.agents_and_threads[agent.name][other_agent.name] = {\n                                \"agent\": agent.name,\n                                \"recipient_agent\": other_agent.name,\n                            }\n            else:\n                raise Exception(\"Invalid agency chart.\")\n\n    def _add_agent(self, agent):\n        \"\"\"\n        Adds an agent to the agency, assigning a temporary ID if necessary.\n\n        Parameters:\n            agent (Agent): The agent to be added to the agency.\n\n        Returns:\n            int: The index of the added agent within the agency's agents list.\n\n        This method adds an agent to the agency's list of agents. If the agent does not have an ID, it assigns a temporary unique ID. It checks for uniqueness of the agent's name before addition. The method returns the index of the agent in the agency's agents list, which is used for referencing the agent within the agency.\n        \"\"\"\n        if not agent.id:\n            # assign temp id\n            agent.id = \"temp_id_\" + str(uuid.uuid4())\n        if agent.id not in self._get_agent_ids():\n            if agent.name in self._get_agent_names():\n                raise Exception(\"Agent names must be unique.\")\n            self.agents.append(agent)\n            return len(self.agents) - 1\n        else:\n            return self._get_agent_ids().index(agent.id)\n\n    def _add_main_recipient(self, agent):\n        \"\"\"\n        Adds an agent to the agency's list of main recipients.\n\n        Parameters:\n            agent (Agent): The agent to be added to the agency's list of main recipients.\n\n        This method adds an agent to the agency's list of main recipients. These are agents that can be directly contacted by the user.\n        \"\"\"\n        main_recipient_ids = [agent.id for agent in self.main_recipients]\n\n        if agent.id not in main_recipient_ids:\n            self.main_recipients.append(agent)\n\n    def _read_instructions(self, path):\n        \"\"\"\n        Reads shared instructions from a specified file and stores them in the agency.\n\n        Parameters:\n            path (str): The file path from which to read the shared instructions.\n\n        This method opens the file located at the given path, reads its contents, and stores these contents in the 'shared_instructions' attribute of the agency. This is used to provide common guidelines or instructions to all agents within the agency.\n        \"\"\"\n        path = path\n        with open(path, \"r\") as f:\n            self.shared_instructions = f.read()\n\n    def _create_special_tools(self):\n        \"\"\"\n        Creates and assigns 'SendMessage' tools to each agent based on the agency's structure.\n\n        This method iterates through the agents and threads in the agency, creating SendMessage tools for each agent. These tools enable agents to send messages to other agents as defined in the agency's structure. The SendMessage tools are tailored to the specific recipient agents that each agent can communicate with.\n\n        No input parameters.\n\n        No output parameters; this method modifies the agents' toolset internally.\n        \"\"\"\n        for agent_name, threads in self.agents_and_threads.items():\n            if agent_name == \"main_thread\":\n                continue\n            recipient_names = list(threads.keys())\n            recipient_agents = self._get_agents_by_names(recipient_names)\n            if len(recipient_agents) == 0:\n                continue\n            agent = self._get_agent_by_name(agent_name)\n            agent.add_tool(self._create_send_message_tool(agent, recipient_agents))\n            if self._thread_type == ThreadAsync:\n                agent.add_tool(self._create_get_response_tool(agent, recipient_agents))\n\n    def _create_send_message_tool(self, agent: Agent, recipient_agents: List[Agent]):\n        \"\"\"\n        Creates a SendMessage tool to enable an agent to send messages to specified recipient agents.\n\n\n        Parameters:\n            agent (Agent): The agent who will be sending messages.\n            recipient_agents (List[Agent]): A list of recipient agents who can receive messages.\n\n        Returns:\n            SendMessage: A SendMessage tool class that is dynamically created and configured for the given agent and its recipient agents. This tool allows the agent to send messages to the specified recipients, facilitating inter-agent communication within the agency.\n        \"\"\"\n        recipient_names = [agent.name for agent in recipient_agents]\n        recipients = Enum(\"recipient\", {name: name for name in recipient_names})\n\n        agent_descriptions = \"\"\n        for recipient_agent in recipient_agents:\n            if not recipient_agent.description:\n                continue\n            agent_descriptions += recipient_agent.name + \": \"\n            agent_descriptions += recipient_agent.description + \"\\n\"\n\n        class SendMessage(self.send_message_tool_class):\n            recipient: recipients = Field(..., description=agent_descriptions)\n\n            @field_validator(\"recipient\")\n            @classmethod\n            def check_recipient(cls, value):\n                if value.value not in recipient_names:\n                    raise ValueError(\n                        f\"Recipient {value} is not valid. Valid recipients are: {recipient_names}\"\n                    )\n                return value\n\n        SendMessage._caller_agent = agent\n        SendMessage._agents_and_threads = self.agents_and_threads\n\n        return SendMessage\n\n    def _create_get_response_tool(self, agent: Agent, recipient_agents: List[Agent]):\n        \"\"\"\n        Creates a CheckStatus tool to enable an agent to check the status of a task with a specified recipient agent.\n        \"\"\"\n        recipient_names = [agent.name for agent in recipient_agents]\n        recipients = Enum(\"recipient\", {name: name for name in recipient_names})\n\n        outer_self = self\n\n        class GetResponse(BaseTool):\n            \"\"\"This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first.\"\"\"\n\n            recipient: recipients = Field(\n                ...,\n                description=f\"Recipient agent that you want to check the status of. Valid recipients are: {recipient_names}\",\n            )\n\n            @field_validator(\"recipient\")\n            def check_recipient(cls, value):\n                if value.value not in recipient_names:\n                    raise ValueError(\n                        f\"Recipient {value} is not valid. Valid recipients are: {recipient_names}\"\n                    )\n                return value\n\n            def run(self):\n                thread = outer_self.agents_and_threads[self._caller_agent.name][\n                    self.recipient.value\n                ]\n\n                return thread.check_status()\n\n        GetResponse._caller_agent = agent\n\n        return GetResponse\n\n    def _get_agent_by_name(self, agent_name):\n        \"\"\"\n        Retrieves an agent from the agency based on the agent's name.\n\n        Parameters:\n            agent_name (str): The name of the agent to be retrieved.\n\n        Returns:\n            Agent: The agent object with the specified name.\n\n        Raises:\n            Exception: If no agent with the given name is found in the agency.\n        \"\"\"\n        for agent in self.agents:\n            if agent.name == agent_name:\n                return agent\n        raise Exception(f\"Agent {agent_name} not found.\")\n\n    def _get_agents_by_names(self, agent_names):\n        \"\"\"\n        Retrieves a list of agent objects based on their names.\n\n        Parameters:\n            agent_names: A list of strings representing the names of the agents to be retrieved.\n\n        Returns:\n            A list of Agent objects corresponding to the given names.\n        \"\"\"\n        return [self._get_agent_by_name(agent_name) for agent_name in agent_names]\n\n    def _get_agent_ids(self):\n        \"\"\"\n        Retrieves the IDs of all agents currently in the agency.\n\n        Returns:\n            List[str]: A list containing the unique IDs of all agents.\n        \"\"\"\n        return [agent.id for agent in self.agents]\n\n    def _get_agent_names(self):\n        \"\"\"\n        Retrieves the names of all agents in the agency.\n\n        Returns:\n            List[str]: A list of names of all agents currently part of the agency.\n        \"\"\"\n        return [agent.name for agent in self.agents]\n\n    def _get_class_folder_path(self):\n        \"\"\"\n        Retrieves the absolute path of the directory containing the class file.\n\n        Returns:\n            str: The absolute path of the directory where the class file is located.\n        \"\"\"\n        return os.path.abspath(os.path.dirname(inspect.getfile(self.__class__)))\n\n    def delete(self):\n        \"\"\"\n        This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.\n        \"\"\"\n        for agent in self.agents:\n            agent.delete()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.__init__","title":"<code>__init__(agency_chart, shared_instructions='', shared_files=None, async_mode=None, send_message_tool_class=SendMessage, settings_path='./settings.json', settings_callbacks=None, threads_callbacks=None, temperature=0.3, top_p=None, max_prompt_tokens=None, max_completion_tokens=None, truncation_strategy=None)</code>","text":"<p>Initializes the Agency object, setting up agents, threads, and core functionalities.</p> <p>Parameters:</p> Name Type Description Default <code>agency_chart</code> <code>List</code> <p>The structure defining the hierarchy and interaction of agents within the agency.</p> required <code>shared_instructions</code> <code>str</code> <p>A path to a file containing shared instructions for all agents. Defaults to an empty string.</p> <code>''</code> <code>shared_files</code> <code>Union[str, List[str]]</code> <p>A path to a folder or a list of folders containing shared files for all agents. Defaults to None.</p> <code>None</code> <code>async_mode</code> <code>str</code> <p>Specifies the mode for asynchronous processing. In \"threading\" mode, all sub-agents run in separate threads. In \"tools_threading\" mode, all tools run in separate threads, but agents do not. Defaults to None.</p> <code>None</code> <code>send_message_tool_class</code> <code>Type[SendMessageBase]</code> <p>The class to use for the send_message tool. For async communication, use <code>SendMessageAsyncThreading</code>. Defaults to SendMessage.</p> <code>SendMessage</code> <code>settings_path</code> <code>str</code> <p>The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.</p> <code>'./settings.json'</code> <code>settings_callbacks</code> <code>SettingsCallbacks</code> <p>A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.</p> <code>None</code> <code>threads_callbacks</code> <code>ThreadsCallbacks</code> <p>A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.</p> <code>None</code> <code>temperature</code> <code>float</code> <p>The temperature value to use for the agents. Agent-specific values will override this. Defaults to 0.3.</p> <code>0.3</code> <code>top_p</code> <code>float</code> <p>The top_p value to use for the agents. Agent-specific values will override this. Defaults to None.</p> <code>None</code> <code>max_prompt_tokens</code> <code>int</code> <p>The maximum number of tokens allowed in the prompt for each agent. Agent-specific values will override this. Defaults to None.</p> <code>None</code> <code>max_completion_tokens</code> <code>int</code> <p>The maximum number of tokens allowed in the completion for each agent. Agent-specific values will override this. Defaults to None.</p> <code>None</code> <code>truncation_strategy</code> <code>dict</code> <p>The truncation strategy to use for the completion for each agent. Agent-specific values will override this. Defaults to None.</p> <code>None</code> <p>This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def __init__(\n    self,\n    agency_chart: List,\n    shared_instructions: str = \"\",\n    shared_files: Union[str, List[str]] = None,\n    async_mode: Literal[\"threading\", \"tools_threading\"] = None,\n    send_message_tool_class: Type[SendMessageBase] = SendMessage,\n    settings_path: str = \"./settings.json\",\n    settings_callbacks: SettingsCallbacks = None,\n    threads_callbacks: ThreadsCallbacks = None,\n    temperature: float = 0.3,\n    top_p: float = None,\n    max_prompt_tokens: int = None,\n    max_completion_tokens: int = None,\n    truncation_strategy: dict = None,\n):\n    \"\"\"\n    Initializes the Agency object, setting up agents, threads, and core functionalities.\n\n    Parameters:\n        agency_chart: The structure defining the hierarchy and interaction of agents within the agency.\n        shared_instructions (str, optional): A path to a file containing shared instructions for all agents. Defaults to an empty string.\n        shared_files (Union[str, List[str]], optional): A path to a folder or a list of folders containing shared files for all agents. Defaults to None.\n        async_mode (str, optional): Specifies the mode for asynchronous processing. In \"threading\" mode, all sub-agents run in separate threads. In \"tools_threading\" mode, all tools run in separate threads, but agents do not. Defaults to None.\n        send_message_tool_class (Type[SendMessageBase], optional): The class to use for the send_message tool. For async communication, use `SendMessageAsyncThreading`. Defaults to SendMessage.\n        settings_path (str, optional): The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.\n        settings_callbacks (SettingsCallbacks, optional): A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n        threads_callbacks (ThreadsCallbacks, optional): A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n        temperature (float, optional): The temperature value to use for the agents. Agent-specific values will override this. Defaults to 0.3.\n        top_p (float, optional): The top_p value to use for the agents. Agent-specific values will override this. Defaults to None.\n        max_prompt_tokens (int, optional): The maximum number of tokens allowed in the prompt for each agent. Agent-specific values will override this. Defaults to None.\n        max_completion_tokens (int, optional): The maximum number of tokens allowed in the completion for each agent. Agent-specific values will override this. Defaults to None.\n        truncation_strategy (dict, optional): The truncation strategy to use for the completion for each agent. Agent-specific values will override this. Defaults to None.\n\n    This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.\n    \"\"\"\n    self.ceo = None\n    self.user = User()\n    self.agents = []\n    self.agents_and_threads = {}\n    self.main_recipients = []\n    self.main_thread = None\n    self.recipient_agents = None  # for autocomplete\n    self.shared_files = shared_files if shared_files else []\n    self.async_mode = async_mode\n    self.send_message_tool_class = send_message_tool_class\n    self.settings_path = settings_path\n    self.settings_callbacks = settings_callbacks\n    self.threads_callbacks = threads_callbacks\n    self.temperature = temperature\n    self.top_p = top_p\n    self.max_prompt_tokens = max_prompt_tokens\n    self.max_completion_tokens = max_completion_tokens\n    self.truncation_strategy = truncation_strategy\n\n    # set thread type based send_message_tool_class async mode\n    if (\n        hasattr(send_message_tool_class.ToolConfig, \"async_mode\")\n        and send_message_tool_class.ToolConfig.async_mode\n    ):\n        self._thread_type = ThreadAsync\n    else:\n        self._thread_type = Thread\n\n    if self.async_mode == \"threading\":\n        from agency_swarm.tools.send_message import SendMessageAsyncThreading\n\n        print(\n            \"Warning: 'threading' mode is deprecated. Please use send_message_tool_class = SendMessageAsyncThreading to use async communication.\"\n        )\n        self.send_message_tool_class = SendMessageAsyncThreading\n    elif self.async_mode == \"tools_threading\":\n        Thread.async_mode = \"tools_threading\"\n        print(\n            \"Warning: 'tools_threading' mode is deprecated. Use tool.ToolConfig.async_mode = 'threading' instead.\"\n        )\n    elif self.async_mode is None:\n        pass\n    else:\n        raise Exception(\n            \"Please select async_mode = 'threading' or 'tools_threading'.\"\n        )\n\n    if os.path.isfile(\n        os.path.join(self._get_class_folder_path(), shared_instructions)\n    ):\n        self._read_instructions(\n            os.path.join(self._get_class_folder_path(), shared_instructions)\n        )\n    elif os.path.isfile(shared_instructions):\n        self._read_instructions(shared_instructions)\n    else:\n        self.shared_instructions = shared_instructions\n\n    self.shared_state = SharedState()\n\n    self._parse_agency_chart(agency_chart)\n    self._init_threads()\n    self._create_special_tools()\n    self._init_agents()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._add_agent","title":"<code>_add_agent(agent)</code>","text":"<p>Adds an agent to the agency, assigning a temporary ID if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Agent</code> <p>The agent to be added to the agency.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The index of the added agent within the agency's agents list.</p> <p>This method adds an agent to the agency's list of agents. If the agent does not have an ID, it assigns a temporary unique ID. It checks for uniqueness of the agent's name before addition. The method returns the index of the agent in the agency's agents list, which is used for referencing the agent within the agency.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _add_agent(self, agent):\n    \"\"\"\n    Adds an agent to the agency, assigning a temporary ID if necessary.\n\n    Parameters:\n        agent (Agent): The agent to be added to the agency.\n\n    Returns:\n        int: The index of the added agent within the agency's agents list.\n\n    This method adds an agent to the agency's list of agents. If the agent does not have an ID, it assigns a temporary unique ID. It checks for uniqueness of the agent's name before addition. The method returns the index of the agent in the agency's agents list, which is used for referencing the agent within the agency.\n    \"\"\"\n    if not agent.id:\n        # assign temp id\n        agent.id = \"temp_id_\" + str(uuid.uuid4())\n    if agent.id not in self._get_agent_ids():\n        if agent.name in self._get_agent_names():\n            raise Exception(\"Agent names must be unique.\")\n        self.agents.append(agent)\n        return len(self.agents) - 1\n    else:\n        return self._get_agent_ids().index(agent.id)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._add_main_recipient","title":"<code>_add_main_recipient(agent)</code>","text":"<p>Adds an agent to the agency's list of main recipients.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Agent</code> <p>The agent to be added to the agency's list of main recipients.</p> required <p>This method adds an agent to the agency's list of main recipients. These are agents that can be directly contacted by the user.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _add_main_recipient(self, agent):\n    \"\"\"\n    Adds an agent to the agency's list of main recipients.\n\n    Parameters:\n        agent (Agent): The agent to be added to the agency's list of main recipients.\n\n    This method adds an agent to the agency's list of main recipients. These are agents that can be directly contacted by the user.\n    \"\"\"\n    main_recipient_ids = [agent.id for agent in self.main_recipients]\n\n    if agent.id not in main_recipient_ids:\n        self.main_recipients.append(agent)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._create_get_response_tool","title":"<code>_create_get_response_tool(agent, recipient_agents)</code>","text":"<p>Creates a CheckStatus tool to enable an agent to check the status of a task with a specified recipient agent.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _create_get_response_tool(self, agent: Agent, recipient_agents: List[Agent]):\n    \"\"\"\n    Creates a CheckStatus tool to enable an agent to check the status of a task with a specified recipient agent.\n    \"\"\"\n    recipient_names = [agent.name for agent in recipient_agents]\n    recipients = Enum(\"recipient\", {name: name for name in recipient_names})\n\n    outer_self = self\n\n    class GetResponse(BaseTool):\n        \"\"\"This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first.\"\"\"\n\n        recipient: recipients = Field(\n            ...,\n            description=f\"Recipient agent that you want to check the status of. Valid recipients are: {recipient_names}\",\n        )\n\n        @field_validator(\"recipient\")\n        def check_recipient(cls, value):\n            if value.value not in recipient_names:\n                raise ValueError(\n                    f\"Recipient {value} is not valid. Valid recipients are: {recipient_names}\"\n                )\n            return value\n\n        def run(self):\n            thread = outer_self.agents_and_threads[self._caller_agent.name][\n                self.recipient.value\n            ]\n\n            return thread.check_status()\n\n    GetResponse._caller_agent = agent\n\n    return GetResponse\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._create_send_message_tool","title":"<code>_create_send_message_tool(agent, recipient_agents)</code>","text":"<p>Creates a SendMessage tool to enable an agent to send messages to specified recipient agents.</p> <p>Parameters:</p> Name Type Description Default <code>agent</code> <code>Agent</code> <p>The agent who will be sending messages.</p> required <code>recipient_agents</code> <code>List[Agent]</code> <p>A list of recipient agents who can receive messages.</p> required <p>Returns:</p> Name Type Description <code>SendMessage</code> <p>A SendMessage tool class that is dynamically created and configured for the given agent and its recipient agents. This tool allows the agent to send messages to the specified recipients, facilitating inter-agent communication within the agency.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _create_send_message_tool(self, agent: Agent, recipient_agents: List[Agent]):\n    \"\"\"\n    Creates a SendMessage tool to enable an agent to send messages to specified recipient agents.\n\n\n    Parameters:\n        agent (Agent): The agent who will be sending messages.\n        recipient_agents (List[Agent]): A list of recipient agents who can receive messages.\n\n    Returns:\n        SendMessage: A SendMessage tool class that is dynamically created and configured for the given agent and its recipient agents. This tool allows the agent to send messages to the specified recipients, facilitating inter-agent communication within the agency.\n    \"\"\"\n    recipient_names = [agent.name for agent in recipient_agents]\n    recipients = Enum(\"recipient\", {name: name for name in recipient_names})\n\n    agent_descriptions = \"\"\n    for recipient_agent in recipient_agents:\n        if not recipient_agent.description:\n            continue\n        agent_descriptions += recipient_agent.name + \": \"\n        agent_descriptions += recipient_agent.description + \"\\n\"\n\n    class SendMessage(self.send_message_tool_class):\n        recipient: recipients = Field(..., description=agent_descriptions)\n\n        @field_validator(\"recipient\")\n        @classmethod\n        def check_recipient(cls, value):\n            if value.value not in recipient_names:\n                raise ValueError(\n                    f\"Recipient {value} is not valid. Valid recipients are: {recipient_names}\"\n                )\n            return value\n\n    SendMessage._caller_agent = agent\n    SendMessage._agents_and_threads = self.agents_and_threads\n\n    return SendMessage\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._create_special_tools","title":"<code>_create_special_tools()</code>","text":"<p>Creates and assigns 'SendMessage' tools to each agent based on the agency's structure.</p> <p>This method iterates through the agents and threads in the agency, creating SendMessage tools for each agent. These tools enable agents to send messages to other agents as defined in the agency's structure. The SendMessage tools are tailored to the specific recipient agents that each agent can communicate with.</p> <p>No input parameters.</p> <p>No output parameters; this method modifies the agents' toolset internally.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _create_special_tools(self):\n    \"\"\"\n    Creates and assigns 'SendMessage' tools to each agent based on the agency's structure.\n\n    This method iterates through the agents and threads in the agency, creating SendMessage tools for each agent. These tools enable agents to send messages to other agents as defined in the agency's structure. The SendMessage tools are tailored to the specific recipient agents that each agent can communicate with.\n\n    No input parameters.\n\n    No output parameters; this method modifies the agents' toolset internally.\n    \"\"\"\n    for agent_name, threads in self.agents_and_threads.items():\n        if agent_name == \"main_thread\":\n            continue\n        recipient_names = list(threads.keys())\n        recipient_agents = self._get_agents_by_names(recipient_names)\n        if len(recipient_agents) == 0:\n            continue\n        agent = self._get_agent_by_name(agent_name)\n        agent.add_tool(self._create_send_message_tool(agent, recipient_agents))\n        if self._thread_type == ThreadAsync:\n            agent.add_tool(self._create_get_response_tool(agent, recipient_agents))\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._get_agent_by_name","title":"<code>_get_agent_by_name(agent_name)</code>","text":"<p>Retrieves an agent from the agency based on the agent's name.</p> <p>Parameters:</p> Name Type Description Default <code>agent_name</code> <code>str</code> <p>The name of the agent to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>Agent</code> <p>The agent object with the specified name.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If no agent with the given name is found in the agency.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _get_agent_by_name(self, agent_name):\n    \"\"\"\n    Retrieves an agent from the agency based on the agent's name.\n\n    Parameters:\n        agent_name (str): The name of the agent to be retrieved.\n\n    Returns:\n        Agent: The agent object with the specified name.\n\n    Raises:\n        Exception: If no agent with the given name is found in the agency.\n    \"\"\"\n    for agent in self.agents:\n        if agent.name == agent_name:\n            return agent\n    raise Exception(f\"Agent {agent_name} not found.\")\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._get_agent_ids","title":"<code>_get_agent_ids()</code>","text":"<p>Retrieves the IDs of all agents currently in the agency.</p> <p>Returns:</p> Type Description <p>List[str]: A list containing the unique IDs of all agents.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _get_agent_ids(self):\n    \"\"\"\n    Retrieves the IDs of all agents currently in the agency.\n\n    Returns:\n        List[str]: A list containing the unique IDs of all agents.\n    \"\"\"\n    return [agent.id for agent in self.agents]\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._get_agent_names","title":"<code>_get_agent_names()</code>","text":"<p>Retrieves the names of all agents in the agency.</p> <p>Returns:</p> Type Description <p>List[str]: A list of names of all agents currently part of the agency.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _get_agent_names(self):\n    \"\"\"\n    Retrieves the names of all agents in the agency.\n\n    Returns:\n        List[str]: A list of names of all agents currently part of the agency.\n    \"\"\"\n    return [agent.name for agent in self.agents]\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._get_agents_by_names","title":"<code>_get_agents_by_names(agent_names)</code>","text":"<p>Retrieves a list of agent objects based on their names.</p> <p>Parameters:</p> Name Type Description Default <code>agent_names</code> <p>A list of strings representing the names of the agents to be retrieved.</p> required <p>Returns:</p> Type Description <p>A list of Agent objects corresponding to the given names.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _get_agents_by_names(self, agent_names):\n    \"\"\"\n    Retrieves a list of agent objects based on their names.\n\n    Parameters:\n        agent_names: A list of strings representing the names of the agents to be retrieved.\n\n    Returns:\n        A list of Agent objects corresponding to the given names.\n    \"\"\"\n    return [self._get_agent_by_name(agent_name) for agent_name in agent_names]\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._get_class_folder_path","title":"<code>_get_class_folder_path()</code>","text":"<p>Retrieves the absolute path of the directory containing the class file.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The absolute path of the directory where the class file is located.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _get_class_folder_path(self):\n    \"\"\"\n    Retrieves the absolute path of the directory containing the class file.\n\n    Returns:\n        str: The absolute path of the directory where the class file is located.\n    \"\"\"\n    return os.path.abspath(os.path.dirname(inspect.getfile(self.__class__)))\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._init_agents","title":"<code>_init_agents()</code>","text":"<p>Initializes all agents in the agency with unique IDs, shared instructions, and OpenAI models.</p> <p>This method iterates through each agent in the agency, assigns a unique ID, adds shared instructions, and initializes the OpenAI models for each agent.</p> <p>There are no input parameters.</p> <p>There are no output parameters as this method is used for internal initialization purposes within the Agency class.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _init_agents(self):\n    \"\"\"\n    Initializes all agents in the agency with unique IDs, shared instructions, and OpenAI models.\n\n    This method iterates through each agent in the agency, assigns a unique ID, adds shared instructions, and initializes the OpenAI models for each agent.\n\n    There are no input parameters.\n\n    There are no output parameters as this method is used for internal initialization purposes within the Agency class.\n    \"\"\"\n    if self.settings_callbacks:\n        loaded_settings = self.settings_callbacks[\"load\"]()\n        with open(self.settings_path, \"w\") as f:\n            json.dump(loaded_settings, f, indent=4)\n\n    for agent in self.agents:\n        if \"temp_id\" in agent.id:\n            agent.id = None\n\n        agent.add_shared_instructions(self.shared_instructions)\n        agent.settings_path = self.settings_path\n\n        if self.shared_files:\n            if isinstance(self.shared_files, str):\n                self.shared_files = [self.shared_files]\n\n            if isinstance(agent.files_folder, str):\n                agent.files_folder = [agent.files_folder]\n                agent.files_folder += self.shared_files\n            elif isinstance(agent.files_folder, list):\n                agent.files_folder += self.shared_files\n\n        if self.temperature is not None and agent.temperature is None:\n            agent.temperature = self.temperature\n        if self.top_p and agent.top_p is None:\n            agent.top_p = self.top_p\n        if self.max_prompt_tokens is not None and agent.max_prompt_tokens is None:\n            agent.max_prompt_tokens = self.max_prompt_tokens\n        if (\n            self.max_completion_tokens is not None\n            and agent.max_completion_tokens is None\n        ):\n            agent.max_completion_tokens = self.max_completion_tokens\n        if (\n            self.truncation_strategy is not None\n            and agent.truncation_strategy is None\n        ):\n            agent.truncation_strategy = self.truncation_strategy\n\n        if not agent.shared_state:\n            agent.shared_state = self.shared_state\n\n        agent.init_oai()\n\n    if self.settings_callbacks:\n        with open(self.agents[0].get_settings_path(), \"r\") as f:\n            settings = f.read()\n        settings = json.loads(settings)\n        self.settings_callbacks[\"save\"](settings)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._init_threads","title":"<code>_init_threads()</code>","text":"<p>Initializes threads for communication between agents within the agency.</p> <p>This method creates Thread objects for each pair of interacting agents as defined in the agents_and_threads attribute of the Agency. Each thread facilitates communication and task execution between an agent and its designated recipient agent.</p> <p>No input parameters.</p> Output Parameters <p>This method does not return any value but updates the agents_and_threads attribute with initialized Thread objects.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _init_threads(self):\n    \"\"\"\n    Initializes threads for communication between agents within the agency.\n\n    This method creates Thread objects for each pair of interacting agents as defined in the agents_and_threads attribute of the Agency. Each thread facilitates communication and task execution between an agent and its designated recipient agent.\n\n    No input parameters.\n\n    Output Parameters:\n        This method does not return any value but updates the agents_and_threads attribute with initialized Thread objects.\n    \"\"\"\n    self.main_thread = Thread(self.user, self.ceo)\n\n    # load thread ids\n    loaded_thread_ids = {}\n    if self.threads_callbacks:\n        loaded_thread_ids = self.threads_callbacks[\"load\"]()\n        if \"main_thread\" in loaded_thread_ids and loaded_thread_ids[\"main_thread\"]:\n            self.main_thread.id = loaded_thread_ids[\"main_thread\"]\n        else:\n            self.main_thread.init_thread()\n\n    # Save main_thread into agents_and_threads\n    self.agents_and_threads[\"main_thread\"] = self.main_thread\n\n    # initialize threads\n    for agent_name, threads in self.agents_and_threads.items():\n        if agent_name == \"main_thread\":\n            continue\n        for other_agent, items in threads.items():\n            # create thread class\n            self.agents_and_threads[agent_name][other_agent] = self._thread_type(\n                self._get_agent_by_name(items[\"agent\"]),\n                self._get_agent_by_name(items[\"recipient_agent\"]),\n            )\n\n            # load thread id if available\n            if (\n                agent_name in loaded_thread_ids\n                and other_agent in loaded_thread_ids[agent_name]\n            ):\n                self.agents_and_threads[agent_name][\n                    other_agent\n                ].id = loaded_thread_ids[agent_name][other_agent]\n            # init threads if threre are threads callbacks so the ids are saved for later use\n            elif self.threads_callbacks:\n                self.agents_and_threads[agent_name][other_agent].init_thread()\n\n    # save thread ids\n    if self.threads_callbacks:\n        loaded_thread_ids = {}\n        for agent_name, threads in self.agents_and_threads.items():\n            if agent_name == \"main_thread\":\n                continue\n            loaded_thread_ids[agent_name] = {}\n            for other_agent, thread in threads.items():\n                loaded_thread_ids[agent_name][other_agent] = thread.id\n\n        loaded_thread_ids[\"main_thread\"] = self.main_thread.id\n\n        self.threads_callbacks[\"save\"](loaded_thread_ids)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._parse_agency_chart","title":"<code>_parse_agency_chart(agency_chart)</code>","text":"<p>Parses the provided agency chart to initialize and organize agents within the agency.</p> <p>Parameters:</p> Name Type Description Default <code>agency_chart</code> <p>A structure representing the hierarchical organization of agents within the agency.     It can contain Agent objects and lists of Agent objects.</p> required <p>This method iterates through each node in the agency chart. If a node is an Agent, it is set as the CEO if not already assigned. If a node is a list, it iterates through the agents in the list, adding them to the agency and establishing communication threads between them. It raises an exception if the agency chart is invalid or if multiple CEOs are defined.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _parse_agency_chart(self, agency_chart):\n    \"\"\"\n    Parses the provided agency chart to initialize and organize agents within the agency.\n\n    Parameters:\n        agency_chart: A structure representing the hierarchical organization of agents within the agency.\n                It can contain Agent objects and lists of Agent objects.\n\n    This method iterates through each node in the agency chart. If a node is an Agent, it is set as the CEO if not already assigned.\n    If a node is a list, it iterates through the agents in the list, adding them to the agency and establishing communication\n    threads between them. It raises an exception if the agency chart is invalid or if multiple CEOs are defined.\n    \"\"\"\n    if not isinstance(agency_chart, list):\n        raise Exception(\"Invalid agency chart.\")\n\n    if len(agency_chart) == 0:\n        raise Exception(\"Agency chart cannot be empty.\")\n\n    for node in agency_chart:\n        if isinstance(node, Agent):\n            if not self.ceo:\n                self.ceo = node\n                self._add_agent(self.ceo)\n            else:\n                self._add_agent(node)\n            self._add_main_recipient(node)\n\n        elif isinstance(node, list):\n            for i, agent in enumerate(node):\n                if not isinstance(agent, Agent):\n                    raise Exception(\"Invalid agency chart.\")\n\n                index = self._add_agent(agent)\n\n                if i == len(node) - 1:\n                    continue\n\n                if agent.name not in self.agents_and_threads.keys():\n                    self.agents_and_threads[agent.name] = {}\n\n                if i &lt; len(node) - 1:\n                    other_agent = node[i + 1]\n                    if other_agent.name == agent.name:\n                        continue\n                    if (\n                        other_agent.name\n                        not in self.agents_and_threads[agent.name].keys()\n                    ):\n                        self.agents_and_threads[agent.name][other_agent.name] = {\n                            \"agent\": agent.name,\n                            \"recipient_agent\": other_agent.name,\n                        }\n        else:\n            raise Exception(\"Invalid agency chart.\")\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._read_instructions","title":"<code>_read_instructions(path)</code>","text":"<p>Reads shared instructions from a specified file and stores them in the agency.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The file path from which to read the shared instructions.</p> required <p>This method opens the file located at the given path, reads its contents, and stores these contents in the 'shared_instructions' attribute of the agency. This is used to provide common guidelines or instructions to all agents within the agency.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _read_instructions(self, path):\n    \"\"\"\n    Reads shared instructions from a specified file and stores them in the agency.\n\n    Parameters:\n        path (str): The file path from which to read the shared instructions.\n\n    This method opens the file located at the given path, reads its contents, and stores these contents in the 'shared_instructions' attribute of the agency. This is used to provide common guidelines or instructions to all agents within the agency.\n    \"\"\"\n    path = path\n    with open(path, \"r\") as f:\n        self.shared_instructions = f.read()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._recipient_agent_completer","title":"<code>_recipient_agent_completer(text, state)</code>","text":"<p>Autocomplete completer for recipient agent names.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _recipient_agent_completer(self, text, state):\n    \"\"\"\n    Autocomplete completer for recipient agent names.\n    \"\"\"\n    options = [\n        agent\n        for agent in self.recipient_agents\n        if agent.lower().startswith(text.lower())\n    ]\n    if state &lt; len(options):\n        return options[state]\n    else:\n        return None\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency._setup_autocomplete","title":"<code>_setup_autocomplete()</code>","text":"<p>Sets up readline with the completer function.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def _setup_autocomplete(self):\n    \"\"\"\n    Sets up readline with the completer function.\n    \"\"\"\n    try:\n        import readline\n    except ImportError:\n        # Attempt to import pyreadline for Windows compatibility\n        try:\n            import pyreadline as readline\n        except ImportError:\n            print(\n                \"Module 'readline' not found. Autocomplete will not work. If you are using Windows, try installing 'pyreadline3'.\"\n            )\n            return\n\n    if not readline:\n        return\n\n    try:\n        readline.set_completer(self._recipient_agent_completer)\n        readline.parse_and_bind(\"tab: complete\")\n    except Exception as e:\n        print(\n            f\"Error setting up autocomplete for agents in terminal: {e}. Autocomplete will not work.\"\n        )\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.delete","title":"<code>delete()</code>","text":"<p>This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def delete(self):\n    \"\"\"\n    This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.\n    \"\"\"\n    for agent in self.agents:\n        agent.delete()\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.demo_gradio","title":"<code>demo_gradio(height=450, dark_mode=True, **kwargs)</code>","text":"<p>Launches a Gradio-based demo interface for the agency chatbot.</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>The height of the chatbot widget in the Gradio interface. Default is 600.</p> <code>450</code> <code>dark_mode</code> <code>bool</code> <p>Flag to determine if the interface should be displayed in dark mode. Default is True.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the Gradio interface.</p> <code>{}</code> <p>This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def demo_gradio(self, height=450, dark_mode=True, **kwargs):\n    \"\"\"\n    Launches a Gradio-based demo interface for the agency chatbot.\n\n    Parameters:\n        height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 600.\n        dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.\n        **kwargs: Additional keyword arguments to be passed to the Gradio interface.\n    This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.\n    \"\"\"\n\n    try:\n        import gradio as gr\n    except ImportError:\n        raise Exception(\"Please install gradio: pip install gradio\")\n\n    js = \"\"\"function () {\n      gradioURL = window.location.href\n      if (!gradioURL.endsWith('?__theme={theme}')) {\n        window.location.replace(gradioURL + '?__theme={theme}');\n      }\n    }\"\"\"\n\n    if dark_mode:\n        js = js.replace(\"{theme}\", \"dark\")\n    else:\n        js = js.replace(\"{theme}\", \"light\")\n\n    attachments = []\n    images = []\n    message_file_names = None\n    uploading_files = False\n    recipient_agent_names = [agent.name for agent in self.main_recipients]\n    recipient_agent = self.main_recipients[0]\n\n    with gr.Blocks(js=js) as demo:\n        chatbot_queue = queue.Queue()\n        chatbot = gr.Chatbot(height=height)\n        with gr.Row():\n            with gr.Column(scale=9):\n                dropdown = gr.Dropdown(\n                    label=\"Recipient Agent\",\n                    choices=recipient_agent_names,\n                    value=recipient_agent.name,\n                )\n                msg = gr.Textbox(label=\"Your Message\", lines=4)\n            with gr.Column(scale=1):\n                file_upload = gr.Files(label=\"OpenAI Files\", type=\"filepath\")\n        button = gr.Button(value=\"Send\", variant=\"primary\")\n\n        def handle_dropdown_change(selected_option):\n            nonlocal recipient_agent\n            recipient_agent = self._get_agent_by_name(selected_option)\n\n        def handle_file_upload(file_list):\n            nonlocal attachments\n            nonlocal message_file_names\n            nonlocal uploading_files\n            nonlocal images\n            uploading_files = True\n            attachments = []\n            message_file_names = []\n            if file_list:\n                try:\n                    for file_obj in file_list:\n                        purpose = get_file_purpose(file_obj.name)\n\n                        with open(file_obj.name, \"rb\") as f:\n                            # Upload the file to OpenAI\n                            file = self.main_thread.client.files.create(\n                                file=f, purpose=purpose\n                            )\n\n                        if purpose == \"vision\":\n                            images.append(\n                                {\n                                    \"type\": \"image_file\",\n                                    \"image_file\": {\"file_id\": file.id},\n                                }\n                            )\n                        else:\n                            attachments.append(\n                                {\n                                    \"file_id\": file.id,\n                                    \"tools\": get_tools(file.filename),\n                                }\n                            )\n\n                        message_file_names.append(file.filename)\n                        print(f\"Uploaded file ID: {file.id}\")\n                    return attachments\n                except Exception as e:\n                    print(f\"Error: {e}\")\n                    return str(e)\n                finally:\n                    uploading_files = False\n\n            uploading_files = False\n            return \"No files uploaded\"\n\n        def user(user_message, history):\n            if not user_message.strip():\n                return user_message, history\n\n            nonlocal message_file_names\n            nonlocal uploading_files\n            nonlocal images\n            nonlocal attachments\n            nonlocal recipient_agent\n\n            # Check if attachments contain file search or code interpreter types\n            def check_and_add_tools_in_attachments(attachments, recipient_agent):\n                for attachment in attachments:\n                    for tool in attachment.get(\"tools\", []):\n                        if tool[\"type\"] == \"file_search\":\n                            if not any(\n                                isinstance(t, FileSearch)\n                                for t in recipient_agent.tools\n                            ):\n                                # Add FileSearch tool if it does not exist\n                                recipient_agent.tools.append(FileSearch)\n                                recipient_agent.client.beta.assistants.update(\n                                    recipient_agent.id,\n                                    tools=recipient_agent.get_oai_tools(),\n                                )\n                                print(\n                                    \"Added FileSearch tool to recipient agent to analyze the file.\"\n                                )\n                        elif tool[\"type\"] == \"code_interpreter\":\n                            if not any(\n                                isinstance(t, CodeInterpreter)\n                                for t in recipient_agent.tools\n                            ):\n                                # Add CodeInterpreter tool if it does not exist\n                                recipient_agent.tools.append(CodeInterpreter)\n                                recipient_agent.client.beta.assistants.update(\n                                    recipient_agent.id,\n                                    tools=recipient_agent.get_oai_tools(),\n                                )\n                                print(\n                                    \"Added CodeInterpreter tool to recipient agent to analyze the file.\"\n                                )\n                return None\n\n            check_and_add_tools_in_attachments(attachments, recipient_agent)\n\n            if history is None:\n                history = []\n\n            original_user_message = user_message\n\n            # Append the user message with a placeholder for bot response\n            if recipient_agent:\n                user_message = (\n                    f\"\ud83d\udc64 User \ud83d\udde3\ufe0f @{recipient_agent.name}:\\n\" + user_message.strip()\n                )\n            else:\n                user_message = f\"\ud83d\udc64 User:\" + user_message.strip()\n\n            nonlocal message_file_names\n            if message_file_names:\n                user_message += \"\\n\\n\ud83d\udcce Files:\\n\" + \"\\n\".join(message_file_names)\n\n            return original_user_message, history + [[user_message, None]]\n\n        class GradioEventHandler(AgencyEventHandler):\n            message_output = None\n\n            @classmethod\n            def change_recipient_agent(cls, recipient_agent_name):\n                nonlocal chatbot_queue\n                chatbot_queue.put(\"[change_recipient_agent]\")\n                chatbot_queue.put(recipient_agent_name)\n\n            @override\n            def on_message_created(self, message: Message) -&gt; None:\n                if message.role == \"user\":\n                    full_content = \"\"\n                    for content in message.content:\n                        if content.type == \"image_file\":\n                            full_content += (\n                                f\"\ud83d\uddbc\ufe0f Image File: {content.image_file.file_id}\\n\"\n                            )\n                            continue\n\n                        if content.type == \"image_url\":\n                            full_content += f\"\\n{content.image_url.url}\\n\"\n                            continue\n\n                        if content.type == \"text\":\n                            full_content += content.text.value + \"\\n\"\n\n                    self.message_output = MessageOutput(\n                        \"text\",\n                        self.agent_name,\n                        self.recipient_agent_name,\n                        full_content,\n                    )\n\n                else:\n                    self.message_output = MessageOutput(\n                        \"text\", self.recipient_agent_name, self.agent_name, \"\"\n                    )\n\n                chatbot_queue.put(\"[new_message]\")\n                chatbot_queue.put(self.message_output.get_formatted_content())\n\n            @override\n            def on_text_delta(self, delta, snapshot):\n                chatbot_queue.put(delta.value)\n\n            @override\n            def on_tool_call_created(self, tool_call: ToolCall):\n                if isinstance(tool_call, dict):\n                    if \"type\" not in tool_call:\n                        tool_call[\"type\"] = \"function\"\n\n                    if tool_call[\"type\"] == \"function\":\n                        tool_call = FunctionToolCall(**tool_call)\n                    elif tool_call[\"type\"] == \"code_interpreter\":\n                        tool_call = CodeInterpreterToolCall(**tool_call)\n                    elif (\n                        tool_call[\"type\"] == \"file_search\"\n                        or tool_call[\"type\"] == \"retrieval\"\n                    ):\n                        tool_call = FileSearchToolCall(**tool_call)\n                    else:\n                        raise ValueError(\n                            \"Invalid tool call type: \" + tool_call[\"type\"]\n                        )\n\n                # TODO: add support for code interpreter and retrieval tools\n                if tool_call.type == \"function\":\n                    chatbot_queue.put(\"[new_message]\")\n                    self.message_output = MessageOutput(\n                        \"function\",\n                        self.recipient_agent_name,\n                        self.agent_name,\n                        str(tool_call.function),\n                    )\n                    chatbot_queue.put(\n                        self.message_output.get_formatted_header() + \"\\n\"\n                    )\n\n            @override\n            def on_tool_call_done(self, snapshot: ToolCall):\n                if isinstance(snapshot, dict):\n                    if \"type\" not in snapshot:\n                        snapshot[\"type\"] = \"function\"\n\n                    if snapshot[\"type\"] == \"function\":\n                        snapshot = FunctionToolCall(**snapshot)\n                    elif snapshot[\"type\"] == \"code_interpreter\":\n                        snapshot = CodeInterpreterToolCall(**snapshot)\n                    elif snapshot[\"type\"] == \"file_search\":\n                        snapshot = FileSearchToolCall(**snapshot)\n                    else:\n                        raise ValueError(\n                            \"Invalid tool call type: \" + snapshot[\"type\"]\n                        )\n\n                self.message_output = None\n\n                # TODO: add support for code interpreter and retrieval tools\n                if snapshot.type != \"function\":\n                    return\n\n                chatbot_queue.put(str(snapshot.function))\n\n                if snapshot.function.name == \"SendMessage\":\n                    try:\n                        args = eval(snapshot.function.arguments)\n                        recipient = args[\"recipient\"]\n                        self.message_output = MessageOutput(\n                            \"text\",\n                            self.recipient_agent_name,\n                            recipient,\n                            args[\"message\"],\n                        )\n\n                        chatbot_queue.put(\"[new_message]\")\n                        chatbot_queue.put(\n                            self.message_output.get_formatted_content()\n                        )\n                    except Exception as e:\n                        pass\n\n                self.message_output = None\n\n            @override\n            def on_run_step_done(self, run_step: RunStep) -&gt; None:\n                if run_step.type == \"tool_calls\":\n                    for tool_call in run_step.step_details.tool_calls:\n                        if tool_call.type != \"function\":\n                            continue\n\n                        if tool_call.function.name == \"SendMessage\":\n                            continue\n\n                        self.message_output = None\n                        chatbot_queue.put(\"[new_message]\")\n\n                        self.message_output = MessageOutput(\n                            \"function_output\",\n                            tool_call.function.name,\n                            self.recipient_agent_name,\n                            tool_call.function.output,\n                        )\n\n                        chatbot_queue.put(\n                            self.message_output.get_formatted_header() + \"\\n\"\n                        )\n                        chatbot_queue.put(tool_call.function.output)\n\n            @override\n            @classmethod\n            def on_all_streams_end(cls):\n                cls.message_output = None\n                chatbot_queue.put(\"[end]\")\n\n        def bot(original_message, history, dropdown):\n            nonlocal attachments\n            nonlocal message_file_names\n            nonlocal recipient_agent\n            nonlocal recipient_agent_names\n            nonlocal images\n            nonlocal uploading_files\n\n            if not original_message:\n                return (\n                    \"\",\n                    history,\n                    gr.update(\n                        value=recipient_agent.name,\n                        choices=set([*recipient_agent_names, recipient_agent.name]),\n                    ),\n                )\n\n            if uploading_files:\n                history.append([None, \"Uploading files... Please wait.\"])\n                yield (\n                    \"\",\n                    history,\n                    gr.update(\n                        value=recipient_agent.name,\n                        choices=set([*recipient_agent_names, recipient_agent.name]),\n                    ),\n                )\n                return (\n                    \"\",\n                    history,\n                    gr.update(\n                        value=recipient_agent.name,\n                        choices=set([*recipient_agent_names, recipient_agent.name]),\n                    ),\n                )\n\n            print(\"Message files: \", attachments)\n            print(\"Images: \", images)\n\n            if images and len(images) &gt; 0:\n                original_message = [\n                    {\n                        \"type\": \"text\",\n                        \"text\": original_message,\n                    },\n                    *images,\n                ]\n\n            completion_thread = threading.Thread(\n                target=self.get_completion_stream,\n                args=(\n                    original_message,\n                    GradioEventHandler,\n                    [],\n                    recipient_agent,\n                    \"\",\n                    attachments,\n                    None,\n                ),\n            )\n            completion_thread.start()\n\n            attachments = []\n            message_file_names = []\n            images = []\n            uploading_files = False\n\n            new_message = True\n            while True:\n                try:\n                    bot_message = chatbot_queue.get(block=True)\n\n                    if bot_message == \"[end]\":\n                        completion_thread.join()\n                        break\n\n                    if bot_message == \"[new_message]\":\n                        new_message = True\n                        continue\n\n                    if bot_message == \"[change_recipient_agent]\":\n                        new_agent_name = chatbot_queue.get(block=True)\n                        recipient_agent = self._get_agent_by_name(new_agent_name)\n                        yield (\n                            \"\",\n                            history,\n                            gr.update(\n                                value=new_agent_name,\n                                choices=set(\n                                    [*recipient_agent_names, recipient_agent.name]\n                                ),\n                            ),\n                        )\n                        continue\n\n                    if new_message:\n                        history.append([None, bot_message])\n                        new_message = False\n                    else:\n                        history[-1][1] += bot_message\n\n                    yield (\n                        \"\",\n                        history,\n                        gr.update(\n                            value=recipient_agent.name,\n                            choices=set(\n                                [*recipient_agent_names, recipient_agent.name]\n                            ),\n                        ),\n                    )\n                except queue.Empty:\n                    break\n\n        button.click(user, inputs=[msg, chatbot], outputs=[msg, chatbot]).then(\n            bot, [msg, chatbot, dropdown], [msg, chatbot, dropdown]\n        )\n        dropdown.change(handle_dropdown_change, dropdown)\n        file_upload.change(handle_file_upload, file_upload)\n        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n            bot, [msg, chatbot, dropdown], [msg, chatbot, dropdown]\n        )\n\n        # Enable queuing for streaming intermediate outputs\n        demo.queue(default_concurrency_limit=10)\n\n    # Launch the demo\n    demo.launch(**kwargs)\n    return demo\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_completion","title":"<code>get_completion(message, message_files=None, yield_messages=False, recipient_agent=None, additional_instructions=None, attachments=None, tool_choice=None, verbose=False, response_format=None)</code>","text":"<p>Retrieves the completion for a given message from the main thread.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message for which completion is to be retrieved.</p> required <code>message_files</code> <code>list</code> <p>A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.</p> <code>None</code> <code>yield_messages</code> <code>bool</code> <p>Flag to determine if intermediate messages should be yielded. Defaults to True.</p> <code>False</code> <code>recipient_agent</code> <code>Agent</code> <p>The agent to which the message should be sent. Defaults to the first agent in the agency chart.</p> <code>None</code> <code>additional_instructions</code> <code>str</code> <p>Additional instructions to be sent with the message. Defaults to None.</p> <code>None</code> <code>attachments</code> <code>List[dict]</code> <p>A list of attachments to be sent with the message, following openai format. Defaults to None.</p> <code>None</code> <code>tool_choice</code> <code>dict</code> <p>The tool choice for the recipient agent to use. Defaults to None.</p> <code>None</code> <code>parallel_tool_calls</code> <code>bool</code> <p>Whether to enable parallel function calling during tool use. Defaults to True.</p> required <code>verbose</code> <code>bool</code> <p>Whether to print the intermediary messages in console. Defaults to False.</p> <code>False</code> <code>response_format</code> <code>dict</code> <p>The response format to use for the completion.</p> <code>None</code> <p>Returns:</p> Type Description <p>Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_completion(\n    self,\n    message: str,\n    message_files: List[str] = None,\n    yield_messages: bool = False,\n    recipient_agent: Agent = None,\n    additional_instructions: str = None,\n    attachments: List[dict] = None,\n    tool_choice: dict = None,\n    verbose: bool = False,\n    response_format: dict = None,\n):\n    \"\"\"\n    Retrieves the completion for a given message from the main thread.\n\n    Parameters:\n        message (str): The message for which completion is to be retrieved.\n        message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n        yield_messages (bool, optional): Flag to determine if intermediate messages should be yielded. Defaults to True.\n        recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n        additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n        attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n        tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n        parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n        verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.\n        response_format (dict, optional): The response format to use for the completion.\n\n    Returns:\n        Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.\n    \"\"\"\n    if verbose and yield_messages:\n        raise Exception(\"Verbose mode is not compatible with yield_messages=True\")\n\n    res = self.main_thread.get_completion(\n        message=message,\n        message_files=message_files,\n        attachments=attachments,\n        recipient_agent=recipient_agent,\n        additional_instructions=additional_instructions,\n        tool_choice=tool_choice,\n        yield_messages=yield_messages or verbose,\n        response_format=response_format,\n    )\n\n    if not yield_messages or verbose:\n        while True:\n            try:\n                message = next(res)\n                if verbose:\n                    message.cprint()\n            except StopIteration as e:\n                return e.value\n\n    return res\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_completion_parse","title":"<code>get_completion_parse(message, response_format, message_files=None, recipient_agent=None, additional_instructions=None, attachments=None, tool_choice=None, verbose=False)</code>","text":"<p>Retrieves the completion for a given message from the main thread and parses the response using the provided pydantic model.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message for which completion is to be retrieved.</p> required <code>response_format</code> <code>type(BaseModel</code> <p>The response format to use for the completion.</p> required <code>message_files</code> <code>list</code> <p>A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.</p> <code>None</code> <code>recipient_agent</code> <code>Agent</code> <p>The agent to which the message should be sent. Defaults to the first agent in the agency chart.</p> <code>None</code> <code>additional_instructions</code> <code>str</code> <p>Additional instructions to be sent with the message. Defaults to None.</p> <code>None</code> <code>attachments</code> <code>List[dict]</code> <p>A list of attachments to be sent with the message, following openai format. Defaults to None.</p> <code>None</code> <code>tool_choice</code> <code>dict</code> <p>The tool choice for the recipient agent to use. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to print the intermediary messages in console. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>T</code> <p>Final response: The final response from the main thread, parsed using the provided pydantic model.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_completion_parse(\n    self,\n    message: str,\n    response_format: Type[T],\n    message_files: List[str] = None,\n    recipient_agent: Agent = None,\n    additional_instructions: str = None,\n    attachments: List[dict] = None,\n    tool_choice: dict = None,\n    verbose: bool = False,\n) -&gt; T:\n    \"\"\"\n    Retrieves the completion for a given message from the main thread and parses the response using the provided pydantic model.\n\n    Parameters:\n        message (str): The message for which completion is to be retrieved.\n        response_format (type(BaseModel)): The response format to use for the completion.\n        message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n        recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n        additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n        attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n        tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n        verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.\n\n    Returns:\n        Final response: The final response from the main thread, parsed using the provided pydantic model.\n    \"\"\"\n    response_model = None\n    if isinstance(response_format, type):\n        response_model = response_format\n        response_format = type_to_response_format_param(response_format)\n\n    res = self.get_completion(\n        message=message,\n        message_files=message_files,\n        recipient_agent=recipient_agent,\n        additional_instructions=additional_instructions,\n        attachments=attachments,\n        tool_choice=tool_choice,\n        response_format=response_format,\n        verbose=verbose,\n    )\n\n    try:\n        return response_model.model_validate_json(res)\n    except:\n        parsed_res = json.loads(res)\n        if \"refusal\" in parsed_res:\n            raise RefusalError(parsed_res[\"refusal\"])\n        else:\n            raise Exception(\"Failed to parse response: \" + res)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_completion_stream","title":"<code>get_completion_stream(message, event_handler, message_files=None, recipient_agent=None, additional_instructions=None, attachments=None, tool_choice=None, response_format=None)</code>","text":"<p>Generates a stream of completions for a given message from the main thread.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>The message for which completion is to be retrieved.</p> required <code>event_handler</code> <code>type(AgencyEventHandler</code> <p>The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md</p> required <code>message_files</code> <code>list</code> <p>A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.</p> <code>None</code> <code>recipient_agent</code> <code>Agent</code> <p>The agent to which the message should be sent. Defaults to the first agent in the agency chart.</p> <code>None</code> <code>additional_instructions</code> <code>str</code> <p>Additional instructions to be sent with the message. Defaults to None.</p> <code>None</code> <code>attachments</code> <code>List[dict]</code> <p>A list of attachments to be sent with the message, following openai format. Defaults to None.</p> <code>None</code> <code>tool_choice</code> <code>dict</code> <p>The tool choice for the recipient agent to use. Defaults to None.</p> <code>None</code> <code>parallel_tool_calls</code> <code>bool</code> <p>Whether to enable parallel function calling during tool use. Defaults to True.</p> required <p>Returns:</p> Type Description <p>Final response: Final response from the main thread.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_completion_stream(\n    self,\n    message: str,\n    event_handler: type(AgencyEventHandler),\n    message_files: List[str] = None,\n    recipient_agent: Agent = None,\n    additional_instructions: str = None,\n    attachments: List[dict] = None,\n    tool_choice: dict = None,\n    response_format: dict = None,\n):\n    \"\"\"\n    Generates a stream of completions for a given message from the main thread.\n\n    Parameters:\n        message (str): The message for which completion is to be retrieved.\n        event_handler (type(AgencyEventHandler)): The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md\n        message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n        recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n        additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n        attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n        tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n        parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n\n    Returns:\n        Final response: Final response from the main thread.\n    \"\"\"\n    if not inspect.isclass(event_handler):\n        raise Exception(\"Event handler must not be an instance.\")\n\n    res = self.main_thread.get_completion_stream(\n        message=message,\n        message_files=message_files,\n        event_handler=event_handler,\n        attachments=attachments,\n        recipient_agent=recipient_agent,\n        additional_instructions=additional_instructions,\n        tool_choice=tool_choice,\n        response_format=response_format,\n    )\n\n    while True:\n        try:\n            next(res)\n        except StopIteration as e:\n            event_handler.on_all_streams_end()\n\n            return e.value\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.get_customgpt_schema","title":"<code>get_customgpt_schema(url)</code>","text":"<p>Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Your server url where the api will be hosted.</p> required Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def get_customgpt_schema(self, url: str):\n    \"\"\"Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.\n\n    Parameters:\n        url (str): Your server url where the api will be hosted.\n    \"\"\"\n\n    return self.ceo.get_openapi_schema(url)\n</code></pre>"},{"location":"api/#agency_swarm.agency.agency.Agency.run_demo","title":"<code>run_demo()</code>","text":"<p>Executes agency in the terminal with autocomplete for recipient agent names.</p> Source code in <code>agency_swarm/agency/agency.py</code> <pre><code>def run_demo(self):\n    \"\"\"\n    Executes agency in the terminal with autocomplete for recipient agent names.\n    \"\"\"\n    outer_self = self\n    from agency_swarm import AgencyEventHandler\n\n    class TermEventHandler(AgencyEventHandler):\n        message_output = None\n\n        @override\n        def on_message_created(self, message: Message) -&gt; None:\n            if message.role == \"user\":\n                self.message_output = MessageOutputLive(\n                    \"text\", self.agent_name, self.recipient_agent_name, \"\"\n                )\n                self.message_output.cprint_update(message.content[0].text.value)\n            else:\n                self.message_output = MessageOutputLive(\n                    \"text\", self.recipient_agent_name, self.agent_name, \"\"\n                )\n\n        @override\n        def on_message_done(self, message: Message) -&gt; None:\n            self.message_output = None\n\n        @override\n        def on_text_delta(self, delta, snapshot):\n            self.message_output.cprint_update(snapshot.value)\n\n        @override\n        def on_tool_call_created(self, tool_call):\n            if isinstance(tool_call, dict):\n                if \"type\" not in tool_call:\n                    tool_call[\"type\"] = \"function\"\n\n                if tool_call[\"type\"] == \"function\":\n                    tool_call = FunctionToolCall(**tool_call)\n                elif tool_call[\"type\"] == \"code_interpreter\":\n                    tool_call = CodeInterpreterToolCall(**tool_call)\n                elif (\n                    tool_call[\"type\"] == \"file_search\"\n                    or tool_call[\"type\"] == \"retrieval\"\n                ):\n                    tool_call = FileSearchToolCall(**tool_call)\n                else:\n                    raise ValueError(\"Invalid tool call type: \" + tool_call[\"type\"])\n\n            # TODO: add support for code interpreter and retirieval tools\n\n            if tool_call.type == \"function\":\n                self.message_output = MessageOutputLive(\n                    \"function\",\n                    self.recipient_agent_name,\n                    self.agent_name,\n                    str(tool_call.function),\n                )\n\n        @override\n        def on_tool_call_delta(self, delta, snapshot):\n            if isinstance(snapshot, dict):\n                if \"type\" not in snapshot:\n                    snapshot[\"type\"] = \"function\"\n\n                if snapshot[\"type\"] == \"function\":\n                    snapshot = FunctionToolCall(**snapshot)\n                elif snapshot[\"type\"] == \"code_interpreter\":\n                    snapshot = CodeInterpreterToolCall(**snapshot)\n                elif snapshot[\"type\"] == \"file_search\":\n                    snapshot = FileSearchToolCall(**snapshot)\n                else:\n                    raise ValueError(\"Invalid tool call type: \" + snapshot[\"type\"])\n\n            self.message_output.cprint_update(str(snapshot.function))\n\n        @override\n        def on_tool_call_done(self, snapshot):\n            self.message_output = None\n\n            # TODO: add support for code interpreter and retrieval tools\n            if snapshot.type != \"function\":\n                return\n\n            if snapshot.function.name == \"SendMessage\" and not (\n                hasattr(\n                    outer_self.send_message_tool_class.ToolConfig,\n                    \"output_as_result\",\n                )\n                and outer_self.send_message_tool_class.ToolConfig.output_as_result\n            ):\n                try:\n                    args = eval(snapshot.function.arguments)\n                    recipient = args[\"recipient\"]\n                    self.message_output = MessageOutputLive(\n                        \"text\", self.recipient_agent_name, recipient, \"\"\n                    )\n\n                    self.message_output.cprint_update(args[\"message\"])\n                except Exception as e:\n                    pass\n\n            self.message_output = None\n\n        @override\n        def on_run_step_done(self, run_step: RunStep) -&gt; None:\n            if run_step.type == \"tool_calls\":\n                for tool_call in run_step.step_details.tool_calls:\n                    if tool_call.type != \"function\":\n                        continue\n\n                    if tool_call.function.name == \"SendMessage\":\n                        continue\n\n                    self.message_output = None\n                    self.message_output = MessageOutputLive(\n                        \"function_output\",\n                        tool_call.function.name,\n                        self.recipient_agent_name,\n                        tool_call.function.output,\n                    )\n                    self.message_output.cprint_update(tool_call.function.output)\n\n                self.message_output = None\n\n        @override\n        def on_end(self):\n            self.message_output = None\n\n    self.recipient_agents = [str(agent.name) for agent in self.main_recipients]\n\n    self._setup_autocomplete()  # Prepare readline for autocomplete\n\n    while True:\n        console.rule()\n        text = input(\"\ud83d\udc64 USER: \")\n\n        if not text:\n            continue\n\n        if text.lower() == \"exit\":\n            break\n\n        recipient_agent = None\n        if \"@\" in text:\n            recipient_agent = text.split(\"@\")[1].split(\" \")[0]\n            text = text.replace(f\"@{recipient_agent}\", \"\").strip()\n            try:\n                recipient_agent = [\n                    agent\n                    for agent in self.recipient_agents\n                    if agent.lower() == recipient_agent.lower()\n                ][0]\n                recipient_agent = self._get_agent_by_name(recipient_agent)\n            except Exception as e:\n                print(f\"Recipient agent {recipient_agent} not found.\")\n                continue\n\n        self.get_completion_stream(\n            message=text,\n            event_handler=TermEventHandler,\n            recipient_agent=recipient_agent,\n        )\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory","title":"<code>ToolFactory</code>","text":"Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>class ToolFactory:\n    @staticmethod\n    def from_langchain_tools(tools: List) -&gt; List[Type[BaseTool]]:\n        \"\"\"\n        Converts a list of langchain tools into a list of BaseTools.\n\n        Parameters:\n            tools: The langchain tools to convert.\n\n        Returns:\n            A list of BaseTools.\n        \"\"\"\n        converted_tools = []\n        for tool in tools:\n            converted_tools.append(ToolFactory.from_langchain_tool(tool))\n\n        return converted_tools\n\n    @staticmethod\n    def from_langchain_tool(tool) -&gt; Type[BaseTool]:\n        \"\"\"\n        Converts a langchain tool into a BaseTool.\n\n        Parameters:\n            tool: The langchain tool to convert.\n\n        Returns:\n            A BaseTool.\n        \"\"\"\n        try:\n            from langchain.tools import format_tool_to_openai_function\n        except ImportError:\n            raise ImportError(\"You must install langchain to use this method.\")\n\n        if inspect.isclass(tool):\n            tool = tool()\n\n        def callback(self):\n            tool_input = self.model_dump()\n            try:\n                return tool.run(tool_input)\n            except TypeError:\n                if len(tool_input) == 1:\n                    return tool.run(list(tool_input.values())[0])\n                else:\n                    raise TypeError(\n                        f\"Error parsing input for tool '{tool.__class__.__name__}' Please open an issue \"\n                        f\"on github.\"\n                    )\n\n        return ToolFactory.from_openai_schema(\n            format_tool_to_openai_function(tool), callback\n        )\n\n    @staticmethod\n    def from_openai_schema(schema: Dict[str, Any], callback: Any) -&gt; Type[BaseTool]:\n        \"\"\"\n        Converts an OpenAI schema into a BaseTool.\n\n        Parameters:\n            schema: The OpenAI schema to convert.\n            callback: The function to run when the tool is called.\n\n        Returns:\n            A BaseTool.\n        \"\"\"\n        data_model_types = get_data_model_types(\n            DataModelType.PydanticV2BaseModel, target_python_version=PythonVersion.PY_37\n        )\n\n        parser = JsonSchemaParser(\n            json.dumps(schema[\"parameters\"]),\n            data_model_type=data_model_types.data_model,\n            data_model_root_type=data_model_types.root_model,\n            data_model_field_type=data_model_types.field_model,\n            data_type_manager_type=data_model_types.data_type_manager,\n            dump_resolve_reference_action=data_model_types.dump_resolve_reference_action,\n            use_schema_description=True,\n            validation=False,\n            class_name=\"Model\",\n            # custom_template_dir=Path('/Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/tools/data_schema_templates')\n        )\n\n        result = parser.parse()\n\n        # # Execute the result to extract the model\n        exec_globals = {}\n        exec(result, exec_globals)\n        model = exec_globals.get(\"Model\")\n\n        if not model:\n            raise ValueError(f\"Could not extract model from schema {schema['name']}\")\n\n        class ToolConfig:\n            strict: bool = schema.get(\"strict\", False)\n\n        tool = type(\n            schema[\"name\"],\n            (BaseTool, model),\n            {\n                \"__doc__\": schema.get(\"description\", \"\"),\n                \"run\": callback,\n            },\n        )\n\n        tool.ToolConfig = ToolConfig\n\n        return tool\n\n    @staticmethod\n    def from_openapi_schema(\n        schema: Union[str, dict],\n        headers: Dict[str, str] = None,\n        params: Dict[str, Any] = None,\n        strict: bool = False,\n    ) -&gt; List[Type[BaseTool]]:\n        \"\"\"\n        Converts an OpenAPI schema into a list of BaseTools.\n\n        Parameters:\n            schema: The OpenAPI schema to convert.\n            headers: The headers to use for requests.\n            params: The parameters to use for requests.\n            strict: Whether to use strict OpenAI mode.\n        Returns:\n            A list of BaseTools.\n        \"\"\"\n        if isinstance(schema, dict):\n            openapi_spec = schema\n            openapi_spec = jsonref.JsonRef.replace_refs(openapi_spec)\n        else:\n            openapi_spec = jsonref.loads(schema)\n        tools = []\n        headers = headers or {}\n        headers = {k: v for k, v in headers.items() if v is not None}\n        for path, methods in openapi_spec[\"paths\"].items():\n            for method, spec_with_ref in methods.items():\n\n                async def callback(self):\n                    url = openapi_spec[\"servers\"][0][\"url\"] + path\n                    parameters = self.model_dump().get(\"parameters\", {})\n                    # replace all parameters in url\n                    for param, value in parameters.items():\n                        if \"{\" + str(param) + \"}\" in url:\n                            url = url.replace(f\"{{{param}}}\", str(value))\n                            parameters[param] = None\n                    url = url.rstrip(\"/\")\n                    parameters = {k: v for k, v in parameters.items() if v is not None}\n                    parameters = {**parameters, **params} if params else parameters\n                    async with httpx.AsyncClient(\n                        timeout=90\n                    ) as client:  # Set custom read timeout to 10 seconds\n                        if method == \"get\":\n                            response = await client.get(\n                                url, params=parameters, headers=headers\n                            )\n                        elif method == \"post\":\n                            response = await client.post(\n                                url,\n                                params=parameters,\n                                json=self.model_dump().get(\"requestBody\", None),\n                                headers=headers,\n                            )\n                        elif method == \"put\":\n                            response = await client.put(\n                                url,\n                                params=parameters,\n                                json=self.model_dump().get(\"requestBody\", None),\n                                headers=headers,\n                            )\n                        elif method == \"delete\":\n                            response = await client.delete(\n                                url,\n                                params=parameters,\n                                json=self.model_dump().get(\"requestBody\", None),\n                                headers=headers,\n                            )\n                        return response.json()\n\n                # 1. Resolve JSON references.\n                spec = jsonref.replace_refs(spec_with_ref)\n\n                # 2. Extract a name for the functions.\n                function_name = spec.get(\"operationId\")\n\n                # 3. Extract a description and parameters.\n                desc = spec.get(\"description\") or spec.get(\"summary\", \"\")\n\n                schema = {\"type\": \"object\", \"properties\": {}}\n\n                req_body = (\n                    spec.get(\"requestBody\", {})\n                    .get(\"content\", {})\n                    .get(\"application/json\", {})\n                    .get(\"schema\")\n                )\n                if req_body:\n                    schema[\"properties\"][\"requestBody\"] = req_body\n\n                spec_params = spec.get(\"parameters\", [])\n                if spec_params:\n                    param_properties = {}\n                    required_params = []\n                    for param in spec_params:\n                        if \"schema\" not in param and \"type\" in param:\n                            param[\"schema\"] = {\"type\": param[\"type\"]}\n                        param_properties[param[\"name\"]] = param[\"schema\"]\n                        if \"description\" in param:\n                            param_properties[param[\"name\"]][\"description\"] = param[\n                                \"description\"\n                            ]\n                        if \"required\" in param and param[\"required\"]:\n                            required_params.append(param[\"name\"])\n                        if \"example\" in param:\n                            param_properties[param[\"name\"]][\"example\"] = param[\n                                \"example\"\n                            ]\n                        if \"examples\" in param:\n                            param_properties[param[\"name\"]][\"examples\"] = param[\n                                \"examples\"\n                            ]\n\n                    schema[\"properties\"][\"parameters\"] = {\n                        \"type\": \"object\",\n                        \"properties\": param_properties,\n                        \"required\": required_params,\n                    }\n\n                function = {\n                    \"name\": function_name,\n                    \"description\": desc,\n                    \"parameters\": schema,\n                    \"strict\": strict,\n                }\n\n                tools.append(ToolFactory.from_openai_schema(function, callback))\n\n        return tools\n\n    @staticmethod\n    def from_file(file_path: str) -&gt; Type[BaseTool]:\n        \"\"\"Dynamically imports a BaseTool class from a Python file within a package structure.\n\n        Parameters:\n            file_path: The file path to the Python file containing the BaseTool class.\n\n        Returns:\n            The imported BaseTool class.\n        \"\"\"\n        file_path = os.path.relpath(file_path)\n        # Normalize the file path to be absolute and extract components\n        directory, file_name = os.path.split(file_path)\n        import_path = os.path.splitext(file_path)[0].replace(os.sep, \".\")\n        class_name = os.path.splitext(file_name)[0]\n\n        exec_globals = globals()\n\n        # importing from agency_swarm package\n        if \"agency_swarm\" in import_path:\n            import_path = import_path.lstrip(\".\")\n            exec(f\"from {import_path} import {class_name}\", exec_globals)\n        # importing from current working directory\n        else:\n            current_working_directory = os.getcwd()\n            sys.path.append(current_working_directory)\n            exec(f\"from {import_path} import {class_name}\", exec_globals)\n\n        imported_class = exec_globals.get(class_name)\n        if not imported_class:\n            raise ImportError(f\"Could not import {class_name} from {import_path}\")\n\n        # Check if the imported class is a subclass of BaseTool\n        if not issubclass(imported_class, BaseTool):\n            raise TypeError(f\"Class {class_name} must be a subclass of BaseTool\")\n\n        return imported_class\n\n    @staticmethod\n    def get_openapi_schema(\n        tools: List[Type[BaseTool]],\n        url: str,\n        title=\"Agent Tools\",\n        description=\"A collection of tools.\",\n    ) -&gt; str:\n        \"\"\"\n        Generates an OpenAPI schema from a list of BaseTools.\n\n        Parameters:\n            tools: BaseTools to generate the schema from.\n            url: The base URL for the schema.\n            title: The title of the schema.\n            description: The description of the schema.\n\n        Returns:\n            A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.\n        \"\"\"\n        schema = {\n            \"openapi\": \"3.1.0\",\n            \"info\": {\"title\": title, \"description\": description, \"version\": \"v1.0.0\"},\n            \"servers\": [\n                {\n                    \"url\": url,\n                }\n            ],\n            \"paths\": {},\n            \"components\": {\n                \"schemas\": {},\n                \"securitySchemes\": {\"apiKey\": {\"type\": \"apiKey\"}},\n            },\n        }\n\n        for tool in tools:\n            if not issubclass(tool, BaseTool):\n                continue\n\n            openai_schema = tool.openai_schema\n            defs = {}\n            if \"$defs\" in openai_schema[\"parameters\"]:\n                defs = openai_schema[\"parameters\"][\"$defs\"]\n                del openai_schema[\"parameters\"][\"$defs\"]\n\n            schema[\"paths\"][\"/\" + openai_schema[\"name\"]] = {\n                \"post\": {\n                    \"description\": openai_schema[\"description\"],\n                    \"operationId\": openai_schema[\"name\"],\n                    \"x-openai-isConsequential\": False,\n                    \"parameters\": [],\n                    \"requestBody\": {\n                        \"content\": {\n                            \"application/json\": {\"schema\": openai_schema[\"parameters\"]}\n                        }\n                    },\n                }\n            }\n\n            schema[\"components\"][\"schemas\"].update(defs)\n\n        schema = json.dumps(schema, indent=2).replace(\n            \"#/$defs/\", \"#/components/schemas/\"\n        )\n\n        return schema\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_file","title":"<code>from_file(file_path)</code>  <code>staticmethod</code>","text":"<p>Dynamically imports a BaseTool class from a Python file within a package structure.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The file path to the Python file containing the BaseTool class.</p> required <p>Returns:</p> Type Description <code>Type[BaseTool]</code> <p>The imported BaseTool class.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_file(file_path: str) -&gt; Type[BaseTool]:\n    \"\"\"Dynamically imports a BaseTool class from a Python file within a package structure.\n\n    Parameters:\n        file_path: The file path to the Python file containing the BaseTool class.\n\n    Returns:\n        The imported BaseTool class.\n    \"\"\"\n    file_path = os.path.relpath(file_path)\n    # Normalize the file path to be absolute and extract components\n    directory, file_name = os.path.split(file_path)\n    import_path = os.path.splitext(file_path)[0].replace(os.sep, \".\")\n    class_name = os.path.splitext(file_name)[0]\n\n    exec_globals = globals()\n\n    # importing from agency_swarm package\n    if \"agency_swarm\" in import_path:\n        import_path = import_path.lstrip(\".\")\n        exec(f\"from {import_path} import {class_name}\", exec_globals)\n    # importing from current working directory\n    else:\n        current_working_directory = os.getcwd()\n        sys.path.append(current_working_directory)\n        exec(f\"from {import_path} import {class_name}\", exec_globals)\n\n    imported_class = exec_globals.get(class_name)\n    if not imported_class:\n        raise ImportError(f\"Could not import {class_name} from {import_path}\")\n\n    # Check if the imported class is a subclass of BaseTool\n    if not issubclass(imported_class, BaseTool):\n        raise TypeError(f\"Class {class_name} must be a subclass of BaseTool\")\n\n    return imported_class\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_langchain_tool","title":"<code>from_langchain_tool(tool)</code>  <code>staticmethod</code>","text":"<p>Converts a langchain tool into a BaseTool.</p> <p>Parameters:</p> Name Type Description Default <code>tool</code> <p>The langchain tool to convert.</p> required <p>Returns:</p> Type Description <code>Type[BaseTool]</code> <p>A BaseTool.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_langchain_tool(tool) -&gt; Type[BaseTool]:\n    \"\"\"\n    Converts a langchain tool into a BaseTool.\n\n    Parameters:\n        tool: The langchain tool to convert.\n\n    Returns:\n        A BaseTool.\n    \"\"\"\n    try:\n        from langchain.tools import format_tool_to_openai_function\n    except ImportError:\n        raise ImportError(\"You must install langchain to use this method.\")\n\n    if inspect.isclass(tool):\n        tool = tool()\n\n    def callback(self):\n        tool_input = self.model_dump()\n        try:\n            return tool.run(tool_input)\n        except TypeError:\n            if len(tool_input) == 1:\n                return tool.run(list(tool_input.values())[0])\n            else:\n                raise TypeError(\n                    f\"Error parsing input for tool '{tool.__class__.__name__}' Please open an issue \"\n                    f\"on github.\"\n                )\n\n    return ToolFactory.from_openai_schema(\n        format_tool_to_openai_function(tool), callback\n    )\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_langchain_tools","title":"<code>from_langchain_tools(tools)</code>  <code>staticmethod</code>","text":"<p>Converts a list of langchain tools into a list of BaseTools.</p> <p>Parameters:</p> Name Type Description Default <code>tools</code> <code>List</code> <p>The langchain tools to convert.</p> required <p>Returns:</p> Type Description <code>List[Type[BaseTool]]</code> <p>A list of BaseTools.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_langchain_tools(tools: List) -&gt; List[Type[BaseTool]]:\n    \"\"\"\n    Converts a list of langchain tools into a list of BaseTools.\n\n    Parameters:\n        tools: The langchain tools to convert.\n\n    Returns:\n        A list of BaseTools.\n    \"\"\"\n    converted_tools = []\n    for tool in tools:\n        converted_tools.append(ToolFactory.from_langchain_tool(tool))\n\n    return converted_tools\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_openai_schema","title":"<code>from_openai_schema(schema, callback)</code>  <code>staticmethod</code>","text":"<p>Converts an OpenAI schema into a BaseTool.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Dict[str, Any]</code> <p>The OpenAI schema to convert.</p> required <code>callback</code> <code>Any</code> <p>The function to run when the tool is called.</p> required <p>Returns:</p> Type Description <code>Type[BaseTool]</code> <p>A BaseTool.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_openai_schema(schema: Dict[str, Any], callback: Any) -&gt; Type[BaseTool]:\n    \"\"\"\n    Converts an OpenAI schema into a BaseTool.\n\n    Parameters:\n        schema: The OpenAI schema to convert.\n        callback: The function to run when the tool is called.\n\n    Returns:\n        A BaseTool.\n    \"\"\"\n    data_model_types = get_data_model_types(\n        DataModelType.PydanticV2BaseModel, target_python_version=PythonVersion.PY_37\n    )\n\n    parser = JsonSchemaParser(\n        json.dumps(schema[\"parameters\"]),\n        data_model_type=data_model_types.data_model,\n        data_model_root_type=data_model_types.root_model,\n        data_model_field_type=data_model_types.field_model,\n        data_type_manager_type=data_model_types.data_type_manager,\n        dump_resolve_reference_action=data_model_types.dump_resolve_reference_action,\n        use_schema_description=True,\n        validation=False,\n        class_name=\"Model\",\n        # custom_template_dir=Path('/Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/tools/data_schema_templates')\n    )\n\n    result = parser.parse()\n\n    # # Execute the result to extract the model\n    exec_globals = {}\n    exec(result, exec_globals)\n    model = exec_globals.get(\"Model\")\n\n    if not model:\n        raise ValueError(f\"Could not extract model from schema {schema['name']}\")\n\n    class ToolConfig:\n        strict: bool = schema.get(\"strict\", False)\n\n    tool = type(\n        schema[\"name\"],\n        (BaseTool, model),\n        {\n            \"__doc__\": schema.get(\"description\", \"\"),\n            \"run\": callback,\n        },\n    )\n\n    tool.ToolConfig = ToolConfig\n\n    return tool\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.from_openapi_schema","title":"<code>from_openapi_schema(schema, headers=None, params=None, strict=False)</code>  <code>staticmethod</code>","text":"<p>Converts an OpenAPI schema into a list of BaseTools.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Union[str, dict]</code> <p>The OpenAPI schema to convert.</p> required <code>headers</code> <code>Dict[str, str]</code> <p>The headers to use for requests.</p> <code>None</code> <code>params</code> <code>Dict[str, Any]</code> <p>The parameters to use for requests.</p> <code>None</code> <code>strict</code> <code>bool</code> <p>Whether to use strict OpenAI mode.</p> <code>False</code> <p>Returns:     A list of BaseTools.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef from_openapi_schema(\n    schema: Union[str, dict],\n    headers: Dict[str, str] = None,\n    params: Dict[str, Any] = None,\n    strict: bool = False,\n) -&gt; List[Type[BaseTool]]:\n    \"\"\"\n    Converts an OpenAPI schema into a list of BaseTools.\n\n    Parameters:\n        schema: The OpenAPI schema to convert.\n        headers: The headers to use for requests.\n        params: The parameters to use for requests.\n        strict: Whether to use strict OpenAI mode.\n    Returns:\n        A list of BaseTools.\n    \"\"\"\n    if isinstance(schema, dict):\n        openapi_spec = schema\n        openapi_spec = jsonref.JsonRef.replace_refs(openapi_spec)\n    else:\n        openapi_spec = jsonref.loads(schema)\n    tools = []\n    headers = headers or {}\n    headers = {k: v for k, v in headers.items() if v is not None}\n    for path, methods in openapi_spec[\"paths\"].items():\n        for method, spec_with_ref in methods.items():\n\n            async def callback(self):\n                url = openapi_spec[\"servers\"][0][\"url\"] + path\n                parameters = self.model_dump().get(\"parameters\", {})\n                # replace all parameters in url\n                for param, value in parameters.items():\n                    if \"{\" + str(param) + \"}\" in url:\n                        url = url.replace(f\"{{{param}}}\", str(value))\n                        parameters[param] = None\n                url = url.rstrip(\"/\")\n                parameters = {k: v for k, v in parameters.items() if v is not None}\n                parameters = {**parameters, **params} if params else parameters\n                async with httpx.AsyncClient(\n                    timeout=90\n                ) as client:  # Set custom read timeout to 10 seconds\n                    if method == \"get\":\n                        response = await client.get(\n                            url, params=parameters, headers=headers\n                        )\n                    elif method == \"post\":\n                        response = await client.post(\n                            url,\n                            params=parameters,\n                            json=self.model_dump().get(\"requestBody\", None),\n                            headers=headers,\n                        )\n                    elif method == \"put\":\n                        response = await client.put(\n                            url,\n                            params=parameters,\n                            json=self.model_dump().get(\"requestBody\", None),\n                            headers=headers,\n                        )\n                    elif method == \"delete\":\n                        response = await client.delete(\n                            url,\n                            params=parameters,\n                            json=self.model_dump().get(\"requestBody\", None),\n                            headers=headers,\n                        )\n                    return response.json()\n\n            # 1. Resolve JSON references.\n            spec = jsonref.replace_refs(spec_with_ref)\n\n            # 2. Extract a name for the functions.\n            function_name = spec.get(\"operationId\")\n\n            # 3. Extract a description and parameters.\n            desc = spec.get(\"description\") or spec.get(\"summary\", \"\")\n\n            schema = {\"type\": \"object\", \"properties\": {}}\n\n            req_body = (\n                spec.get(\"requestBody\", {})\n                .get(\"content\", {})\n                .get(\"application/json\", {})\n                .get(\"schema\")\n            )\n            if req_body:\n                schema[\"properties\"][\"requestBody\"] = req_body\n\n            spec_params = spec.get(\"parameters\", [])\n            if spec_params:\n                param_properties = {}\n                required_params = []\n                for param in spec_params:\n                    if \"schema\" not in param and \"type\" in param:\n                        param[\"schema\"] = {\"type\": param[\"type\"]}\n                    param_properties[param[\"name\"]] = param[\"schema\"]\n                    if \"description\" in param:\n                        param_properties[param[\"name\"]][\"description\"] = param[\n                            \"description\"\n                        ]\n                    if \"required\" in param and param[\"required\"]:\n                        required_params.append(param[\"name\"])\n                    if \"example\" in param:\n                        param_properties[param[\"name\"]][\"example\"] = param[\n                            \"example\"\n                        ]\n                    if \"examples\" in param:\n                        param_properties[param[\"name\"]][\"examples\"] = param[\n                            \"examples\"\n                        ]\n\n                schema[\"properties\"][\"parameters\"] = {\n                    \"type\": \"object\",\n                    \"properties\": param_properties,\n                    \"required\": required_params,\n                }\n\n            function = {\n                \"name\": function_name,\n                \"description\": desc,\n                \"parameters\": schema,\n                \"strict\": strict,\n            }\n\n            tools.append(ToolFactory.from_openai_schema(function, callback))\n\n    return tools\n</code></pre>"},{"location":"api/#agency_swarm.tools.ToolFactory.ToolFactory.get_openapi_schema","title":"<code>get_openapi_schema(tools, url, title='Agent Tools', description='A collection of tools.')</code>  <code>staticmethod</code>","text":"<p>Generates an OpenAPI schema from a list of BaseTools.</p> <p>Parameters:</p> Name Type Description Default <code>tools</code> <code>List[Type[BaseTool]]</code> <p>BaseTools to generate the schema from.</p> required <code>url</code> <code>str</code> <p>The base URL for the schema.</p> required <code>title</code> <p>The title of the schema.</p> <code>'Agent Tools'</code> <code>description</code> <p>The description of the schema.</p> <code>'A collection of tools.'</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.</p> Source code in <code>agency_swarm/tools/ToolFactory.py</code> <pre><code>@staticmethod\ndef get_openapi_schema(\n    tools: List[Type[BaseTool]],\n    url: str,\n    title=\"Agent Tools\",\n    description=\"A collection of tools.\",\n) -&gt; str:\n    \"\"\"\n    Generates an OpenAPI schema from a list of BaseTools.\n\n    Parameters:\n        tools: BaseTools to generate the schema from.\n        url: The base URL for the schema.\n        title: The title of the schema.\n        description: The description of the schema.\n\n    Returns:\n        A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.\n    \"\"\"\n    schema = {\n        \"openapi\": \"3.1.0\",\n        \"info\": {\"title\": title, \"description\": description, \"version\": \"v1.0.0\"},\n        \"servers\": [\n            {\n                \"url\": url,\n            }\n        ],\n        \"paths\": {},\n        \"components\": {\n            \"schemas\": {},\n            \"securitySchemes\": {\"apiKey\": {\"type\": \"apiKey\"}},\n        },\n    }\n\n    for tool in tools:\n        if not issubclass(tool, BaseTool):\n            continue\n\n        openai_schema = tool.openai_schema\n        defs = {}\n        if \"$defs\" in openai_schema[\"parameters\"]:\n            defs = openai_schema[\"parameters\"][\"$defs\"]\n            del openai_schema[\"parameters\"][\"$defs\"]\n\n        schema[\"paths\"][\"/\" + openai_schema[\"name\"]] = {\n            \"post\": {\n                \"description\": openai_schema[\"description\"],\n                \"operationId\": openai_schema[\"name\"],\n                \"x-openai-isConsequential\": False,\n                \"parameters\": [],\n                \"requestBody\": {\n                    \"content\": {\n                        \"application/json\": {\"schema\": openai_schema[\"parameters\"]}\n                    }\n                },\n            }\n        }\n\n        schema[\"components\"][\"schemas\"].update(defs)\n\n    schema = json.dumps(schema, indent=2).replace(\n        \"#/$defs/\", \"#/components/schemas/\"\n    )\n\n    return schema\n</code></pre>"},{"location":"contributing/","title":"Contributing to Agency Swarm","text":"<p>Each agent or tool you add to Agency Swarm will automatically be available for import by the Genesis Swarm, which will help us create an exponentially larger and smarter system.</p> <p>This document provides guidelines for contributing new agents and tools to the framework.</p> <p>Will be updated soon</p> <p>The way we contribute agents and tools will be updated soon to load source files directly from the repository, rather than import them into the framework. This will allow you to have full control over all your agents and tools.</p>"},{"location":"contributing/#folder-structure-for-tools","title":"Folder Structure for Tools","text":"<p>Tools should be added in the agency_swarm/tools/{category}/ directory like below. Each tool should be in its specific category folder like coding, browsing, investing etc.</p> <p>Your tool file should be named YourNewTool.py. Tests should be added in agency_swarm/tests/test_tools.py. Directory structure for a new tool:</p> <pre><code>agency_swarm/tools/your-tool-category/\n\u2502\n\u251c\u2500\u2500 YourNewTool.py          # The main agent class file\n\u2514\u2500\u2500 __init__.py             # Make sure to import your tool here\n</code></pre>"},{"location":"contributing/#adding-tests-for-your-tools","title":"Adding Tests For Your Tools","text":"<p>For each tool, please add the following test case in agency_swarm/tests/test_tools.py: <pre><code>    def test_my_tool_example(self):\n        output = MyCustomTool(query='John Doe').run()\n        self.assertFalse(\"error\" in output.lower())\n</code></pre></p>"},{"location":"contributing/#folder-structure-for-agents","title":"Folder Structure for Agents","text":"<p>Agents should be placed in agency_swarm/agents/{category}/ directory. Each agent should have its dedicated folder named AgentName like below. Make sure to use CamelCase for the agent name and the folder. <pre><code>agency_swarm/agents/your-agent-category/AgentName/\n\u2502\n\u251c\u2500\u2500 agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)\n\u2514\u2500\u2500 AgentName/                  # Directory for the specific agent\n    \u251c\u2500\u2500 files/                  # Directory for files that will be uploaded to openai (if any)\n    \u251c\u2500\u2500 schemas/                # Directory for OpenAPI schemas to be converted into tools (if any)\n    \u251c\u2500\u2500 AgentName.py            # The main agent class file\n    \u251c\u2500\u2500 __init__.py             # Initializes the agent folder as a Python package\n    \u2514\u2500\u2500 instructions.md         # Instruction document for the agent\n</code></pre></p>"},{"location":"contributing/#creating-an-agent","title":"Creating an Agent","text":"<p>Follow the structure below in your AgentName.py as a guideline. All tools (except schemas) should be imported in AgentName.py from the agency_swarm/tools/... folder. <pre><code>from agency_swarm import Agent\nfrom agency_swarm.tools.example import ExampleTool\n\nclass AgentName(Agent):\n    def __init__(self, **kwargs):\n        # Initialize tools in kwargs if not present\n        if 'tools' not in kwargs:\n            kwargs['tools'] = []\n        # Add required tools\n        kwargs['tools'].extend([ExampleTool])\n\n        # Set instructions\n        kwargs['instructions'] = \"./instructions.md\"\n\n        # Add more kwargs as needed\n\n        # Initialize the parent class\n        super().__init__(**kwargs)\n</code></pre></p> <p>Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.</p>"},{"location":"deployment/","title":"Deployment to Production","text":"<p>To deploy your Agency on a production server, typically, you need to do the following:</p> <ol> <li>Load Agents and Threads dynamically: Depending on your use case, you may want to load different agents and threads, based on current user/chat/session.</li> <li>Deploy each agent as a separate microservice (optional): This is useful when you want to scale each agent independently.</li> </ol>"},{"location":"deployment/#loading-agents-and-threads-dynamically","title":"Loading Agents and Threads dynamically","text":"<p>To load agents and threads dynamically, based on specific conditions, you will need to implement <code>threads_callbacks</code> and <code>settings_callbacks</code> in your agency.</p>"},{"location":"deployment/#settings-callbacks","title":"Settings Callbacks","text":"<p>Settings is a list of dictionaries that contains states of all the agents within your agency. If any change is detected after you initialize it, settings will be updated, and new settings will be saved to a file specified by <code>settings_path</code>. <code>settings_callbacks</code> will be executed every time these settings are loaded or saved.</p> <p>Here is an example of how you can use them:</p> <pre><code>def load_settings(user_id):\n    # your code to load settings from DB here\n    settings = load_settings_from_db(user_id)\n    return settings\n\ndef save_settings(new_settings: List[Dict]):\n    # your code to save new_settings to DB here\n    save_settings_to_db(new_settings)\n</code></pre>"},{"location":"deployment/#threads-callbacks","title":"Threads Callbacks","text":"<p>Threads is a dictionary that contains all threads between your agents. Loading them from the database, allows your agents to continue their conversations where they left off, even if you are using stateless backend. <code>threads_callbacks</code> callbacks work in a same way as <code>settings_callbacks</code>, except they are kept in memory, instead of being saved to a file:</p> <pre><code>def load_threads(chat_id):\n    # your code to load threads from DB here\n    threads = load_threads_from_db(chat_id)\n    return threads\n\ndef save_threads(new_threads: Dict):\n    # your code to save new_threads to DB here\n    save_threads_to_db(new_threads)\n</code></pre> <p>Note</p> <p>Make sure you load and return settings and threads in the exact same format as they are saved.</p>"},{"location":"deployment/#example","title":"Example","text":"<p>Below is an example of how you initialize an agency with these callbacks. You will typically need to get some info like <code>user_id</code> or <code>chat_id</code> beforehand, and pass them into these callbacks, depending on your use case or business logic:</p> <pre><code>agency = Agency([ceo],\n                threads_callbacks={\n                    'load': lambda: load_threads(chat_id),\n                    'save': lambda new_threads: save_threads(new_threads)\n                },\n                settings_callbacks={\n                    'load': lambda: load_settings(user_id),\n                    'save': lambda new_settings: save_settings(new_settings)\n                },\n                settings_path='my_settings.json'\n)\n</code></pre>"},{"location":"deployment/#deploy-each-agent-as-a-separate-microservice","title":"Deploy each agent as a separate microservice","text":"<p>... coming soon ...</p>"},{"location":"examples/","title":"Examples","text":"<p>The best new examples and tutorials will be posted on my YouTube Channel.</p>"},{"location":"examples/#agency-examples","title":"Agency Examples","text":"<p>Examples of Agencies can be found in the agency-swarm-lab repository:</p> <ul> <li>WebDevCrafters - Web Development Agency that builds responsive web applications using Next.js, React, and MUI.</li> <li>CodeGuardiansAgency - Agency that runs only on the backend using github actions and submits code reviews on pull requests, according to your SOPs.</li> </ul>"},{"location":"examples/#videos-with-notebooks","title":"Videos with Notebooks","text":"<ul> <li>Browsing Agent for QA Testing Agency - This video shows how to use BrowsingAgent with GPT-4 vision inside a QA testing agency. It can also break captcha, as shown in this video. The notebook is available here.</li> <li>Genesis Agency - This agency creates your agents for you. The notebook is available here.</li> </ul>"},{"location":"examples/#more-coming-soon","title":"... more coming soon","text":""},{"location":"quick_start/","title":"Quick Start","text":"<p>When it comes to getting started with Agency Swarm, you have two options:</p> <ol> <li>Start from Scratch: This is the best option if you want to get a feel for the framework and understand how it works. You can start by creating your own agents and tools, and then use them to create your own agencies.</li> <li>Use Genesis Swarm: This is the best option if you want to get started quickly and don't want to spend time creating your own agents and tools. You can use the Genesis Agency to create your agent templates and tools, and then fine-tune them to your needs.</li> <li>Create agent templates with CLI: This is the best option if you want to create a structured environment for each agent and tool. See Advanced Agents for more information.</li> </ol>"},{"location":"quick_start/#installation","title":"Installation","text":"<pre><code>pip install agency-swarm\n</code></pre>"},{"location":"quick_start/#start-from-scratch","title":"Start from Scratch","text":"<ol> <li> <p>Set Your OpenAI Key:</p> <pre><code>from agency_swarm import set_openai_key\nset_openai_key(\"YOUR_API_KEY\")\n</code></pre> </li> <li> <p>Create Tools: Define your custom tools with Instructor. All tools must extend the <code>BaseTool</code> class and implement the <code>run</code> method.     <pre><code>from agency_swarm.tools import BaseTool\nfrom pydantic import Field\n\nclass MyCustomTool(BaseTool):\n    \"\"\"\n    A brief description of what the custom tool does.\n    The docstring should clearly explain the tool's purpose and functionality.\n    It will be used by the agent to determine when to use this tool.\n    \"\"\"\n\n    # Define the fields with descriptions using Pydantic Field\n    example_field: str = Field(\n        ..., description=\"Description of the example field, explaining its purpose and usage for the Agent.\"\n    )\n\n    # Additional Pydantic fields as required\n    # ...\n\n    def run(self):\n        \"\"\"\n        The implementation of the run method, where the tool's main functionality is executed.\n        This method should utilize the fields defined above to perform the task.\n        Doc string is not required for this method and will not be used by your agent.\n        \"\"\"\n\n        # Your custom tool logic goes here\n        do_something(self.example_field)\n\n        # Return the result of the tool's operation as a string\n        return \"Result of MyCustomTool operation\"\n</code></pre></p> </li> <li> <p>Define Agent Roles: Define your agent roles. For example, a CEO agent for managing tasks and a developer agent for executing tasks.</p> <pre><code>from agency_swarm import Agent\n\nceo = Agent(name=\"CEO\",\n            description=\"Responsible for client communication, task planning and management.\",\n            instructions=\"You must converse with other agents to ensure complete task execution.\", # can be a file like ./instructions.md\n            tools=[])\n\ndeveloper = Agent(name=\"Developer\",\n                  description=\"Responsible for executing tasks and providing feedback.\",\n                  instructions=\"You must execute the tasks provided by the CEO and provide feedback.\", # can be a file like ./instructions.md\n                  tools=[MyCustomTool])\n</code></pre> </li> <li> <p>Create Agency: Define your agency chart.</p> <p>Any agents that are listed in the same list (eg. <code>[[ceo, dev]]</code>) can communicate with each other. The top-level list (<code>[ceo]</code>) defines agents that can communicate with the user.</p> <pre><code>from agency_swarm import Agency\n\nagency = Agency([\n    ceo,  # CEO will be the entry point for communication with the user\n    [ceo, dev],  # CEO can initiate communication with Developer\n], shared_instructions='You are a part of an ai development agency.\\n\\n') # shared instructions for all agents\n</code></pre> <p>Note on Communication Flows</p> <p>In Agency Swarm, communication flows are directional, meaning they are established from left to right in the agency_chart definition. For instance, in the example above, the CEO can initiate a chat with the developer (dev), and the developer can respond in this chat. However, the developer cannot initiate a chat with the CEO.</p> </li> <li> <p>Run Demo:    Run the demo to see your agents in action!</p> <p>Web interface:</p> <pre><code>agency.demo_gradio(height=900)\n</code></pre> <p>Terminal version:</p> <pre><code>agency.run_demo()\n</code></pre> <p>Backend version:</p> <pre><code>completion_output = agency.get_completion(\"Please create a new website for our client.\", yield_messages=False)\n</code></pre> </li> </ol>"},{"location":"quick_start/#use-genesis-agency","title":"Use Genesis Agency","text":"<ol> <li> <p>Run the <code>genesis</code> command: This will start the Genesis Agency in your terminal, that will create your agent templates for you.</p> </li> <li> <p>Chat with Genesis CEO: Provide as much context as possible to Genesis Agency. Make sure to include:</p> <ul> <li>Your mission and goals.</li> <li>The agents you want to involve and their communication flows.</li> <li>Which tools or APIs each agent should have access to, if any.</li> </ul> </li> <li> <p>Fine Tune: After Genesis has created your agents for you, you will see all the agent folders in the same directory where you ran the <code>genesis</code> command. You can then fine-tune the agents and tools as per your requirements. To do so, follow these steps:</p> <ol> <li>Adjust Tools: Modify the tools in the <code>tools</code> directories of each agent as per your requirements.</li> <li>Adjust Instructions: Modify the agents in the <code>agents</code> directories as per your requirements.</li> <li>Run Agency: Run the <code>agency.py</code> file, send your tasks and see how they perform.</li> <li>Repeat: Repeat the process until your agents are performing as expected.</li> </ol> <p>Agent Development is an Iterative Process</p> <p>Right now, all agent development is iterative. You will need to constantly monitor and adjust your system until it works as expected. In the future, this will become less of a problem, as larger and smarter models are released.</p> </li> </ol>"},{"location":"quick_start/#command-syntax","title":"Command Syntax:","text":"<pre><code>agency-swarm genesis [--openai_key \"YOUR_API_KEY\"]\n</code></pre>"},{"location":"quick_start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn how to create more Tools, Agents and Agencies</li> <li>Deploy in Production</li> </ul>"},{"location":"advanced-usage/agencies/","title":"Agencies","text":"<p>An <code>Agency</code> is a collection of Agents that can communicate with one another.</p>"},{"location":"advanced-usage/agencies/#benefits-of-using-an-agency","title":"Benefits of using an Agency","text":"<p>Here are the primary benefits of using an Agency, instead of an individual agent:</p> <ol> <li>Fewer hallucinations: When agents are part of an agency, they can supervise one another and recover from mistakes or unexpected circumstances.</li> <li>More complex tasks: The more agents you add, the longer the sequence of actions they can perform before returning the result back to the user.</li> <li> <p>Scalability: As the complexity of your integration increases, you can keep adding more and more agents.</p> <p>Tip</p> <p>It is recommended to start with as few agents as possible, fine-tune them until they are working as expected, and only then add new agents to the agency. If you add too many agents at first, it will be difficult to debug and understand what is going on.</p> </li> </ol>"},{"location":"advanced-usage/agencies/#communication-flows","title":"Communication Flows","text":"<p>Unlike all other frameworks, communication flows in Agency Swarm are not hierarchical or sequential. Instead, they are uniform. You can define them however you want. But keep in mind that they are established from left to right inside the <code>agency_chart</code>. So, in the example below, the CEO can initiate communication and send tasks to the Developer and the Virtual Assistant, and they can respond back to him in the same thread, but the Developer or the VA cannot initiate a conversation and assign tasks to the CEO. You can add as many levels of communication as you want.</p> <pre><code>from agency_swarm import Agency\n\nagency = Agency([\n    ceo, dev  # CEO and Developer will be the entry point for communication with the user\n    [ceo, dev],  # CEO can initiate communication with Developer\n    [ceo, va],   # CEO can initiate communication with Virtual Assistant\n    [dev, va]    # Developer can initiate communication with Virtual Assistant\n])\n</code></pre> <p>All agents added inside the top-level list of <code>agency_chart</code> without being part of a second list, can talk to the user.</p>"},{"location":"advanced-usage/agencies/#streaming-responses","title":"Streaming Responses","text":"<p>To stream the conversation between agents, you can use the <code>get_completion_stream</code> method with your event handler like below. The process is extremely similar to the one in the official documentation.</p> <p>The only difference is that you must extend the <code>AgencyEventHandler</code> class, which has 2 additional properties: <code>agent_name</code> and <code>recipient_agent_name</code>, to get the names of the agents communicating with each other. (See the <code>on_text_created</code> below.)</p> <pre><code>from typing_extensions import override\nfrom agency_swarm import AgencyEventHandler\n\nclass EventHandler(AgencyEventHandler):\n    @override\n    def on_text_created(self, text) -&gt; None:\n        # get the name of the agent that is sending the message\n        print(f\"\\n{self.recipient_agent_name} @ {self.agent_name}  &gt; \", end=\"\", flush=True)\n\n    @override\n    def on_text_delta(self, delta, snapshot):\n        print(delta.value, end=\"\", flush=True)\n\n    def on_tool_call_created(self, tool_call):\n        print(f\"\\n{self.recipient_agent_name} &gt; {tool_call.type}\\n\", flush=True)\n\n    def on_tool_call_delta(self, delta, snapshot):\n        if delta.type == 'code_interpreter':\n            if delta.code_interpreter.input:\n                print(delta.code_interpreter.input, end=\"\", flush=True)\n            if delta.code_interpreter.outputs:\n                print(f\"\\n\\noutput &gt;\", flush=True)\n                for output in delta.code_interpreter.outputs:\n                    if output.type == \"logs\":\n                        print(f\"\\n{output.logs}\", flush=True)\n\n    @classmethod\n    def on_all_streams_end(cls):\n        print(\"\\n\\nAll streams have ended.\") # Conversation is over and message is returned to the user.\n\nresponse = agency.get_completion_stream(\"I want you to build me a website\", event_handler=EventHandler)\n</code></pre> <p>Also, there is an additional class method <code>on_all_streams_end</code> which is called when all streams have ended. This method is needed because, unlike in the official documentation, your event handler will be called multiple times and probably by even multiple agents.</p>"},{"location":"advanced-usage/agencies/#async-mode","title":"Async Mode","text":"<p>When it comes to asynchronous execution, there are 2 modes you can use at the moment: <code>threading</code>, <code>tools_threading</code>.</p>"},{"location":"advanced-usage/agencies/#agents-threading","title":"Agents - Threading","text":"<p>If you would like to use asynchronous communication between agents, you can specify a <code>async_mode</code> parameter to <code>threading</code>. This is useful when you don't want to wait for a response from an agent. For example, if it takes it long to write it.</p> <pre><code>agency = Agency([ceo], async_mode='threading')\n</code></pre> <p>With this mode, the response from the <code>SendMessage</code> tool will be returned instantly as a system notification with a status update. The recipient agent will then continue to execute the task in the background. The caller agent can check the status (if task is in progress) or the response (if the task is completed) with the <code>GetResponse</code> tool.</p>"},{"location":"advanced-usage/agencies/#tools-threading","title":"Tools - Threading","text":"<p>If you would like to use asynchronous execution for tools, you can specify a <code>async_mode</code> parameter to <code>tools_threading</code>. With this mode on, all tools will be executed concurrently in separate threads, which can significantly speed up the work flow of I/O bound tasks.</p> <pre><code>agency = Agency([ceo], async_mode='tools_threading')\n</code></pre>"},{"location":"advanced-usage/agencies/#shared-files","title":"Shared Files","text":"<p>You can add shared files for all agents in the agency by specifying a folder path in a <code>shared_files</code> parameter. This is useful for sharing common resources that all agents need to access.</p> <pre><code>agency = Agency([ceo], shared_files='shared_files')\n</code></pre>"},{"location":"advanced-usage/agencies/#settings-path","title":"Settings Path","text":"<p>If you would like to use a different file path for the settings, other than default <code>settings.json</code>, you can specify a <code>settings_path</code> parameter. All your agent states will then be saved and loaded from this file. If this file does not exist, it will be created, along with new Assistants on your OpenAI account.</p> <pre><code>agency = Agency([ceo], settings_path='my_settings.json')\n</code></pre>"},{"location":"advanced-usage/agencies/#temperature-and-max-token-controls","title":"Temperature and Max Token Controls","text":"<p>You can also specify parameters like <code>temperature</code>, <code>top_p</code>, <code>max_completion_tokens</code>,  <code>max_prompt_tokens</code> and <code>truncation_strategy</code>, parameters for the entire agency. These parameters will be used as default values for all agents in the agency, however, you can still override them for individual agents by specifying them in the agent's constructor.</p> <pre><code>agency = Agency([ceo], temperature=0.3, max_prompt_tokens=25000)\n</code></pre>"},{"location":"advanced-usage/agencies/#running-the-agency","title":"Running the Agency","text":"<p>When it comes to running the agency, you have 3 options:</p> <ol> <li>Run it inside a Gradio interface: The most convenient way to get started.</li> <li>Get completion from the agency: For backend or custom integrations.</li> <li>Run it from your terminal: Best for quick debugging and testing.</li> </ol>"},{"location":"advanced-usage/agencies/#running-the-agency-inside-a-gradio-interface","title":"Running the Agency inside a Gradio Interface","text":"<pre><code>agency.demo_gradio(height=700)\n</code></pre>"},{"location":"advanced-usage/agencies/#get-completion-from-the-agency","title":"Get completion from the agency","text":"<pre><code>response = agency.get_completion(\"I want you to build me a website\",\n                                 additional_instructions=\"This is an additional instruction for the task.\",\n                                 tool_choice={\"type\": \"function\", \"function\": {\"name\": \"SendMessage\"}},\n                                 attachments=[],\n                                 recipient_agent=dev,\n                                 )\nprint(response)\n</code></pre> <p>Params like <code>additional_instructions</code>, <code>tool_choice</code>, and <code>attachments</code> are optional. You can also specify the <code>recipient_agent</code> parameter to send the message to a specific agent.</p>"},{"location":"advanced-usage/agencies/#running-the-agency-from-your-terminal","title":"Running the Agency from your terminal","text":"<pre><code>agency.run_demo()\n</code></pre> <p>To talk to one of the top-level agents when running the agency from your terminal, you can use mentions feature, similar to how you would use it inside ChatGPT. Simply mention the agent name in the message like <code>@Developer I want you to build me a website</code>. The message will then be sent to the Developer agent, instead of the CEO. You can also use tab to autocomplete the agent name after the <code>@</code> symbol.</p>"},{"location":"advanced-usage/agencies/#deleting-the-agency","title":"Deleting the Agency","text":"<p>If you would like to delete the agency and all its agents with all associated files and vector stores, you can use the <code>delete</code> method.</p> <pre><code>agency.delete()\n</code></pre>"},{"location":"advanced-usage/agents/","title":"Agents","text":"<p>Agents are essentially wrappers for Assistants in OpenAI Assistants API. The <code>Agent</code> class contains a lot of convenience methods to help you manage the state of your assistant, upload files, attach tools, and more.</p>"},{"location":"advanced-usage/agents/#advanced-parameters","title":"Advanced Parameters","text":"<p>All parameters inside the Agent class, primarily follow the same structure as OpenAI's Assistants API. However, there are a few additional parameters that you can use to customize your agent.</p>"},{"location":"advanced-usage/agents/#parallel-tool-calls","title":"Parallel Tool Calls","text":"<p>You can specify weather to run tools in parallel or sequentially by setting the <code>parallel_tool_calls</code> parameter. By default, this parameter is set to <code>True</code>.</p> <pre><code>from agency_swarm import Agent\n\nagent = Agent(name='MyAgent', parallel_tool_calls=False)\n</code></pre> <p>Now, the agent will run all tools sequentially.</p>"},{"location":"advanced-usage/agents/#file-search-configuration","title":"File Search Configuration","text":"<p>You can also specify the file search configuration for the agent, as described in the OpenAI documentation. Right now, only <code>max_num_results</code> is supported.</p> <pre><code>from agency_swarm import Agent\n\nagent = Agent(name='MyAgent', file_search={'max_num_results': 25}) # must be between 1 and 50\n</code></pre>"},{"location":"advanced-usage/agents/#schemas-folder","title":"Schemas Folder","text":"<p>You can specify the folder where the agent will look for OpenAPI schemas to convert into tools. Additionally, you can add <code>api_params</code> and <code>api_headers</code> to the schema to pass additional parameters and headers to the API call.</p> <pre><code>from agency_swarm import Agent\n\nagent = Agent(name='MyAgent',\n              schemas_folder='schemas',\n              api_params={'my_schema.json': {'param1': 'value1'}},\n              api_headers={'my_schema.json': {'Authorization': 'Bearer token'}}\n            )\n</code></pre> <p>Note</p> <p>Schemas folder automatically converts any OpenAPI schemas into BaseTools. This means that your agents will type check all the API parameters before calling the API, which significantly reduces any chances of errors.</p>"},{"location":"advanced-usage/agents/#fine-tuned-models","title":"Fine Tuned models","text":"<p>You can use any previously fine-tuned model by specifying the <code>model</code> parameter in the agent.</p> <pre><code>from agency_swarm import Agent\n\nagent = Agent(name='MyAgent', model='gpt-3.5-turbo-model-name')\n</code></pre>"},{"location":"advanced-usage/agents/#response-validator","title":"Response Validator","text":"<p>You can also provide a response validator function to validate the response before sending it to the user or another agent. This function should raise an error if the response is invalid.</p> <pre><code>from agency_swarm import Agent\n\nclass MyAgent(Agent):\n    def response_validator(self, message: str) -&gt; str:\n        \"\"\"This function is used to validate the response before sending it to the user or another agent.\"\"\"\n        if \"bad word\" in message:\n            raise ValueError(\"Please don't use bad words.\")\n\n        return message\n</code></pre>"},{"location":"advanced-usage/agents/#few-shot-examples","title":"Few-Shot Examples","text":"<p>You can now also provide few-shot examples for each agent. These examples help the agent to understand how to respond. The format for examples follows message object format on OpenAI:</p> <pre><code>examples=[\n    {\n        \"role\": \"user\",\n        \"content\": \"Hi!\",\n        \"attachments\": [],\n        \"metadata\": {},\n    },\n    {\n        \"role\": \"assistant\",\n        \"content\": \"Hi! I am the CEO. I am here to help you with your tasks. Please tell me what you need help with.\",\n        \"attachments\": [],\n        \"metadata\": {},\n    }\n]\n\nagent.examples = examples\n</code></pre> <p>or you can also provide them when initializing the agent in init method:</p> <pre><code>agent = Agent(examples=examples)\n</code></pre>"},{"location":"advanced-usage/agents/#creating-agents","title":"Creating Agents","text":"<p>When it comes to creating your agent, you have 3 options:</p> <ol> <li>Define the agent directly in the code.</li> <li>Create agent template locally using CLI.</li> <li>Import from existing agents.</li> </ol>"},{"location":"advanced-usage/agents/#defining-the-agent-directly-in-the-code","title":"Defining the agent directly in the code","text":"<p>To define your agent in the code, you can simply instantiate the <code>Agent</code> class and pass the required parameters.</p> <pre><code>from agency_swarm import Agent\n\nagent = Agent(name=\"My Agent\",\n              description=\"This is a description of my agent.\",\n              instructions=\"These are the instructions for my agent.\",\n              tools=[ToolClass1, ToolClass2],\n              temperature=0.3,\n              max_prompt_tokens=25000\n            )\n</code></pre>"},{"location":"advanced-usage/agents/#create-agent-template-locally-using-cli","title":"Create agent template locally using CLI","text":"<p>This CLI command simplifies the process of creating a structured environment for each agent.</p>"},{"location":"advanced-usage/agents/#command-syntax","title":"Command Syntax:","text":"<pre><code>agency-swarm create-agent-template --name \"AgentName\" --description \"Agent Description\" [--path \"/path/to/directory\"] [--use_txt]\n</code></pre>"},{"location":"advanced-usage/agents/#folder-structure","title":"Folder Structure","text":"<p>When you run the <code>create-agent-template</code> command, it creates the following folder structure for your agent:</p> <pre><code>/your-specified-path/\n\u2502\n\u251c\u2500\u2500 agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)\n\u2514\u2500\u2500 AgentName/                  # Directory for the specific agent\n    \u251c\u2500\u2500 files/                  # Directory for files that will be uploaded to openai\n    \u251c\u2500\u2500 schemas/                # Directory for OpenAPI schemas to be converted into tools\n    \u251c\u2500\u2500 tools/                  # Directory for tools to be imported by default.\n    \u251c\u2500\u2500 AgentName.py            # The main agent class file\n    \u251c\u2500\u2500 __init__.py             # Initializes the agent folder as a Python package\n    \u2514\u2500\u2500 instructions.md or .txt # Instruction document for the agent\n</code></pre> <ul> <li><code>files</code>: This folder is used to store files that will be uploaded to OpenAI. You can use any of the acceptable file formats. After file is uploaded, an id will be attached to the file name to avoid re-uploading the same file twice.</li> <li><code>schemas</code>: This folder is used to store OpenAPI schemas that will be converted into tools automatically. All you have to do is put the schema in this folder, and specify it when initializing your agent.</li> <li><code>tools</code>: This folder is used to store tools in the form of Python files. Each file must have the same name as the tool class for it to be imported by default. For example, <code>ExampleTool.py</code> must contain a class called <code>ExampleTool</code>.</li> </ul>"},{"location":"advanced-usage/agents/#agent-template","title":"Agent Template","text":"<p>The <code>AgentName.py</code> file will contain the following code:</p> <pre><code>from agency_swarm.agents import Agent\n\nclass AgentName(Agent):\n    def __init__(self):\n        super().__init__(\n            name=\"agent_name\",\n            description=\"agent_description\",\n            instructions=\"./instructions.md\",\n            files_folder=\"./files\",\n            schemas_folder=\"./schemas\",\n            tools_folder=\"./tools\",\n            temperature=0.3,\n            max_prompt_tokens=25000,\n            examples=[]\n        )\n\n    def response_validator(self, message: str) -&gt; str:\n        \"\"\"This function is used to validate the response before sending it to the user or another agent.\"\"\"\n        if \"bad word\" in message:\n            raise ValueError(\"Please don't use bad words.\")\n\n        return message\n</code></pre> <p>To initialize the agent, you can simply import the agent and instantiate it:</p> <pre><code>from AgentName import AgentName\n\nagent = AgentName()\n</code></pre>"},{"location":"advanced-usage/agents/#importing-existing-agents","title":"Importing existing agents","text":"<p>For the most complex and requested use cases, we will be creating premade agents that you can import and reuse in your own projects. To import an existing agent, you can run the following CLI command:</p> <pre><code>agency-swarm import-agent --name \"AgentName\" --destination \"/path/to/directory\"\n</code></pre> <p>This will copy all your agent source files locally. You can then import the agent as shown above. To check available agents, simply run this command without any arguments.</p>"},{"location":"advanced-usage/azure-openai/","title":"Azure OpenAI","text":"<p>Many organizations are concerned about data privacy and sharing their data with OpenAI. However, using Azure ensures that your data is processed in a secure environment, allowing you to utilize the OpenAI API without even sharing data with OpenAI itself.</p>"},{"location":"advanced-usage/azure-openai/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure that you have the following:</p> <ul> <li>An Azure account with an active subscription. Create an account here.</li> <li>Approved access to the OpenAI Service on Azure.</li> <li>An Azure OpenAI resource created in one of the available regions and a model deployed to it.</li> <li>Enpoint URL and API key for the OpenAI resource.</li> </ul>"},{"location":"advanced-usage/azure-openai/#using-azure-openai","title":"Using Azure OpenAI","text":"<p>To use Azure OpenAI, you need to change OpenAI client with AzureOpenAI client. Here is an example of how you can do it in agency swarm:</p> <pre><code>from openai import AzureOpenAI\nfrom agency_swarm import set_openai_client\n\nclient = AzureOpenAI(\n    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n    api_version=\"2024-02-15-preview\",\n    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n    timeout=5,\n    max_retries=5,\n)\n\nset_openai_client(client)\n</code></pre> <p>Then, you also have to replace <code>model</code> parameter inside each agent with your model deployment name from Azure. Here is an example of how you can do it:</p> <pre><code>ceo = Agent(name=\"ceo\", description=\"I am the CEO\", model='azure-model-deployment-name')\n</code></pre> <p>Then, you can run your agency as usual:</p> <pre><code>agency = Agency([ceo])\nagency.run_demo()\n</code></pre> <p>Retrieval is not supported yet</p> <p>Currently, Azure OpenAI does not support the <code>Retrieval</code> tool. You can only use <code>CodeInterpreter</code> or custom tools made with the <code>BaseTool</code> class.</p>"},{"location":"advanced-usage/azure-openai/#example-notebook","title":"Example Notebook","text":"<p>You can find an example notebook for using Azure OpenAI in the notebooks folder.</p>"},{"location":"advanced-usage/communication_flows/","title":"Advanced Communication Flows","text":"<p>Multi-agent communication is the core functionality of any Multi-Agent System. Unlike in all other frameworks, Agency Swarm not only allows you to define communication flows in any way you want (uniform communication flows), but to also configure the underlying logic for this feature. This means that you can create entirely new types of communication, or adjust it to your own needs. Below you will find a guide on how to do all this, along with some common examples.</p>"},{"location":"advanced-usage/communication_flows/#pre-made-sendmessage-classes","title":"Pre-Made SendMessage Classes","text":"<p>Agency Swarm contains multiple commonly requested classes for communication flows. Currently, the following classes are available:</p> Class Name Description When to Use Code Link <code>SendMessage</code> (default) This is the default class for sending messages to other agents. It uses synchronous communication with basic COT (Chain of Thought) prompting and allows agents to relay files and modify system instructions for each other. Suitable for most use cases. Balances speed and functionality. link <code>SendMessageQuick</code> A variant of the SendMessage class without Chain of Thought prompting, files, and additional instructions. It allows for faster communication without the overhead of COT. Use for simpler use cases or when you want to save tokens and increase speed. link <code>SendMessageAsyncThreading</code> Similar to <code>SendMessage</code> but with <code>async_mode='threading'</code>. Each agent will execute asynchronously in a separate thread. In the meantime, the caller agent can continue the conversation with the user and check the results later. Use for asynchronous applications or when sub-agents take singificant amounts of time to complete their tasks. link <code>SendMessageSwarm</code> Instead of sending a message to another agent, it replaces the caller agent with the recipient agent, similar to OpenAI's Swarm. The recipient agent will then have access to the entire conversation. When you need more granular control. It is not able to handle complex multi-step, multi-agent tasks. link <p>To use any of the pre-made <code>SendMessage</code> classes, simply put it in the <code>send_message_tool_class</code> parameter when initializing the <code>Agency</code> class:</p> <pre><code>from agency_swarm.tools.send_message import SendMessageQuick\n\nagency = Agency(\n    ...\n    send_message_tool_class=SendMessageQuick\n)\n</code></pre> <p>That's it! Now, your agents will use your own custom <code>SendMessageQuick</code> class for communication.</p>"},{"location":"advanced-usage/communication_flows/#creating-your-own-unique-communication-flows","title":"Creating Your Own Unique Communication Flows","text":"<p>To create you own communication flow, you will first need to extend the <code>SendMessageBase</code> class. This class extends the <code>BaseTool</code> class, like any other tools in Agency Swarm, and contains the most basic parameters required for communication, such as the <code>recipient_agent</code>.</p>"},{"location":"advanced-usage/communication_flows/#default-sendmessage-class","title":"Default <code>SendMessage</code> Class","text":"<p>By defualt, Agency Swarm uses the following tool for communication:</p> <pre><code>from typing import Optional, List\nfrom pydantic import Field, field_validator, model_validator\nfrom .SendMessageBase import SendMessageBase\n\nclass SendMessage(SendMessageBase):\n    \"\"\"Use this tool to facilitate direct, synchronous communication between specialized agents within your agency. When you send a message using this tool, you receive a response exclusively from the designated recipient agent. To continue the dialogue, invoke this tool again with the desired recipient agent and your follow-up message. Remember, communication here is synchronous; the recipient agent won't perform any tasks post-response. You are responsible for relaying the recipient agent's responses back to the user, as the user does not have direct access to these replies. Keep engaging with the tool for continuous interaction until the task is fully resolved. Do not send more than 1 message to the same recipient agent at the same time.\"\"\"\n    my_primary_instructions: str = Field(\n        ...,\n        description=(\n            \"Please repeat your primary instructions step-by-step, including both completed \"\n            \"and the following next steps that you need to perform. For multi-step, complex tasks, first break them down \"\n            \"into smaller steps yourself. Then, issue each step individually to the \"\n            \"recipient agent via the message parameter. Each identified step should be \"\n            \"sent in a separate message. Keep in mind that the recipient agent does not have access \"\n            \"to these instructions. You must include recipient agent-specific instructions \"\n            \"in the message or additional_instructions parameters.\"\n        )\n    )\n    message: str = Field(\n        ...,\n        description=\"Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information needed to complete the task.\"\n    )\n    message_files: Optional[List[str]] = Field(\n        default=None,\n        description=\"A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.\",\n        examples=[\"file-1234\", \"file-5678\"]\n    )\n    additional_instructions: Optional[str] = Field(\n        default=None,\n        description=\"Additional context or instructions from the conversation needed by the recipient agent to complete the task.\"\n    )\n\n    @model_validator(mode='after')\n    def validate_files(self):\n        # prevent hallucinations with agents sending file IDs into incorrect fields\n        if \"file-\" in self.message or (self.additional_instructions and \"file-\" in self.additional_instructions):\n            if not self.message_files:\n                raise ValueError(\"You must include file IDs in message_files parameter.\")\n        return self\n\n\n    def run(self):\n        return self._get_completion(message=self.message,\n                                    message_files=self.message_files,\n                                    additional_instructions=self.additional_instructions)\n</code></pre> <p>Let's break down the code.</p> <p>In general, all <code>SendMessage</code> tools have the following components:</p> <ol> <li>The Docstring: This is used to generate a description of the tool for the agent. This part should clearly describe how your multi-agent communication works, along with some additional guidelines on how to use it.</li> <li>Parameters: Parameters like <code>message</code>, <code>message_files</code>, <code>additional_instructions</code> are used to provide the recipient agent with the necessary information.</li> <li>The <code>run</code> method: This is where the communication logic is implemented. Most of the time, you just need to map your parameters to <code>self._get_completion()</code> the same way you would call it in the <code>agency.get_completion()</code> method.</li> </ol> <p>When creating your own <code>SendMessage</code> tools, you can use the above components as a template.</p>"},{"location":"advanced-usage/communication_flows/#common-use-cases","title":"Common Use Cases","text":"<p>In the following sections, we'll look at some common use cases for extending the <code>SendMessageBase</code> tool and how to implement them, so you can learn how to create your own SendMessage tools and use them in your own applications.</p>"},{"location":"advanced-usage/communication_flows/#1-adjusting-parameters-and-descriptions","title":"1. Adjusting parameters and descriptions","text":"<p>The most basic use case is if you want to use your own parameter descriptions, such as if you want to change the docstring or the description of the <code>message</code> parameter. This can help you better customize how the agents communicate with each other and what information they relay.</p> <p>Let's say that instead of sending messages, I want my agents to send tasks to each other. In this case, I can change the docstring and the <code>message</code> parameter to a <code>task</code> parameter to better fit the nature of my application.</p> <pre><code>from pydantic import Field\nfrom agency_swarm.tools.send_message import SendMessageBase\n\nclass SendMessageTask(SendMessageBase):\n    \"\"\"Use this tool to send tasks to other agents within your agency.\"\"\"\n    chain_of_thought: str = Field(\n        ...,\n        description=\"Please think step-by-step about how to solve your current task, provided by the user. Then, break down this task into smaller steps and issue each step individually to the recipient agent via the task parameter.\"\n    )\n    task: str = Field(\n        ...,\n        description=\"Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information needed to complete the task.\"\n    )\n\n    def run(self):\n        return self._get_completion(message=self.task)\n</code></pre> <p>To remove the chain of thought, you can simply remove the <code>chain_of_thought</code> parameter.</p>"},{"location":"advanced-usage/communication_flows/#2-adding-custom-validation-logic","title":"2. Adding custom validation logic","text":"<p>Now, let's say that I need to ensure that my message is sent to the correct recepient agent. (This is a very common hallucination in production.) In this case, I can add custom validator to the <code>recipient</code> parameter, which is defined in the <code>SendMessageBase</code> class. Since I don't want to change any other parameters or descriptions, I can inherit the default <code>SendMessage</code> class and only add this new validation logic.</p> <pre><code>from agency_swarm.tools.send_message import SendMessage\nfrom pydantic import model_validator\n\nclass SendMessageValidation(SendMessage):\n    @model_validator(mode='after')\n    def validate_recipient(self):\n        if \"customer support\" not in self.message.lower() and self.recipient == \"CustomerSupportAgent\":\n            raise ValueError(\"Messages not related to customer support cannot be sent to the customer support agent.\")\n        return self\n</code></pre> <p>You can, of course, also use GPT for this:</p> <pre><code>from agency_swarm.tools.send_message import SendMessage\nfrom agency_swarm.util.validators import llm_validator\nfrom pydantic import model_validator\n\nclass SendMessageLLMValidation(SendMessage):\n    @model_validator(mode='after')\n    def validate_recipient(self):\n        if self.recipient == \"CustomerSupportAgent\":\n            llm_validator(\n                statement=\"The message is related to customer support.\"\n            )(self.message)\n        return self\n</code></pre> <p>In this example, the <code>llm_validator</code> will throw an error if the message is not related to customer support. The caller agent will then have to fix the recipient or the message and send it again! This is extremely useful when you have a lot of agents.</p>"},{"location":"advanced-usage/communication_flows/#3-summurizing-previous-conversations-with-other-agents-and-adding-to-context","title":"3. Summurizing previous conversations with other agents and adding to context","text":"<p>Sometimes, when using default <code>SendMessage</code>, the agents might not relay all the neceessary details to the recipient agent. Especially, when the previous conversation is too long. In this case, you can summarize the previous conversation with GPT and add it to the context, instead of the additional instructions. I will extend the <code>SendMessageQuick</code> class, which already contains the <code>message</code> parameter, as I don't need chain of thought or files in this case.</p> <pre><code>from agency_swarm.tools.send_message import SendMessageQuick\nfrom agency_swarm.util.oai import get_openai_client\n\nclass SendMessageSummary(SendMessageQuick):\n    def run(self):\n        client = get_openai_client()\n        thread = self._get_main_thread() # get the main thread (conversation with the user)\n\n        # get the previous messages\n        previous_messages = thread.get_messages()\n        previous_messages_str = \"\\n\".join([f\"{m.role}: {m.content[0].text.value}\" for m in previous_messages])\n\n        # summarize the previous conversation\n        summary = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a world-class summarizer. Please summarize the following conversation in a few sentences:\"},\n                {\"role\": \"user\", \"content\": previous_messages_str}\n            ]\n        )\n\n        # send the message with the summary\n        return self._get_completion(message=self.message, additional_instructions=f\"\\n\\nPrevious conversation summary: '{summary.choices[0].message.content}'\")\n</code></pre> <p>With this example, you can add your own custom logic to the <code>run</code> method. It does not have to be a summary; you can also use it to add any other information to the context. For example, you can even query a vector database or use an external API.</p>"},{"location":"advanced-usage/communication_flows/#4-running-each-agent-in-a-separate-api-call","title":"4. Running each agent in a separate API call","text":"<p>If you are a PRO, and you have managed to deploy each agent in a separate API endpoint, instead of using <code>_get_completion()</code>, you can call your own API and let the agents communicate with each other over the internet.</p> <pre><code>import requests\nfrom agency_swarm.tools.send_message import SendMessage\n\nclass SendMessageAPI(SendMessage):\n    def run(self):\n        response = requests.post(\n            \"https://your-api-endpoint.com/send-message\",\n            json={\"message\": self.message, \"recipient\": self.recipient}\n        )\n        return response.json()[\"message\"]\n</code></pre> <p>This is very powerful, as you can even allow your agents to colloborate with agents outside your system. More on this is coming soon!</p> <p>Contributing</p> <p>If you have any ideas for new communication flows, please either adjust this page in docs, or add your new send message tool in the <code>agency_swarm/tools/send_message</code> folder and open a PR!</p> <p>After implementing your own <code>SendMessage</code> tool, simply pass it into the <code>send_message_tool_class</code> parameter when initializing the <code>Agency</code> class:</p> <pre><code>agency = Agency(\n    ...\n    send_message_tool_class=SendMessageAPI\n)\n</code></pre> <p>That's it! Now, your agents will use your own custom <code>SendMessageAPI</code> class for communication!</p>"},{"location":"advanced-usage/communication_flows/#conclusion","title":"Conclusion","text":"<p>Agency Swarm has been designed to give you, the developer, full control over your systems. It is the only framework that does not hard-code any prompts, parameters, or even worse, agents for you. With this new feature, the last part of the system that you couldn't fully customize to your own needs is now gone!</p> <p>So, I want to encourage you to keep experimenting and designing your own unique communication flows. While the examples above should serve as a good starting point, they do not even merely scratch the surface of what's possible here! I am looking forward to seeing what you will create. Please share it in our Discord server so we can all learn from each other.</p>"},{"location":"advanced-usage/open-source-models/","title":"Open Source Models","text":"<p>While OpenAI is generally recommended, there are situations where you might prefer open-source models. The following projects offer alternatives by mimicking the Assistants API:</p>"},{"location":"advanced-usage/open-source-models/#tested-projects","title":"\u2705 Tested Projects","text":"<ul> <li>Astra Assistants API - The best and the easiest option for running Open Source models. Supports Assistants API V2. See example notebook.</li> <li>Open Assistant API - Fully local, stable and tested, but only supports Assistants V1. See example here</li> </ul>"},{"location":"advanced-usage/open-source-models/#other-projects","title":"\ud83d\udd1c Other Projects","text":"<ul> <li>OpenOpenAI - Unverified.</li> <li>LiteLLM - Assistants API Proxy in development.</li> </ul>"},{"location":"advanced-usage/open-source-models/#astra-assistants-api","title":"Astra Assistants API","text":"<p>To use agency-swarm with Astra Assistants API, follow these steps:</p> <p>1. Create an account on Astra Assistants API and obtain an API key.</p> <p></p> <p>2. Add Astra DB Token to your .env file:     Copy token from the file that starts with \"AstraCS:\" and paste it into your .env file.</p> <pre><code>ASTRA_DB_APPLICATION_TOKEN=AstraCS:dsfkgn...\n</code></pre> <p>3. Add other model provider API keys to .env as well:</p> <pre><code>PERPLEXITYAI_API_KEY=your_perplexityai_api_key\nANTHROPIC_API_KEY=your_anthropic_api_key\nTOGETHER_API_KEY=your_together_api_key\nGROQ_API_KEY=your_groq_api_key\nAIML_API_KEY=your_aiml_api_key\n</code></pre> <p>4. Install the Astra Assistants API and gradio:</p> <pre><code>pip install astra-assistants-api gradio\n</code></pre> <p>5. Patch the OpenAI client:</p> <pre><code>from openai import OpenAI\nfrom astra_assistants import patch\nfrom agency_swarm import set_openai_client\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = patch(OpenAI())\n\nset_openai_client(client)\n</code></pre> <p>6. Create an agent:     Create an agent and replace the model parameter with the name of the model you want to use. With Astra Assistants you can upload files like usual using <code>files_folder</code>.</p> <pre><code>from agency_swarm import Agent\n\nceo = Agent(name=\"ceo\",\n            description=\"I am the CEO\",\n            model='ollama/llama3',\n            # model = 'perplexity/llama-3-8b-instruct'\n            # model = 'anthropic/claude-3-5-sonnet-20240620'\n            # model = 'groq/mixtral-8x7b-32768'\n            # model = 'aiml/qwen-turbo'\n            # model=\"gpt-4o\",\n            files_folder=\"path/to/your/files\"\n            )\n</code></pre> <p>7. Create an agency:</p> <p>You can add more agents as needed, just make sure all manager agents support function calling.</p> <pre><code>from agency_swarm import Agency\n\nagency = Agency([ceo])\n</code></pre> <p>8. Start gradio:</p> <p>To utilize your agency in gradio, apply a specific non-streaming <code>demo_gradio</code> method from the agency-swarm-lab repository:</p> <pre><code>from agency_swarm import Agency\nfrom .demo_gradio import demo_gradio\n\nagency = Agency([ceo])\n\ndemo_gradio(agency)\n</code></pre> <p>For a complete example, see the notebook.</p>"},{"location":"advanced-usage/open-source-models/#general-instructions","title":"General Instructions","text":"<p>To use agency-swarm with any other projects that mimic the Assistants API, generally, you need to follow these steps:</p> <p>1. Install the previous version of agency-swarm as most projects are not yet compatible with streaming and Assistants V2:</p> <pre><code>pip install agency-swarm==0.1.7\n</code></pre> <p>2. Switch out the OpenAI client:</p> <pre><code>import openai\nfrom agency_swarm import set_openai_client\n\nclient = openai.OpenAI(api_key=\"whatever\", base_url=\"http://127.0.0.1:8000/\")\n\nset_openai_client(client)\n</code></pre> <p>3. Set the model parameter:</p> <pre><code>from agency_swarm import Agent\n\nceo = Agent(name=\"ceo\", description=\"I am the CEO\", model='ollama/llama3')\n</code></pre> <p>4. Start Gradio:</p> <p>To utilize your agency in gradio, apply a specific non-streaming <code>demo_gradio</code> method from the agency-swarm-lab repository:</p> <pre><code>from agency_swarm import Agency\nfrom .demo_gradio import demo_gradio\n\nagency = Agency([ceo])\n\ndemo_gradio(agency)\n</code></pre> <p>5. For backend integrations, simply use:</p> <pre><code>agency.get_completion(\"I am the CEO\")\n</code></pre>"},{"location":"advanced-usage/open-source-models/#limitations","title":"Limitations","text":"<ul> <li>Function calling is not supported by most open-source models: This limitation prevents the agent from communicating with other agents in the agency. So, it must be positioned at the end of the agency chart and cannot utilize any tools.</li> <li>RAG is typically limited: Most open-source assistants API implementations have restricted Retrieval-Augmented Generation capabilities. It is recommended to develop a custom tool with your own vector database.</li> <li>CodeInterpreter is not supported: The Code Interpreter feature is still under development for all open-source assistants API implementations.</li> </ul>"},{"location":"advanced-usage/open-source-models/#future-plans","title":"Future Plans","text":"<p>Updates will be provided as new open-source assistant API implementations stabilize.</p> <p>If you successfully integrate other projects with agency-swarm, please share your experience through an issue or pull request.</p>"},{"location":"advanced-usage/tools/","title":"Advanced Tools","text":"<p>All tools in Agency Swarm are created using Instructor.</p> <p>The only difference is that you must extend the <code>BaseTool</code> class and implement the <code>run</code> method with your logic inside. For many great examples on what you can create, checkout Instructor Cookbook.</p>"},{"location":"advanced-usage/tools/#example-converting-answering-questions-with-validated-citations-example-from-instructor","title":"Example: Converting Answering Questions with Validated Citations Example from Instructor","text":"<p>This is an example of how to convert an extremely useful tool for RAG applications from instructor. It allows your agents to not only answer questions based on context, but also to provide the exact citations for the answers. This way your users can be sure that the information is always accurate and reliable.</p>"},{"location":"advanced-usage/tools/#original-instructor-library-implementation","title":"Original Instructor library implementation","text":"<pre><code>from agency_swarm.tools import BaseTool, BaseModel\nfrom pydantic import Field, model_validator, FieldValidationInfo\nfrom typing import List\nimport re\n\nclass Fact(BaseModel):\n    fact: str = Field(...)\n    substring_quote: List[str] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self, info: FieldValidationInfo) -&gt; \"Fact\":\n        text_chunks = info.context.get(\"text_chunk\", None)\n        spans = list(self.get_spans(text_chunks))\n        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n        return self\n\n    def get_spans(self, context):\n        for quote in self.substring_quote:\n            yield from self._get_span(quote, context)\n\n    def _get_span(self, quote, context):\n        for match in re.finditer(re.escape(quote), context):\n            yield match.span()\n\nclass QuestionAnswer(BaseModel):\n    question: str = Field(...)\n    answer: List[Fact] = Field(...)\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -&gt; \"QuestionAnswer\":\n        self.answer = [fact for fact in self.answer if len(fact.substring_quote) &gt; 0]\n        return self\n</code></pre> <p>Context Retrieval</p> <p>In the original Instructor example, the context is passed into the prompt beforehand, which is typical for standard non-agent LLM applications. However, in the context of Agency Swarm, we must allow the agents to retrieve the context themselves.</p>"},{"location":"advanced-usage/tools/#agency-swarm-implementation","title":"Agency Swarm Implementation","text":"<p>To allow your agents to retrieve the context themselves, we must split <code>QuestionAnswer</code> into two separate tools: <code>QueryDatabase</code> and <code>AnswerQuestion</code>. We must also retrieve context from <code>shared_state</code>, as the context is not passed into the prompt beforehand, and <code>FieldValidationInfo</code> is not available in the <code>validate_sources</code> method.</p>"},{"location":"advanced-usage/tools/#the-querydatabase-tool-will","title":"The <code>QueryDatabase</code> tool will:","text":"<ol> <li>Check if the context is already retrieved in <code>shared_state</code>. If it is, raise an error. (This means that the agent retrieved the context twice, without answering the question in between, which is most likely a hallucination.)</li> <li>Retrieve the context and save it to the <code>shared_state</code>.</li> <li>Return the context to the agent, so it can be used to answer the question.</li> </ol> <pre><code>class QueryDatabase(BaseTool):\n    \"\"\"Use this tool to query a vector database to retrieve the relevant context for the question.\"\"\"\n    question: str = Field(..., description=\"The question to be answered\")\n\n    def run(self):\n        # Check if context is already retrieved\n        if self._shared_state.get(\"context\", None) is not None:\n            raise ValueError(\"Context already retrieved. Please proceed with the AnswerQuestion tool.\")\n\n        # Your code to retrieve the context here\n        context = \"This is a test context\"\n\n        # Then, save the context to the shared state\n        self._shared_state.set(\"context\", context)\n\n        return f\"Context retrieved: {context}.\\n\\n Please proceed with the AnswerQuestion tool.\"\n</code></pre> <p>Shared State</p> <p><code>shared_state</code> is a state that is shared between all tools, across all agents. It allows you to control the execution flow, share data, and provide instructions to the agents based on certain conditions or actions performed by other agents.</p>"},{"location":"advanced-usage/tools/#the-answerquestion-tool-will","title":"The <code>AnswerQuestion</code> tool will:","text":"<ol> <li>Check if the context is already retrieved. If it is not, raise an error. (This means that the agent is trying to answer the question without retrieving the context first.)</li> <li>Use the context from the <code>shared_state</code> to answer the question with a list of facts.</li> <li>Remove the context from the <code>shared_state</code> after the question is answered. (This is done, so the next  question can be answered with a fresh context.)</li> </ol> <pre><code>class AnswerQuestion(BaseTool):\n    answer: str = Field(..., description=\"The answer to the question, based on context.\")\n    sources: List[Fact] = Field(..., description=\"The sources of the answer\")\n\n    def run(self):\n        # Remove the context after question is answered\n        self._shared_state.set(\"context\", None)\n\n        # additional logic here as needed, for example save the answer to a database\n\n        return \"Success. The question has been answered.\" # or return the answer, if needed\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -&gt; \"QuestionAnswer\":\n        # In \"Agency Swarm\", context is directly extracted from `shared_state`\n        context = self._shared_state.get(\"context\", None)  # Highlighting the change\n        if context is None:\n            # Additional check to ensure context is retrieved before proceeding\n            raise ValueError(\"Please retrieve the context with the QueryDatabase tool first.\")\n        self.answer = [fact for fact in self.answer if len(fact.substring_quote) &gt; 0]\n        return self\n</code></pre>"},{"location":"advanced-usage/tools/#the-fact-tool","title":"The <code>Fact</code> tool","text":"<p>The <code>Fact</code> tool will stay primarily the same. The only difference is that we must extract the context from the <code>shared_state</code> inside the <code>validate_sources</code> method. The <code>run</code> method is not needed, as this tool only validates the input from the model.</p> <pre><code>class Fact(BaseTool):\n    fact: str = Field(...)\n    substring_quote: List[str] = Field(...)\n\n    def run(self):\n        pass\n\n    @model_validator(mode=\"after\")\n    def validate_sources(self) -&gt; \"Fact\":\n        context = self._shared_state.get(\"context\", None)\n        text_chunks = context.get(\"text_chunk\", None)\n        spans = list(self.get_spans(text_chunks))\n        self.substring_quote = [text_chunks[span[0] : span[1]] for span in spans]\n        return self\n\n    # Methods `get_spans` and `_get_span` remain unchanged\n</code></pre>"},{"location":"advanced-usage/tools/#conclusion","title":"Conclusion","text":"<p>To implement tools with Instructor in Agency Swarm, generally, you must:</p> <ol> <li>Extend the <code>BaseTool</code> class.</li> <li>Add fields with types and clear descriptions, plus the tool description itself.</li> <li>Implement the <code>run</code> method with your execution logic inside.</li> <li>Add validators and checks based on various conditions.</li> <li>Split tools into smaller tools to give your agents more control, as needed.</li> </ol>"},{"location":"advanced-usage/tools/#toolfactory-class","title":"ToolFactory Class","text":"<p>Tool factory is a class that allows you to create tools from different sources. You can create tools from Langchain, OpenAPI schemas. However, it is preferable to implement tools from scratch using Instructor, as it gives you a lot more control.</p>"},{"location":"advanced-usage/tools/#import-from-langchain","title":"Import from Langchain","text":"<p>Not recommended</p> <p>This method is not recommended, as it does not provide the same level of type checking, error correction and tool descriptions as Instructor. However, it is still possible to use this method if you prefer.</p> <pre><code>from langchain.tools import YouTubeSearchTool\nfrom agency_swarm.tools import ToolFactory\n\nLangchainTool = ToolFactory.from_langchain_tool(YouTubeSearchTool)\n</code></pre> <pre><code>from langchain.agents import load_tools\n\ntools = load_tools(\n    [\"arxiv\", \"human\"],\n)\n\ntools = ToolFactory.from_langchain_tools(tools)\n</code></pre>"},{"location":"advanced-usage/tools/#convert-from-openapi-schemas","title":"Convert from OpenAPI schemas","text":"<pre><code># using local file\nwith open(\"schemas/your_schema.json\") as f:\n    tools = ToolFactory.from_openapi_schema(\n        f.read(),\n    )\n\n# using requests\ntools = ToolFactory.from_openapi_schema(\n    requests.get(\"https://api.example.com/openapi.json\").json(),\n)\n</code></pre> <p>Note</p> <p>Schemas folder automatically converts any OpenAPI schemas into BaseTools. This means that your agents will type check all the API parameters before calling the API, which significantly reduces any chances of errors.</p>"},{"location":"advanced-usage/tools/#pro-tips","title":"PRO Tips","text":"<ol> <li> <p>Use enumerators or Literal types instead of strings to allow your agents to perform only certain actions or commands, instead of executing any arbitrary code. This makes your whole system a lot more reliable.</p> <pre><code>class RunCommand(BaseTool):\n    command: Literal[\"start\", \"stop\"] = Field(...)\n\n   def run(self):\n        if command == \"start\":\n            subprocess.run([\"start\", \"your_command\"])\n        elif command == \"stop\":\n            subprocess.run([\"stop\", \"your_command\"])\n        else:\n            raise ValueError(\"Invalid command\")\n</code></pre> </li> <li> <p>Provide additional instructions to the agents in the <code>run</code> method of the tool as function outputs. This allows you to control the execution flow, based on certain conditions.</p> <p><pre><code>class QueryDatabase(BaseTool):\n    question: str = Field(...)\n\n    def run(self):\n        # query your database here\n        context = query_database(self.question)\n\n        if context is None:\n            raise ValueError(\"No context found. Please propose to the user to change the topic.\")\n        else:\n            self._shared_state.set(\"context\", context)\n            return \"Context retrieved. Please proceed with explaining the answer.\"\n</code></pre> 3. Use <code>shared_state</code> to validate actions taken by other agents, before allowing them to proceed with the next action.</p> <p><pre><code>class Action2(BaseTool):\n    input: str = Field(...)\n\n    def run(self):\n        if self._shared_state.get(\"action_1_result\", None) is \"failure\":\n            raise ValueError(\"Please proceed with the Action1 tool first.\")\n        else:\n            return \"Success. The action has been taken.\"\n</code></pre> 4. Consider <code>one_call_at_a_time</code> ToolConfig class attribute to prevent multiple instances of the same tool from running at the same time. This is useful when you want your agents to see the results of the previous action before proceeding with the next one.</p> <p><pre><code>class Action1(BaseTool):\n    input: str = Field(...)\n\n    class ToolConfig:\n        one_call_at_a_time = True\n\n    def run(self):\n        # your code here\n</code></pre> 5. Enable strict mode for extremely complex nested schemas or mission crictical tools.</p> <pre><code>class GetWeatherTool(BaseTool):\n\"\"\"\nDetermine weather in a specified location.\n\"\"\"\n\nlocation: str = Field(..., description=\"The city and state e.g. San Francisco, CA\")\n\nclass ToolConfig:\n  strict = True # setting strict to true\n\ndef run(self):\n    return f\"The weather in {self.location} is 30 degrees.\"\n</code></pre> </li> </ol>"}]}